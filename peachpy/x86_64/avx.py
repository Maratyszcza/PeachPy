# This file is auto-generated by /codegen/x86_64.py
# Instruction data is based on package opcodes 0.3.14

import inspect

import peachpy.stream
import peachpy.x86_64.options
import peachpy.x86_64.isa
from peachpy.util import is_sint8, is_sint32
from peachpy.x86_64.encoding import rex, optional_rex, vex2, vex3, evex, modrm_sib_disp
from peachpy.x86_64.instructions import Instruction, BranchInstruction
from peachpy.x86_64.operand import is_al, is_ax, is_eax, is_rax, is_cl, is_xmm0, is_r8, is_r8rex, is_r16, is_r32, is_r64, \
    is_mm, is_xmm, is_ymm, is_m, is_m8, is_m16, is_m32, is_m64, is_m80, is_m128, is_m256, is_m512, \
    is_evex_xmm, is_xmmk, is_xmmkz, is_evex_ymm, is_ymmk, is_ymmkz, is_zmm, is_zmmk, is_zmmkz, is_k, is_kk, \
    is_m32k, is_m64k, is_m16kz, is_m32kz, is_m64kz, is_m128kz, is_m256kz, is_m512kz, \
    is_m64_m32bcst, is_m128_m32bcst, is_m256_m32bcst, is_m512_m32bcst, \
    is_m128_m64bcst, is_m256_m64bcst, is_m512_m64bcst, \
    is_vmx, is_vmy, is_evex_vmx, is_evex_vmy, is_vmz, is_vmxk, is_vmyk, is_vmzk, \
    is_imm, is_imm4, is_imm8, is_imm16, is_imm32, is_imm64, \
    is_rel8, is_rel32, is_label, is_er, is_sae, check_operand, format_operand_type


class VMOVSS(Instruction):
    """Move Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVSS(m32, xmm)               [AVX]
            * VMOVSS(m32{k}, xmm)            [AVX512F]
            * VMOVSS(xmm, m32)               [AVX]
            * VMOVSS(xmm, xmm, xmm)          [AVX]
            * VMOVSS(xmm{k}{z}, m32)         [AVX512F]
            * VMOVSS(xmm{k}{z}, xmm, xmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVSS, self).__init__("VMOVSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.in_regs = (False, True)
                self.out_regs = (True, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m32(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.in_regs = (True, True)
                self.out_regs = (False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m32k(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
                self.in_regs = (True, True)
                self.out_regs = (False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.in_regs = (False, True)
                self.out_regs = (True, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[2].hcode, op[0], op[1].hlcode, vex3) + bytearray([0x11, 0xC0 | op[2].lcode << 3 | op[0].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[2].hcode << 7) | (op[0].ehcode << 5) | (op[2].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x11, 0xC0 | op[2].lcode << 3 | op[0].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTPS(Instruction):
    """Extract Packed Single Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTPS(r32/m32, xmm, imm8)    [AVX512F]
            * VEXTRACTPS(r32/m32, xmm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTPS, self).__init__("VEXTRACTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTPS\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x79, 0x17, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[1].hcode, op[0].address) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, 0x08, 0x17, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTPS(Instruction):
    """Insert Packed Single Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTPS(xmm, xmm, xmm/m32, imm8)    [AVX512F]
            * VINSERTPS(xmm, xmm, xmm/m32, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTPS, self).__init__("VINSERTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTPS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x21, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x21, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VINSERTPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDSS(Instruction):
    """Add Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDSS(xmm, xmm, xmm/m32)            [AVX]
            * VADDSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VADDSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDSS, self).__init__("VADDSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VADDSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSUBSS(Instruction):
    """Subtract Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSUBSS(xmm, xmm, xmm/m32)            [AVX]
            * VSUBSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSUBSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSUBSS, self).__init__("VSUBSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSUBSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMULSS(Instruction):
    """Multiply Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMULSS(xmm, xmm, xmm/m32)            [AVX]
            * VMULSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VMULSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMULSS, self).__init__("VMULSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMULSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDIVSS(Instruction):
    """Divide Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDIVSS(xmm, xmm, xmm/m32)            [AVX]
            * VDIVSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VDIVSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDIVSS, self).__init__("VDIVSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VDIVSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSQRTSS(Instruction):
    """Compute Square Root of Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSQRTSS(xmm, xmm, xmm/m32)            [AVX]
            * VSQRTSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSQRTSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSQRTSS, self).__init__("VSQRTSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSQRTSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VROUNDSS(Instruction):
    """Round Scalar Single Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VROUNDSS(xmm, xmm, xmm/m32, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VROUNDSS, self).__init__("VROUNDSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VROUNDSS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VROUNDSS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRNDSCALESS(Instruction):
    """Round Scalar Single-Precision Floating-Point Value To Include A Given Number Of Fraction Bits"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRNDSCALESS(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VRNDSCALESS(xmm{k}{z}, xmm, xmm/m32, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRNDSCALESS, self).__init__("VRNDSCALESS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALESS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x0A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALESS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRNDSCALESS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRANGESS(Instruction):
    """Range Restriction Calculation For a pair of Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRANGESS(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512DQ]
            * VRANGESS(xmm{k}{z}, xmm, xmm/m32, imm8)       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRANGESS, self).__init__("VRANGESS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VRANGESS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGESS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRANGESS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMINSS(Instruction):
    """Return Minimum Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMINSS(xmm, xmm, xmm/m32)             [AVX]
            * VMINSS(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VMINSS(xmm{k}{z}, xmm, xmm/m32)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMINSS, self).__init__("VMINSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMINSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMAXSS(Instruction):
    """Return Maximum Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMAXSS(xmm, xmm, xmm/m32)             [AVX]
            * VMAXSS(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VMAXSS(xmm{k}{z}, xmm, xmm/m32)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMAXSS, self).__init__("VMAXSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMAXSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VREDUCESS(Instruction):
    """Perform Reduction Transformation on a Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VREDUCESS(xmm{k}{z}, xmm, xmm/m32, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VREDUCESS, self).__init__("VREDUCESS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VREDUCESS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VREDUCESS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETMANTSS(Instruction):
    """Extract Normalized Mantissa from Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETMANTSS(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VGETMANTSS(xmm{k}{z}, xmm, xmm/m32, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETMANTSS, self).__init__("VGETMANTSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VGETMANTSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETMANTSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETEXPSS(Instruction):
    """Extract Exponent of Scalar Single-Precision Floating-Point Value as Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETEXPSS(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VGETEXPSS(xmm{k}{z}, xmm, xmm/m32)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETEXPSS, self).__init__("VGETEXPSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VGETEXPSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETEXPSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCALEFSS(Instruction):
    """Scale Scalar Single-Precision Floating-Point Value With a Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCALEFSS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSCALEFSS(xmm{k}{z}, xmm, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCALEFSS, self).__init__("VSCALEFSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x2D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VSCALEFSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x2D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSCALEFSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFIXUPIMMSS(Instruction):
    """Fix Up Special Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFIXUPIMMSS(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VFIXUPIMMSS(xmm{k}{z}, xmm, xmm/m32, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFIXUPIMMSS, self).__init__("VFIXUPIMMSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (True, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (True, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VFIXUPIMMSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFPCLASSSS(Instruction):
    """Test Class of Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFPCLASSSS(k{k}, xmm/m32, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFPCLASSSS, self).__init__("VFPCLASSSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VFPCLASSSS\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, op[0].kcode | 0x08, 0x67, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_kk(self.operands[0]) and is_m32(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4) + bytearray([op[2] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VFPCLASSSS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCPSS(Instruction):
    """Compute Approximate Reciprocal of Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCPSS(xmm, xmm, xmm/m32)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCPSS, self).__init__("VRCPSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRCPSS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x53, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x53]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VRCPSS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRTSS(Instruction):
    """Compute Reciprocal of Square Root of Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRTSS(xmm, xmm, xmm/m32)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRTSS, self).__init__("VRSQRTSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRSQRTSS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x52, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x52]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VRSQRTSS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP14SS(Instruction):
    """Compute Approximate Reciprocal of a Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP14SS(xmm{k}{z}, xmm, xmm/m32)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP14SS, self).__init__("VRCP14SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRCP14SS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x4D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x4D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
        else:
            raise SyntaxError("Invalid operand types: VRCP14SS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT14SS(Instruction):
    """Compute Approximate Reciprocal of a Square Root of a Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT14SS(xmm{k}{z}, xmm, xmm/m32)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT14SS, self).__init__("VRSQRT14SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRSQRT14SS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x4F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x4F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
        else:
            raise SyntaxError("Invalid operand types: VRSQRT14SS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP28SS(Instruction):
    """Approximation to the Reciprocal of a Scalar Single-Precision Floating-Point Value with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP28SS(xmm{k}{z}, xmm, xmm, {sae})    [AVX512ER]
            * VRCP28SS(xmm{k}{z}, xmm, xmm/m32)       [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP28SS, self).__init__("VRCP28SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xCB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xCB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRCP28SS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xCB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRCP28SS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRCP28SS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT28SS(Instruction):
    """Approximation to the Reciprocal Square Root of a Scalar Single-Precision Floating-Point Value with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT28SS(xmm{k}{z}, xmm, xmm, {sae})    [AVX512ER]
            * VRSQRT28SS(xmm{k}{z}, xmm, xmm/m32)       [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT28SS, self).__init__("VRSQRT28SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xCD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xCD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28SS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xCD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28SS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRSQRT28SS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCMPSS(Instruction):
    """Compare Scalar Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCMPSS(k{k}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VCMPSS(k{k}, xmm, xmm/m32, imm8)       [AVX512F]
            * VCMPSS(xmm, xmm, xmm/m32, imm8)        [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCMPSS, self).__init__("VCMPSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPSS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPSS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCMPSS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCOMISS(Instruction):
    """Compare Scalar Ordered Single-Precision Floating-Point Values and Set EFLAGS"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCOMISS(xmm, xmm, {sae})    [AVX512F]
            * VCOMISS(xmm, xmm/m32)       [AVX512F]
            * VCOMISS(xmm, xmm/m32)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCOMISS, self).__init__("VCOMISS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, 0x48, 0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCOMISS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, 0x18, 0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.out_operands = (False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCOMISS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCOMISS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUCOMISS(Instruction):
    """Unordered Compare Scalar Single-Precision Floating-Point Values and Set EFLAGS"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUCOMISS(xmm, xmm, {sae})    [AVX512F]
            * VUCOMISS(xmm, xmm/m32)       [AVX512F]
            * VUCOMISS(xmm, xmm/m32)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUCOMISS, self).__init__("VUCOMISS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, 0x48, 0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VUCOMISS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, 0x18, 0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.out_operands = (False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VUCOMISS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VUCOMISS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVSD(Instruction):
    """Move Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVSD(m64, xmm)               [AVX]
            * VMOVSD(m64{k}, xmm)            [AVX512F]
            * VMOVSD(xmm, m64)               [AVX]
            * VMOVSD(xmm, xmm, xmm)          [AVX]
            * VMOVSD(xmm{k}{z}, m64)         [AVX512F]
            * VMOVSD(xmm{k}{z}, xmm, xmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVSD, self).__init__("VMOVSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.in_regs = (False, True)
                self.out_regs = (True, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.in_regs = (True, True)
                self.out_regs = (False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64k(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
                self.in_regs = (True, True)
                self.out_regs = (False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.in_regs = (False, True)
                self.out_regs = (True, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[2].hcode, op[0], op[1].hlcode, vex3) + bytearray([0x11, 0xC0 | op[2].lcode << 3 | op[0].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[2].hcode << 7) | (op[0].ehcode << 5) | (op[2].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x11, 0xC0 | op[2].lcode << 3 | op[0].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDSD(Instruction):
    """Add Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDSD(xmm, xmm, xmm/m64)            [AVX]
            * VADDSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VADDSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDSD, self).__init__("VADDSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VADDSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSUBSD(Instruction):
    """Subtract Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSUBSD(xmm, xmm, xmm/m64)            [AVX]
            * VSUBSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSUBSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSUBSD, self).__init__("VSUBSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSUBSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMULSD(Instruction):
    """Multiply Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMULSD(xmm, xmm, xmm/m64)            [AVX]
            * VMULSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VMULSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMULSD, self).__init__("VMULSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMULSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDIVSD(Instruction):
    """Divide Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDIVSD(xmm, xmm, xmm/m64)            [AVX]
            * VDIVSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VDIVSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDIVSD, self).__init__("VDIVSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VDIVSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSQRTSD(Instruction):
    """Compute Square Root of Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSQRTSD(xmm, xmm, xmm/m64)            [AVX]
            * VSQRTSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSQRTSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSQRTSD, self).__init__("VSQRTSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSQRTSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VROUNDSD(Instruction):
    """Round Scalar Double Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VROUNDSD(xmm, xmm, xmm/m64, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VROUNDSD, self).__init__("VROUNDSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VROUNDSD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VROUNDSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRNDSCALESD(Instruction):
    """Round Scalar Double-Precision Floating-Point Value To Include A Given Number Of Fraction Bits"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRNDSCALESD(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VRNDSCALESD(xmm{k}{z}, xmm, xmm/m64, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRNDSCALESD, self).__init__("VRNDSCALESD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALESD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALESD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRNDSCALESD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRANGESD(Instruction):
    """Range Restriction Calculation For a pair of Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRANGESD(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512DQ]
            * VRANGESD(xmm{k}{z}, xmm, xmm/m64, imm8)       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRANGESD, self).__init__("VRANGESD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VRANGESD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x51, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGESD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRANGESD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMINSD(Instruction):
    """Return Minimum Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMINSD(xmm, xmm, xmm/m64)             [AVX]
            * VMINSD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VMINSD(xmm{k}{z}, xmm, xmm/m64)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMINSD, self).__init__("VMINSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMINSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMAXSD(Instruction):
    """Return Maximum Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMAXSD(xmm, xmm, xmm/m64)             [AVX]
            * VMAXSD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VMAXSD(xmm{k}{z}, xmm, xmm/m64)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMAXSD, self).__init__("VMAXSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMAXSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VREDUCESD(Instruction):
    """Perform Reduction Transformation on a Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VREDUCESD(xmm{k}{z}, xmm, xmm/m64, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VREDUCESD, self).__init__("VREDUCESD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VREDUCESD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VREDUCESD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETMANTSD(Instruction):
    """Extract Normalized Mantissa from Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETMANTSD(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VGETMANTSD(xmm{k}{z}, xmm, xmm/m64, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETMANTSD, self).__init__("VGETMANTSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VGETMANTSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETMANTSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETEXPSD(Instruction):
    """Extract Exponent of Scalar Double-Precision Floating-Point Value as Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETEXPSD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VGETEXPSD(xmm{k}{z}, xmm, xmm/m64)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETEXPSD, self).__init__("VGETEXPSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VGETEXPSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETEXPSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCALEFSD(Instruction):
    """Scale Scalar Double-Precision Floating-Point Value With a Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCALEFSD(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VSCALEFSD(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCALEFSD, self).__init__("VSCALEFSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x2D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VSCALEFSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x2D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSCALEFSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFIXUPIMMSD(Instruction):
    """Fix Up Special Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFIXUPIMMSD(xmm{k}{z}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VFIXUPIMMSD(xmm{k}{z}, xmm, xmm/m64, imm8)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFIXUPIMMSD, self).__init__("VFIXUPIMMSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (True, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (True, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VFIXUPIMMSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFPCLASSSD(Instruction):
    """Test Class of Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFPCLASSSD(k{k}, xmm/m64, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFPCLASSSD, self).__init__("VFPCLASSSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VFPCLASSSD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, op[0].kcode | 0x08, 0x67, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_kk(self.operands[0]) and is_m64(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8) + bytearray([op[2] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VFPCLASSSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP14SD(Instruction):
    """Compute Approximate Reciprocal of a Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP14SD(xmm{k}{z}, xmm, xmm/m64)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP14SD, self).__init__("VRCP14SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRCP14SD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x4D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x4D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
        else:
            raise SyntaxError("Invalid operand types: VRCP14SD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT14SD(Instruction):
    """Compute Approximate Reciprocal of a Square Root of a Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT14SD(xmm{k}{z}, xmm, xmm/m64)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT14SD, self).__init__("VRSQRT14SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VRSQRT14SD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x4F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x4F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
        else:
            raise SyntaxError("Invalid operand types: VRSQRT14SD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP28SD(Instruction):
    """Approximation to the Reciprocal of a Scalar Double-Precision Floating-Point Value with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP28SD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512ER]
            * VRCP28SD(xmm{k}{z}, xmm, xmm/m64)       [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP28SD, self).__init__("VRCP28SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xCB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xCB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRCP28SD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xCB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRCP28SD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRCP28SD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT28SD(Instruction):
    """Approximation to the Reciprocal Square Root of a Scalar Double-Precision Floating-Point Value with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT28SD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512ER]
            * VRSQRT28SD(xmm{k}{z}, xmm, xmm/m64)       [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT28SD, self).__init__("VRSQRT28SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xCD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xCD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28SD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xCD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28SD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRSQRT28SD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCMPSD(Instruction):
    """Compare Scalar Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCMPSD(k{k}, xmm, xmm, {sae}, imm8)    [AVX512F]
            * VCMPSD(k{k}, xmm, xmm/m64, imm8)       [AVX512F]
            * VCMPSD(xmm, xmm, xmm/m64, imm8)        [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCMPSD, self).__init__("VCMPSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPSD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPSD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCMPSD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCOMISD(Instruction):
    """Compare Scalar Ordered Double-Precision Floating-Point Values and Set EFLAGS"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCOMISD(xmm, xmm, {sae})    [AVX512F]
            * VCOMISD(xmm, xmm/m64)       [AVX512F]
            * VCOMISD(xmm, xmm/m64)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCOMISD, self).__init__("VCOMISD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, 0x48, 0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCOMISD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, 0x18, 0x2F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.out_operands = (False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCOMISD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCOMISD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUCOMISD(Instruction):
    """Unordered Compare Scalar Double-Precision Floating-Point Values and Set EFLAGS"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUCOMISD(xmm, xmm, {sae})    [AVX512F]
            * VUCOMISD(xmm, xmm/m64)       [AVX512F]
            * VUCOMISD(xmm, xmm/m64)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUCOMISD, self).__init__("VUCOMISD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, 0x48, 0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VUCOMISD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, 0x18, 0x2E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.out_operands = (False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VUCOMISD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VUCOMISD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVAPS(Instruction):
    """Move Aligned Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVAPS(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVAPS(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVAPS(m512{k}{z}, zmm)        [AVX512F]
            * VMOVAPS(xmm, xmm/m128)          [AVX]
            * VMOVAPS(xmm/m128, xmm)          [AVX]
            * VMOVAPS(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVAPS(ymm, ymm/m256)          [AVX]
            * VMOVAPS(ymm/m256, ymm)          [AVX]
            * VMOVAPS(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVAPS(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVAPS, self).__init__("VMOVAPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVAPS\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[1].hcode, op[0], 0, vex3) + bytearray([0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[1].hcode, op[0], 0, vex3) + bytearray([0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVAPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVUPS(Instruction):
    """Move Unaligned Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVUPS(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVUPS(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVUPS(m512{k}{z}, zmm)        [AVX512F]
            * VMOVUPS(xmm, xmm/m128)          [AVX]
            * VMOVUPS(xmm/m128, xmm)          [AVX]
            * VMOVUPS(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVUPS(ymm, ymm/m256)          [AVX]
            * VMOVUPS(ymm/m256, ymm)          [AVX]
            * VMOVUPS(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVUPS(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVUPS, self).__init__("VMOVUPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVUPS\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[1].hcode, op[0], 0, vex3) + bytearray([0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[1].hcode, op[0], 0, vex3) + bytearray([0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVUPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVLPS(Instruction):
    """Move Low Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVLPS(m64, xmm)         [AVX512F]
            * VMOVLPS(m64, xmm)         [AVX]
            * VMOVLPS(xmm, xmm, m64)    [AVX512F]
            * VMOVLPS(xmm, xmm, m64)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVLPS, self).__init__("VMOVLPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_m64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[1].ehcode, op[0].address) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVLPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVLPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVLPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVHPS(Instruction):
    """Move High Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVHPS(m64, xmm)         [AVX512F]
            * VMOVHPS(m64, xmm)         [AVX]
            * VMOVHPS(xmm, xmm, m64)    [AVX512F]
            * VMOVHPS(xmm, xmm, m64)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVHPS, self).__init__("VMOVHPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_m64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[1].ehcode, op[0].address) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVHPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVHPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVHPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMASKMOVPS(Instruction):
    """Conditional Move Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMASKMOVPS(m128, xmm, xmm)    [AVX]
            * VMASKMOVPS(m256, ymm, ymm)    [AVX]
            * VMASKMOVPS(xmm, xmm, m128)    [AVX]
            * VMASKMOVPS(ymm, ymm, m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMASKMOVPS, self).__init__("VMASKMOVPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VMASKMOVPS\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x2E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x2E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VMASKMOVPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVMSKPS(Instruction):
    """Extract Packed Single-Precision Floating-Point Sign Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVMSKPS(r32, xmm)    [AVX]
            * VMOVMSKPS(r32, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVMSKPS, self).__init__("VMOVMSKPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVMSKPS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x50, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_r32(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x50, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        else:
            raise SyntaxError("Invalid operand types: VMOVMSKPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVNTPS(Instruction):
    """Store Packed Single-Precision Floating-Point Values Using Non-Temporal Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVNTPS(m128, xmm)    [AVX512F and AVX512VL]
            * VMOVNTPS(m128, xmm)    [AVX]
            * VMOVNTPS(m256, ymm)    [AVX512F and AVX512VL]
            * VMOVNTPS(m256, ymm)    [AVX]
            * VMOVNTPS(m512, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVNTPS, self).__init__("VMOVNTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVNTPS\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVNTPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTSS(Instruction):
    """Broadcast Single-Precision Floating-Point Element"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTSS(xmm, m32)              [AVX]
            * VBROADCASTSS(xmm, xmm)              [AVX2]
            * VBROADCASTSS(ymm, m32)              [AVX]
            * VBROADCASTSS(ymm, xmm)              [AVX2]
            * VBROADCASTSS(ymm{k}{z}, xmm/m32)    [AVX512F and AVX512VL]
            * VBROADCASTSS(zmm{k}{z}, xmm/m32)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTSS, self).__init__("VBROADCASTSS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTSS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x18, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x18, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x18, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x18, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTSS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVSLDUP(Instruction):
    """Move Packed Single-FP Low and Duplicate"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVSLDUP(xmm, xmm/m128)          [AVX]
            * VMOVSLDUP(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVSLDUP(ymm, ymm/m256)          [AVX]
            * VMOVSLDUP(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVSLDUP(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVSLDUP, self).__init__("VMOVSLDUP", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVSLDUP\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVSLDUP " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVSHDUP(Instruction):
    """Move Packed Single-FP High and Duplicate"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVSHDUP(xmm, xmm/m128)          [AVX]
            * VMOVSHDUP(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVSHDUP(ymm, ymm/m256)          [AVX]
            * VMOVSHDUP(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVSHDUP(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVSHDUP, self).__init__("VMOVSHDUP", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVSHDUP\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x16, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0x16, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x16, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x16, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x16, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVSHDUP " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXPANDPS(Instruction):
    """Load Sparse Packed Single-Precision Floating-Point Values from Dense Memory"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXPANDPS(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VEXPANDPS(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VEXPANDPS(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXPANDPS, self).__init__("VEXPANDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VEXPANDPS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VEXPANDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCOMPRESSPS(Instruction):
    """Store Sparse Packed Single-Precision Floating-Point Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCOMPRESSPS(m128{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VCOMPRESSPS(m256{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VCOMPRESSPS(m512{k}{z}, zmm)    [AVX512F]
            * VCOMPRESSPS(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VCOMPRESSPS(ymm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VCOMPRESSPS(zmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCOMPRESSPS, self).__init__("VCOMPRESSPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VCOMPRESSPS\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VCOMPRESSPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERDPS(Instruction):
    """Gather Packed Single-Precision Floating-Point Values Using Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERDPS(xmm, vm32x, xmm)    [AVX2]
            * VGATHERDPS(xmm{k}, vm32x)      [AVX512F and AVX512VL]
            * VGATHERDPS(ymm, vm32y, ymm)    [AVX2]
            * VGATHERDPS(ymm{k}, vm32y)      [AVX512F and AVX512VL]
            * VGATHERDPS(zmm{k}, vm32z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERDPS, self).__init__("VGATHERDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGATHERDPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmy(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VGATHERDPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGATHERDPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERQPS(Instruction):
    """Gather Packed Single-Precision Floating-Point Values Using Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERQPS(xmm, vm64x, xmm)    [AVX2]
            * VGATHERQPS(xmm, vm64y, xmm)    [AVX2]
            * VGATHERQPS(xmm{k}, vm64x)      [AVX512F and AVX512VL]
            * VGATHERQPS(xmm{k}, vm64y)      [AVX512F and AVX512VL]
            * VGATHERQPS(ymm{k}, vm64z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERQPS, self).__init__("VGATHERQPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGATHERQPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_xmm(self.operands[0]) and is_vmy(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VGATHERQPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGATHERQPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF0DPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Doubleword Indices Using T0 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF0DPS(vm32z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF0DPS, self).__init__("VGATHERPF0DPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF0DPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(1, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF0DPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF0QPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Quadword Indices Using T0 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF0QPS(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF0QPS, self).__init__("VGATHERPF0QPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF0QPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(1, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF0QPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF1DPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Doubleword Indices Using T1 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF1DPS(vm32z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF1DPS, self).__init__("VGATHERPF1DPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF1DPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(2, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF1DPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF1QPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Quadword Indices Using T1 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF1QPS(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF1QPS, self).__init__("VGATHERPF1QPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF1QPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(2, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF1QPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERDPS(Instruction):
    """Scatter Packed Single-Precision Floating-Point Values with Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERDPS(vm32x{k}, xmm)    [AVX512F and AVX512VL]
            * VSCATTERDPS(vm32y{k}, ymm)    [AVX512F and AVX512VL]
            * VSCATTERDPS(vm32z{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERDPS, self).__init__("VSCATTERDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VSCATTERDPS\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERQPS(Instruction):
    """Scatter Packed Single-Precision Floating-Point Values with Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERQPS(vm64x{k}, xmm)    [AVX512F and AVX512VL]
            * VSCATTERQPS(vm64y{k}, xmm)    [AVX512F and AVX512VL]
            * VSCATTERQPS(vm64z{k}, ymm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERQPS, self).__init__("VSCATTERQPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VSCATTERQPS\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERQPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF0DPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Doubleword Indices Using T0 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF0DPS(vm32z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF0DPS, self).__init__("VSCATTERPF0DPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF0DPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(5, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF0DPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF0QPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Quadword Indices Using T0 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF0QPS(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF0QPS, self).__init__("VSCATTERPF0QPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF0QPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(5, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF0QPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF1DPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Doubleword Indices Using T1 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF1DPS(vm32z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF1DPS, self).__init__("VSCATTERPF1DPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF1DPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(6, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF1DPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF1QPS(Instruction):
    """Sparse Prefetch Packed Single-Precision Floating-Point Data Values with Signed Quadword Indices Using T1 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF1QPS(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF1QPS, self).__init__("VSCATTERPF1QPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF1QPS\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(6, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF1QPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVAPD(Instruction):
    """Move Aligned Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVAPD(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVAPD(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVAPD(m512{k}{z}, zmm)        [AVX512F]
            * VMOVAPD(xmm, xmm/m128)          [AVX]
            * VMOVAPD(xmm/m128, xmm)          [AVX]
            * VMOVAPD(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVAPD(ymm, ymm/m256)          [AVX]
            * VMOVAPD(ymm/m256, ymm)          [AVX]
            * VMOVAPD(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVAPD(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVAPD, self).__init__("VMOVAPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVAPD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[1].hcode, op[0], 0, vex3) + bytearray([0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[1].hcode, op[0], 0, vex3) + bytearray([0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x29]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x29, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVAPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVUPD(Instruction):
    """Move Unaligned Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVUPD(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVUPD(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVUPD(m512{k}{z}, zmm)        [AVX512F]
            * VMOVUPD(xmm, xmm/m128)          [AVX]
            * VMOVUPD(xmm/m128, xmm)          [AVX]
            * VMOVUPD(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVUPD(ymm, ymm/m256)          [AVX]
            * VMOVUPD(ymm/m256, ymm)          [AVX]
            * VMOVUPD(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVUPD(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVUPD, self).__init__("VMOVUPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVUPD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[1].hcode, op[0], 0, vex3) + bytearray([0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[1].hcode, op[0], 0, vex3) + bytearray([0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x10, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVUPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVLPD(Instruction):
    """Move Low Packed Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVLPD(m64, xmm)         [AVX512F]
            * VMOVLPD(m64, xmm)         [AVX]
            * VMOVLPD(xmm, xmm, m64)    [AVX512F]
            * VMOVLPD(xmm, xmm, m64)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVLPD, self).__init__("VMOVLPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_m64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVLPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVLPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVLPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVHPD(Instruction):
    """Move High Packed Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVHPD(m64, xmm)         [AVX512F]
            * VMOVHPD(m64, xmm)         [AVX]
            * VMOVHPD(xmm, xmm, m64)    [AVX512F]
            * VMOVHPD(xmm, xmm, m64)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVHPD, self).__init__("VMOVHPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_m64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0x17]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVHPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMOVHPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMOVHPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMASKMOVPD(Instruction):
    """Conditional Move Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMASKMOVPD(m128, xmm, xmm)    [AVX]
            * VMASKMOVPD(m256, ymm, ymm)    [AVX]
            * VMASKMOVPD(xmm, xmm, m128)    [AVX]
            * VMASKMOVPD(ymm, ymm, m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMASKMOVPD, self).__init__("VMASKMOVPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VMASKMOVPD\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x2F]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x2F]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VMASKMOVPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVMSKPD(Instruction):
    """Extract Packed Double-Precision Floating-Point Sign Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVMSKPD(r32, xmm)    [AVX]
            * VMOVMSKPD(r32, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVMSKPD, self).__init__("VMOVMSKPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVMSKPD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x50, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_r32(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x50, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        else:
            raise SyntaxError("Invalid operand types: VMOVMSKPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVNTPD(Instruction):
    """Store Packed Double-Precision Floating-Point Values Using Non-Temporal Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVNTPD(m128, xmm)    [AVX512F and AVX512VL]
            * VMOVNTPD(m128, xmm)    [AVX]
            * VMOVNTPD(m256, ymm)    [AVX512F and AVX512VL]
            * VMOVNTPD(m256, ymm)    [AVX]
            * VMOVNTPD(m512, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVNTPD, self).__init__("VMOVNTPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVNTPD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[1].ehcode, op[0].address) + bytearray([0x2B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVNTPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTSD(Instruction):
    """Broadcast Double-Precision Floating-Point Element"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTSD(ymm, m64)              [AVX]
            * VBROADCASTSD(ymm, xmm)              [AVX2]
            * VBROADCASTSD(ymm{k}{z}, xmm/m64)    [AVX512F and AVX512VL]
            * VBROADCASTSD(zmm{k}{z}, xmm/m64)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTSD, self).__init__("VBROADCASTSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTSD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x19]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x19, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x19, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x19, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDDUP(Instruction):
    """Move One Double-FP and Duplicate"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDDUP(xmm, xmm/m64)           [AVX]
            * VMOVDDUP(xmm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VMOVDDUP(ymm, ymm/m256)          [AVX]
            * VMOVDDUP(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVDDUP(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDDUP, self).__init__("VMOVDDUP", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDDUP\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[1], 0, vex3) + bytearray([0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[1], 0, vex3) + bytearray([0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x12, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVDDUP " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXPANDPD(Instruction):
    """Load Sparse Packed Double-Precision Floating-Point Values from Dense Memory"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXPANDPD(xmm{k}{z}, xmm/m128)    [AVX512VL]
            * VEXPANDPD(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VEXPANDPD(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXPANDPD, self).__init__("VEXPANDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VEXPANDPD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x88, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x88]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VEXPANDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCOMPRESSPD(Instruction):
    """Store Sparse Packed Double-Precision Floating-Point Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCOMPRESSPD(m128{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VCOMPRESSPD(m256{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VCOMPRESSPD(m512{k}{z}, zmm)    [AVX512F]
            * VCOMPRESSPD(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VCOMPRESSPD(ymm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VCOMPRESSPD(zmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCOMPRESSPD, self).__init__("VCOMPRESSPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VCOMPRESSPD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x8A, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8A]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VCOMPRESSPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERDPD(Instruction):
    """Gather Packed Double-Precision Floating-Point Values Using Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERDPD(xmm, vm32x, xmm)    [AVX2]
            * VGATHERDPD(xmm{k}, vm32x)      [AVX512F and AVX512VL]
            * VGATHERDPD(ymm, vm32x, ymm)    [AVX2]
            * VGATHERDPD(ymm{k}, vm32x)      [AVX512F and AVX512VL]
            * VGATHERDPD(zmm{k}, vm32y)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERDPD, self).__init__("VGATHERDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGATHERDPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmx(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x92]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VGATHERDPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGATHERDPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERQPD(Instruction):
    """Gather Packed Double-Precision Floating-Point Values Using Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERQPD(xmm, vm64x, xmm)    [AVX2]
            * VGATHERQPD(xmm{k}, vm64x)      [AVX512F and AVX512VL]
            * VGATHERQPD(ymm, vm64y, ymm)    [AVX2]
            * VGATHERQPD(ymm{k}, vm64y)      [AVX512F and AVX512VL]
            * VGATHERQPD(zmm{k}, vm64z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERQPD, self).__init__("VGATHERQPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGATHERQPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmy(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x93]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VGATHERQPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGATHERQPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF0DPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Doubleword Indices Using T0 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF0DPD(vm32y{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF0DPD, self).__init__("VGATHERPF0DPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF0DPD\" requires 1 operands")
        if is_vmyk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(1, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF0DPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF0QPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Quadword Indices Using T0 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF0QPD(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF0QPD, self).__init__("VGATHERPF0QPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF0QPD\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(1, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF0QPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF1DPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Doubleword Indices Using T1 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF1DPD(vm32y{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF1DPD, self).__init__("VGATHERPF1DPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF1DPD\" requires 1 operands")
        if is_vmyk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(2, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF1DPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGATHERPF1QPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Quadword Indices Using T1 Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGATHERPF1QPD(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGATHERPF1QPD, self).__init__("VGATHERPF1QPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VGATHERPF1QPD\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(2, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VGATHERPF1QPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERDPD(Instruction):
    """Scatter Packed Double-Precision Floating-Point Values with Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERDPD(vm32x{k}, xmm)    [AVX512F and AVX512VL]
            * VSCATTERDPD(vm32x{k}, ymm)    [AVX512F and AVX512VL]
            * VSCATTERDPD(vm32y{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERDPD, self).__init__("VSCATTERDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VSCATTERDPD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmyk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA2]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERQPD(Instruction):
    """Scatter Packed Double-Precision Floating-Point Values with Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERQPD(vm64x{k}, xmm)    [AVX512F and AVX512VL]
            * VSCATTERQPD(vm64y{k}, ymm)    [AVX512F and AVX512VL]
            * VSCATTERQPD(vm64z{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERQPD, self).__init__("VSCATTERQPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VSCATTERQPD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA3]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERQPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF0DPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Doubleword Indices Using T0 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF0DPD(vm32y{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF0DPD, self).__init__("VSCATTERPF0DPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF0DPD\" requires 1 operands")
        if is_vmyk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(5, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF0DPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF0QPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Quadword Indices Using T0 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF0QPD(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF0QPD, self).__init__("VSCATTERPF0QPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF0QPD\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(5, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF0QPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF1DPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Doubleword Indices Using T1 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF1DPD(vm32y{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF1DPD, self).__init__("VSCATTERPF1DPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF1DPD\" requires 1 operands")
        if is_vmyk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC6]) + modrm_sib_disp(6, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF1DPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCATTERPF1QPD(Instruction):
    """Sparse Prefetch Packed Double-Precision Floating-Point Data Values with Signed Quadword Indices Using T1 Hint with Intent to Write"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCATTERPF1QPD(vm64z{k})    [AVX512PF]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCATTERPF1QPD, self).__init__("VSCATTERPF1QPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSCATTERPF1QPD\" requires 1 operands")
        if is_vmzk(self.operands[0]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, 0, op[0].address, aaa=op[0].kcode) + bytearray([0xC7]) + modrm_sib_disp(6, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512pf])
        else:
            raise SyntaxError("Invalid operand types: VSCATTERPF1QPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDPS(Instruction):
    """Add Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDPS(xmm, xmm, xmm/m128)              [AVX]
            * VADDPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VADDPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VADDPS(ymm, ymm, ymm/m256)              [AVX]
            * VADDPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VADDPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VADDPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VADDPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VADDPS(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDPS, self).__init__("VADDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VADDPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VHADDPS(Instruction):
    """Packed Single-FP Horizontal Add"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VHADDPS(xmm, xmm, xmm/m128)    [AVX]
            * VHADDPS(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VHADDPS, self).__init__("VHADDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VHADDPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VHADDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSUBPS(Instruction):
    """Subtract Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSUBPS(xmm, xmm, xmm/m128)              [AVX]
            * VSUBPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VSUBPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VSUBPS(ymm, ymm, ymm/m256)              [AVX]
            * VSUBPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VSUBPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VSUBPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VSUBPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VSUBPS(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSUBPS, self).__init__("VSUBPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSUBPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VHSUBPS(Instruction):
    """Packed Single-FP Horizontal Subtract"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VHSUBPS(xmm, xmm, xmm/m128)    [AVX]
            * VHSUBPS(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VHSUBPS, self).__init__("VHSUBPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VHSUBPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VHSUBPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDSUBPS(Instruction):
    """Packed Single-FP Add/Subtract"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDSUBPS(xmm, xmm, xmm/m128)    [AVX]
            * VADDSUBPS(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDSUBPS, self).__init__("VADDSUBPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VADDSUBPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VADDSUBPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMULPS(Instruction):
    """Multiply Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMULPS(xmm, xmm, xmm/m128)              [AVX]
            * VMULPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VMULPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMULPS(ymm, ymm, ymm/m256)              [AVX]
            * VMULPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VMULPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMULPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VMULPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMULPS(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMULPS, self).__init__("VMULPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMULPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDIVPS(Instruction):
    """Divide Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDIVPS(xmm, xmm, xmm/m128)              [AVX]
            * VDIVPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VDIVPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VDIVPS(ymm, ymm, ymm/m256)              [AVX]
            * VDIVPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VDIVPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VDIVPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VDIVPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VDIVPS(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDIVPS, self).__init__("VDIVPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VDIVPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSQRTPS(Instruction):
    """Compute Square Roots of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSQRTPS(xmm, xmm/m128)              [AVX]
            * VSQRTPS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VSQRTPS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VSQRTPS(ymm, ymm/m256)              [AVX]
            * VSQRTPS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VSQRTPS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VSQRTPS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VSQRTPS(zmm{k}{z}, zmm)             [AVX512F]
            * VSQRTPS(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSQRTPS, self).__init__("VSQRTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSQRTPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDPD(Instruction):
    """Add Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDPD(xmm, xmm, xmm/m128)              [AVX]
            * VADDPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VADDPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VADDPD(ymm, ymm, ymm/m256)              [AVX]
            * VADDPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VADDPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VADDPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VADDPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VADDPD(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDPD, self).__init__("VADDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x58, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VADDPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VADDPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VHADDPD(Instruction):
    """Packed Double-FP Horizontal Add"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VHADDPD(xmm, xmm, xmm/m128)    [AVX]
            * VHADDPD(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VHADDPD, self).__init__("VHADDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VHADDPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VHADDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSUBPD(Instruction):
    """Subtract Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSUBPD(xmm, xmm, xmm/m128)              [AVX]
            * VSUBPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VSUBPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VSUBPD(ymm, ymm, ymm/m256)              [AVX]
            * VSUBPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VSUBPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VSUBPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VSUBPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VSUBPD(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSUBPD, self).__init__("VSUBPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSUBPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSUBPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VHSUBPD(Instruction):
    """Packed Double-FP Horizontal Subtract"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VHSUBPD(xmm, xmm, xmm/m128)    [AVX]
            * VHSUBPD(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VHSUBPD, self).__init__("VHSUBPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VHSUBPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VHSUBPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VADDSUBPD(Instruction):
    """Packed Double-FP Add/Subtract"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VADDSUBPD(xmm, xmm, xmm/m128)    [AVX]
            * VADDSUBPD(ymm, ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VADDSUBPD, self).__init__("VADDSUBPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VADDSUBPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VADDSUBPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMULPD(Instruction):
    """Multiply Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMULPD(xmm, xmm, xmm/m128)              [AVX]
            * VMULPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VMULPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMULPD(ymm, ymm, ymm/m256)              [AVX]
            * VMULPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VMULPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMULPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VMULPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMULPD(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMULPD, self).__init__("VMULPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x59, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMULPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMULPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDIVPD(Instruction):
    """Divide Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDIVPD(xmm, xmm, xmm/m128)              [AVX]
            * VDIVPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VDIVPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VDIVPD(ymm, ymm, ymm/m256)              [AVX]
            * VDIVPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VDIVPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VDIVPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VDIVPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VDIVPD(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDIVPD, self).__init__("VDIVPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VDIVPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VDIVPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSQRTPD(Instruction):
    """Compute Square Roots of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSQRTPD(xmm, xmm/m128)              [AVX]
            * VSQRTPD(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VSQRTPD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VSQRTPD(ymm, ymm/m256)              [AVX]
            * VSQRTPD(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VSQRTPD(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VSQRTPD(zmm{k}{z}, m512/m64bcst)    [AVX512F]
            * VSQRTPD(zmm{k}{z}, zmm)             [AVX512F]
            * VSQRTPD(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSQRTPD, self).__init__("VSQRTPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x51]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x51, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSQRTPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSQRTPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VROUNDPS(Instruction):
    """Round Packed Single Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VROUNDPS(xmm, xmm/m128, imm8)    [AVX]
            * VROUNDPS(ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VROUNDPS, self).__init__("VROUNDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VROUNDPS\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[1].address) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VROUNDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRNDSCALEPS(Instruction):
    """Round Packed Single-Precision Floating-Point Values To Include A Given Number Of Fraction Bits"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRNDSCALEPS(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VRNDSCALEPS(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VRNDSCALEPS(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VRNDSCALEPS(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VRNDSCALEPS(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VRNDSCALEPS(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VRNDSCALEPS(zmm{k}{z}, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRNDSCALEPS, self).__init__("VRNDSCALEPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALEPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x08, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[3] & 0xFF])))
                self.in_regs = (False, True, False, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALEPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRNDSCALEPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRANGEPS(Instruction):
    """Range Restriction Calculation For Packed Pairs of Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRANGEPS(xmm{k}{z}, xmm, m128/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VRANGEPS(xmm{k}{z}, xmm, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VRANGEPS(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VRANGEPS(ymm{k}{z}, ymm, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VRANGEPS(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512DQ]
            * VRANGEPS(zmm{k}{z}, zmm, zmm, imm8)             [AVX512DQ]
            * VRANGEPS(zmm{k}{z}, zmm, zmm, {sae}, imm8)      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRANGEPS, self).__init__("VRANGEPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGEPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGEPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRANGEPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMINPS(Instruction):
    """Return Minimum Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMINPS(xmm, xmm, xmm/m128)              [AVX]
            * VMINPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VMINPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMINPS(ymm, ymm, ymm/m256)              [AVX]
            * VMINPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VMINPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMINPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VMINPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMINPS(zmm{k}{z}, zmm, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMINPS, self).__init__("VMINPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMINPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMAXPS(Instruction):
    """Return Maximum Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMAXPS(xmm, xmm, xmm/m128)              [AVX]
            * VMAXPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VMAXPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMAXPS(ymm, ymm, ymm/m256)              [AVX]
            * VMAXPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VMAXPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMAXPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VMAXPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMAXPS(zmm{k}{z}, zmm, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMAXPS, self).__init__("VMAXPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMAXPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VREDUCEPS(Instruction):
    """Perform Reduction Transformation on Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VREDUCEPS(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VREDUCEPS(xmm{k}{z}, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VREDUCEPS(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VREDUCEPS(ymm{k}{z}, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VREDUCEPS(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512DQ]
            * VREDUCEPS(zmm{k}{z}, zmm, imm8)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VREDUCEPS, self).__init__("VREDUCEPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VREDUCEPS\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VREDUCEPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDPPS(Instruction):
    """Dot Product of Packed Single Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDPPS(xmm, xmm, xmm/m128, imm8)    [AVX]
            * VDPPS(ymm, ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDPPS, self).__init__("VDPPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VDPPS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VDPPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETMANTPS(Instruction):
    """Extract Normalized Mantissas from Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETMANTPS(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VGETMANTPS(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VGETMANTPS(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VGETMANTPS(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VGETMANTPS(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VGETMANTPS(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VGETMANTPS(zmm{k}{z}, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETMANTPS, self).__init__("VGETMANTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[3] & 0xFF])))
                self.in_regs = (False, True, False, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETMANTPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETEXPPS(Instruction):
    """Extract Exponents of Packed Single-Precision Floating-Point Values as Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETEXPPS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VGETEXPPS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VGETEXPPS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VGETEXPPS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VGETEXPPS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VGETEXPPS(zmm{k}{z}, zmm)             [AVX512F]
            * VGETEXPPS(zmm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETEXPPS, self).__init__("VGETEXPPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETEXPPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCALEFPS(Instruction):
    """Scale Packed Single-Precision Floating-Point Values With Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCALEFPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VSCALEFPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VSCALEFPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VSCALEFPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VSCALEFPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VSCALEFPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VSCALEFPS(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCALEFPS, self).__init__("VSCALEFPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSCALEFPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFIXUPIMMPS(Instruction):
    """Fix Up Special Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFIXUPIMMPS(xmm{k}{z}, xmm, m128/m32bcst, imm8)    [AVX512VL]
            * VFIXUPIMMPS(xmm{k}{z}, xmm, xmm, imm8)             [AVX512VL]
            * VFIXUPIMMPS(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VFIXUPIMMPS(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VFIXUPIMMPS(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VFIXUPIMMPS(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
            * VFIXUPIMMPS(zmm{k}{z}, zmm, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFIXUPIMMPS, self).__init__("VFIXUPIMMPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (True, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (True, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VFIXUPIMMPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFPCLASSPS(Instruction):
    """Test Class of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFPCLASSPS(k{k}, m128/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VFPCLASSPS(k{k}, m256/m32bcst, imm8)    [AVX512DQ and AVX512VL]
            * VFPCLASSPS(k{k}, m512/m32bcst, imm8)    [AVX512DQ]
            * VFPCLASSPS(k{k}, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VFPCLASSPS(k{k}, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VFPCLASSPS(k{k}, zmm, imm8)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFPCLASSPS, self).__init__("VFPCLASSPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VFPCLASSPS\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, op[0].kcode | 0x48, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, op[0].kcode | 0x08, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, op[0].kcode | 0x28, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VFPCLASSPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCPPS(Instruction):
    """Compute Approximate Reciprocals of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCPPS(xmm, xmm/m128)    [AVX]
            * VRCPPS(ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCPPS, self).__init__("VRCPPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRCPPS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x53, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x53]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x53, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x53]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VRCPPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRTPS(Instruction):
    """Compute Reciprocals of Square Roots of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRTPS(xmm, xmm/m128)    [AVX]
            * VRSQRTPS(ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRTPS, self).__init__("VRSQRTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRSQRTPS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x52, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x52]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x52, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x52]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VRSQRTPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP14PS(Instruction):
    """Compute Approximate Reciprocals of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP14PS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VRCP14PS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VRCP14PS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VRCP14PS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VRCP14PS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VRCP14PS(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP14PS, self).__init__("VRCP14PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRCP14PS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VRCP14PS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT14PS(Instruction):
    """Compute Approximate Reciprocals of Square Roots of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT14PS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VRSQRT14PS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VRSQRT14PS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VRSQRT14PS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VRSQRT14PS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VRSQRT14PS(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT14PS, self).__init__("VRSQRT14PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRSQRT14PS\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VRSQRT14PS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP28PS(Instruction):
    """Approximation to the Reciprocal of Packed Single-Precision Floating-Point Values with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP28PS(zmm{k}{z}, m512/m32bcst)    [AVX512ER]
            * VRCP28PS(zmm{k}{z}, zmm)             [AVX512ER]
            * VRCP28PS(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP28PS, self).__init__("VRCP28PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xCA]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xCA, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRCP28PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xCA, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRCP28PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRCP28PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT28PS(Instruction):
    """Approximation to the Reciprocal Square Root of Packed Single-Precision Floating-Point Values with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT28PS(zmm{k}{z}, m512/m32bcst)    [AVX512ER]
            * VRSQRT28PS(zmm{k}{z}, zmm)             [AVX512ER]
            * VRSQRT28PS(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT28PS, self).__init__("VRSQRT28PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xCC]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xCC, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xCC, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRSQRT28PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXP2PS(Instruction):
    """Approximation to the Exponential 2^x of Packed Single-Precision Floating-Point Values with Less Than 2^-23 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXP2PS(zmm{k}{z}, m512/m32bcst)    [AVX512ER]
            * VEXP2PS(zmm{k}{z}, zmm)             [AVX512ER]
            * VEXP2PS(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXP2PS, self).__init__("VEXP2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC8]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xC8, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VEXP2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xC8, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VEXP2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VEXP2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCMPPS(Instruction):
    """Compare Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCMPPS(k{k}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VCMPPS(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VCMPPS(k{k}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VCMPPS(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VCMPPS(k{k}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VCMPPS(k{k}, zmm, zmm, imm8)             [AVX512F]
            * VCMPPS(k{k}, zmm, zmm, {sae}, imm8)      [AVX512F]
            * VCMPPS(xmm, xmm, xmm/m128, imm8)         [AVX]
            * VCMPPS(ymm, ymm, ymm/m256, imm8)         [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCMPPS, self).__init__("VCMPPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPPS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPPS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCMPPS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VTESTPS(Instruction):
    """Packed Single-Precision Floating-Point Bit Test"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VTESTPS(xmm, xmm/m128)    [AVX]
            * VTESTPS(ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VTESTPS, self).__init__("VTESTPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VTESTPS\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x0E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x0E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x0E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x0E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VTESTPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VROUNDPD(Instruction):
    """Round Packed Double Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VROUNDPD(xmm, xmm/m128, imm8)    [AVX]
            * VROUNDPD(ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VROUNDPD, self).__init__("VROUNDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VROUNDPD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[1].address) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VROUNDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRNDSCALEPD(Instruction):
    """Round Packed Double-Precision Floating-Point Values To Include A Given Number Of Fraction Bits"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRNDSCALEPD(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VRNDSCALEPD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VRNDSCALEPD(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VRNDSCALEPD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VRNDSCALEPD(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VRNDSCALEPD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VRNDSCALEPD(zmm{k}{z}, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRNDSCALEPD, self).__init__("VRNDSCALEPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALEPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x09, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[3] & 0xFF])))
                self.in_regs = (False, True, False, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VRNDSCALEPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRNDSCALEPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRANGEPD(Instruction):
    """Range Restriction Calculation For Packed Pairs of Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRANGEPD(xmm{k}{z}, xmm, m128/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VRANGEPD(xmm{k}{z}, xmm, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VRANGEPD(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VRANGEPD(ymm{k}{z}, ymm, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VRANGEPD(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512DQ]
            * VRANGEPD(zmm{k}{z}, zmm, zmm, imm8)             [AVX512DQ]
            * VRANGEPD(zmm{k}{z}, zmm, zmm, {sae}, imm8)      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRANGEPD, self).__init__("VRANGEPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x50]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGEPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x50, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VRANGEPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRANGEPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMINPD(Instruction):
    """Return Minimum Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMINPD(xmm, xmm, xmm/m128)              [AVX]
            * VMINPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VMINPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMINPD(ymm, ymm, ymm/m256)              [AVX]
            * VMINPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VMINPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMINPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VMINPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMINPD(zmm{k}{z}, zmm, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMINPD, self).__init__("VMINPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMINPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMINPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMAXPD(Instruction):
    """Return Maximum Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMAXPD(xmm, xmm, xmm/m128)              [AVX]
            * VMAXPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VMAXPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VMAXPD(ymm, ymm, ymm/m256)              [AVX]
            * VMAXPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VMAXPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VMAXPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VMAXPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VMAXPD(zmm{k}{z}, zmm, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMAXPD, self).__init__("VMAXPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x5F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VMAXPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VMAXPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VREDUCEPD(Instruction):
    """Perform Reduction Transformation on Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VREDUCEPD(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VREDUCEPD(xmm{k}{z}, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VREDUCEPD(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VREDUCEPD(ymm{k}{z}, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VREDUCEPD(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512DQ]
            * VREDUCEPD(zmm{k}{z}, zmm, imm8)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VREDUCEPD, self).__init__("VREDUCEPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VREDUCEPD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x56, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VREDUCEPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDPPD(Instruction):
    """Dot Product of Packed Double Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDPPD(xmm, xmm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDPPD, self).__init__("VDPPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VDPPD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x41, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x41]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VDPPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETMANTPD(Instruction):
    """Extract Normalized Mantissas from Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETMANTPD(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VGETMANTPD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VGETMANTPD(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VGETMANTPD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VGETMANTPD(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VGETMANTPD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VGETMANTPD(zmm{k}{z}, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETMANTPD, self).__init__("VGETMANTPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x26, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[3] & 0xFF])))
                self.in_regs = (False, True, False, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETMANTPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETMANTPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VGETEXPPD(Instruction):
    """Extract Exponents of Packed Double-Precision Floating-Point Values as Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VGETEXPPD(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VGETEXPPD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VGETEXPPD(ymm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VGETEXPPD(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VGETEXPPD(zmm{k}{z}, m512/m64bcst)    [AVX512F]
            * VGETEXPPD(zmm{k}{z}, zmm)             [AVX512F]
            * VGETEXPPD(zmm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VGETEXPPD, self).__init__("VGETEXPPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x42, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VGETEXPPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VGETEXPPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSCALEFPD(Instruction):
    """Scale Packed Double-Precision Floating-Point Values With Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSCALEFPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VSCALEFPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VSCALEFPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VSCALEFPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VSCALEFPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VSCALEFPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
            * VSCALEFPD(zmm{k}{z}, zmm, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSCALEFPD, self).__init__("VSCALEFPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x2C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VSCALEFPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VSCALEFPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFIXUPIMMPD(Instruction):
    """Fix Up Special Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFIXUPIMMPD(xmm{k}{z}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VFIXUPIMMPD(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VFIXUPIMMPD(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VFIXUPIMMPD(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VFIXUPIMMPD(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VFIXUPIMMPD(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
            * VFIXUPIMMPD(zmm{k}{z}, zmm, zmm, {sae}, imm8)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFIXUPIMMPD, self).__init__("VFIXUPIMMPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (True, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (True, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VFIXUPIMMPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VFIXUPIMMPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VFPCLASSPD(Instruction):
    """Test Class of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VFPCLASSPD(k{k}, m128/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VFPCLASSPD(k{k}, m256/m64bcst, imm8)    [AVX512DQ and AVX512VL]
            * VFPCLASSPD(k{k}, m512/m64bcst, imm8)    [AVX512DQ]
            * VFPCLASSPD(k{k}, xmm, imm8)             [AVX512DQ and AVX512VL]
            * VFPCLASSPD(k{k}, ymm, imm8)             [AVX512DQ and AVX512VL]
            * VFPCLASSPD(k{k}, zmm, imm8)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VFPCLASSPD, self).__init__("VFPCLASSPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VFPCLASSPD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, op[0].kcode | 0x48, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, b=op[1].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, op[0].kcode | 0x08, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, op[0].kcode | 0x28, 0x66, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VFPCLASSPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP14PD(Instruction):
    """Compute Approximate Reciprocals of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP14PD(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VRCP14PD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VRCP14PD(ymm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VRCP14PD(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VRCP14PD(zmm{k}{z}, m512/m64bcst)    [AVX512F]
            * VRCP14PD(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP14PD, self).__init__("VRCP14PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRCP14PD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x4C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VRCP14PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT14PD(Instruction):
    """Compute Approximate Reciprocals of Square Roots of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT14PD(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VRSQRT14PD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VRSQRT14PD(ymm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VRSQRT14PD(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VRSQRT14PD(zmm{k}{z}, m512/m64bcst)    [AVX512F]
            * VRSQRT14PD(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT14PD, self).__init__("VRSQRT14PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VRSQRT14PD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x4E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x4E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VRSQRT14PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRCP28PD(Instruction):
    """Approximation to the Reciprocal of Packed Double-Precision Floating-Point Values with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRCP28PD(zmm{k}{z}, m512/m64bcst)    [AVX512ER]
            * VRCP28PD(zmm{k}{z}, zmm)             [AVX512ER]
            * VRCP28PD(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRCP28PD, self).__init__("VRCP28PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xCA]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xCA, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRCP28PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xCA, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRCP28PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRCP28PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VRSQRT28PD(Instruction):
    """Approximation to the Reciprocal Square Root of Packed Double-Precision Floating-Point Values with Less Than 2^-28 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VRSQRT28PD(zmm{k}{z}, m512/m64bcst)    [AVX512ER]
            * VRSQRT28PD(zmm{k}{z}, zmm)             [AVX512ER]
            * VRSQRT28PD(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VRSQRT28PD, self).__init__("VRSQRT28PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xCC]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xCC, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xCC, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VRSQRT28PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VRSQRT28PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXP2PD(Instruction):
    """Approximation to the Exponential 2^x of Packed Double-Precision Floating-Point Values with Less Than 2^-23 Relative Error"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXP2PD(zmm{k}{z}, m512/m64bcst)    [AVX512ER]
            * VEXP2PD(zmm{k}{z}, zmm)             [AVX512ER]
            * VEXP2PD(zmm{k}{z}, zmm, {sae})      [AVX512ER]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXP2PD, self).__init__("VEXP2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC8]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xC8, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VEXP2PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xC8, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512er])
            else:
                raise SyntaxError("Invalid operand types: VEXP2PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VEXP2PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCMPPD(Instruction):
    """Compare Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCMPPD(k{k}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VCMPPD(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VCMPPD(k{k}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VCMPPD(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VCMPPD(k{k}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VCMPPD(k{k}, zmm, zmm, imm8)             [AVX512F]
            * VCMPPD(k{k}, zmm, zmm, {sae}, imm8)      [AVX512F]
            * VCMPPD(xmm, xmm, xmm/m128, imm8)         [AVX]
            * VCMPPD(ymm, ymm, ymm/m256, imm8)         [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCMPPD, self).__init__("VCMPPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0xC2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPPD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 5:
            if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_sae(self.operands[3]) and is_imm(self.operands[4]):
                if not is_imm8(self.operands[4]):
                    raise ValueError("Argument #4 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0xC2, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[4] & 0xFF])))
                self.in_regs = (False, True, True, False, False)
                self.out_regs = (True, False, False, False, False)
                self.out_operands = (True, False, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCMPPD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCMPPD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VTESTPD(Instruction):
    """Packed Double-Precision Floating-Point Bit Test"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VTESTPD(xmm, xmm/m128)    [AVX]
            * VTESTPD(ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VTESTPD, self).__init__("VTESTPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VTESTPD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x0F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x0F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VTESTPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VANDPS(Instruction):
    """Bitwise Logical AND of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VANDPS(xmm, xmm, xmm/m128)              [AVX]
            * VANDPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VANDPS(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VANDPS(ymm, ymm, ymm/m256)              [AVX]
            * VANDPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512DQ and AVX512VL]
            * VANDPS(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VANDPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512DQ]
            * VANDPS(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VANDPS, self).__init__("VANDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VANDPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VANDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VANDNPS(Instruction):
    """Bitwise Logical AND NOT of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VANDNPS(xmm, xmm, xmm/m128)              [AVX]
            * VANDNPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VANDNPS(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VANDNPS(ymm, ymm, ymm/m256)              [AVX]
            * VANDNPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512DQ and AVX512VL]
            * VANDNPS(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VANDNPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512DQ]
            * VANDNPS(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VANDNPS, self).__init__("VANDNPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VANDNPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VANDNPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VORPS(Instruction):
    """Bitwise Logical OR of Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VORPS(xmm, xmm, xmm/m128)              [AVX]
            * VORPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VORPS(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VORPS(ymm, ymm, ymm/m256)              [AVX]
            * VORPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512DQ and AVX512VL]
            * VORPS(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VORPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512DQ]
            * VORPS(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VORPS, self).__init__("VORPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VORPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VORPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VXORPS(Instruction):
    """Bitwise Logical XOR for Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VXORPS(xmm, xmm, xmm/m128)              [AVX]
            * VXORPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VXORPS(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VXORPS(ymm, ymm, ymm/m256)              [AVX]
            * VXORPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512DQ and AVX512VL]
            * VXORPS(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VXORPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512DQ]
            * VXORPS(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VXORPS, self).__init__("VXORPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VXORPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VXORPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDPS(Instruction):
    """ Blend Packed Single Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDPS(xmm, xmm, xmm/m128, imm8)    [AVX]
            * VBLENDPS(ymm, ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDPS, self).__init__("VBLENDPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VBLENDPS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VBLENDPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDVPS(Instruction):
    """ Variable Blend Packed Single Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDVPS(xmm, xmm, xmm/m128, xmm)    [AVX]
            * VBLENDVPS(ymm, ymm, ymm/m256, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDVPS, self).__init__("VBLENDVPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VBLENDVPS\" requires 4 operands")
        self.in_regs = (False, True, True, True)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x4A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x4A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
        else:
            raise SyntaxError("Invalid operand types: VBLENDVPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDMPS(Instruction):
    """Blend Packed Single-Precision Floating-Point Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDMPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VBLENDMPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VBLENDMPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VBLENDMPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VBLENDMPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VBLENDMPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDMPS, self).__init__("VBLENDMPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VBLENDMPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBLENDMPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VANDPD(Instruction):
    """Bitwise Logical AND of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VANDPD(xmm, xmm, xmm/m128)              [AVX]
            * VANDPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VANDPD(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VANDPD(ymm, ymm, ymm/m256)              [AVX]
            * VANDPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VANDPD(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VANDPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512DQ]
            * VANDPD(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VANDPD, self).__init__("VANDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VANDPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x54]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x54, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VANDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VANDNPD(Instruction):
    """Bitwise Logical AND NOT of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VANDNPD(xmm, xmm, xmm/m128)              [AVX]
            * VANDNPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VANDNPD(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VANDNPD(ymm, ymm, ymm/m256)              [AVX]
            * VANDNPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VANDNPD(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VANDNPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512DQ]
            * VANDNPD(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VANDNPD, self).__init__("VANDNPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VANDNPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x55, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VANDNPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VORPD(Instruction):
    """Bitwise Logical OR of Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VORPD(xmm, xmm, xmm/m128)              [AVX]
            * VORPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VORPD(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VORPD(ymm, ymm, ymm/m256)              [AVX]
            * VORPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VORPD(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VORPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512DQ]
            * VORPD(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VORPD, self).__init__("VORPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VORPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x56]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x56, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VORPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VXORPD(Instruction):
    """Bitwise Logical XOR for Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VXORPD(xmm, xmm, xmm/m128)              [AVX]
            * VXORPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VXORPD(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VXORPD(ymm, ymm, ymm/m256)              [AVX]
            * VXORPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VXORPD(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VXORPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512DQ]
            * VXORPD(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VXORPD, self).__init__("VXORPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VXORPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x57]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x57, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VXORPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDPD(Instruction):
    """Blend Packed Double Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDPD(xmm, xmm, xmm/m128, imm8)    [AVX]
            * VBLENDPD(ymm, ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDPD, self).__init__("VBLENDPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VBLENDPD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VBLENDPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDVPD(Instruction):
    """ Variable Blend Packed Double Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDVPD(xmm, xmm, xmm/m128, xmm)    [AVX]
            * VBLENDVPD(ymm, ymm, ymm/m256, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDVPD, self).__init__("VBLENDVPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VBLENDVPD\" requires 4 operands")
        self.in_regs = (False, True, True, True)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x4B, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x4B, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
        else:
            raise SyntaxError("Invalid operand types: VBLENDVPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBLENDMPD(Instruction):
    """Blend Packed Double-Precision Floating-Point Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBLENDMPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VBLENDMPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VBLENDMPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VBLENDMPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VBLENDMPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VBLENDMPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBLENDMPD, self).__init__("VBLENDMPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VBLENDMPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBLENDMPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUNPCKLPS(Instruction):
    """Unpack and Interleave Low Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUNPCKLPS(xmm, xmm, xmm/m128)              [AVX]
            * VUNPCKLPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VUNPCKLPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VUNPCKLPS(ymm, ymm, ymm/m256)              [AVX]
            * VUNPCKLPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VUNPCKLPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VUNPCKLPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VUNPCKLPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUNPCKLPS, self).__init__("VUNPCKLPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VUNPCKLPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VUNPCKLPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUNPCKHPS(Instruction):
    """Unpack and Interleave High Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUNPCKHPS(xmm, xmm, xmm/m128)              [AVX]
            * VUNPCKHPS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VUNPCKHPS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VUNPCKHPS(ymm, ymm, ymm/m256)              [AVX]
            * VUNPCKHPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VUNPCKHPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VUNPCKHPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VUNPCKHPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUNPCKHPS, self).__init__("VUNPCKHPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VUNPCKHPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VUNPCKHPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVLHPS(Instruction):
    """Move Packed Single-Precision Floating-Point Values Low to High"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVLHPS(xmm, xmm, xmm)    [AVX512F]
            * VMOVLHPS(xmm, xmm, xmm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVLHPS, self).__init__("VMOVLHPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VMOVLHPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVLHPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVHLPS(Instruction):
    """Move Packed Single-Precision Floating-Point Values High to Low"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVHLPS(xmm, xmm, xmm)    [AVX512F]
            * VMOVHLPS(xmm, xmm, xmm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVHLPS, self).__init__("VMOVHLPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VMOVHLPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x12, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x12, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVHLPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFPS(Instruction):
    """Shuffle Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFPS(xmm, xmm, xmm/m128, imm8)              [AVX]
            * VSHUFPS(xmm{k}{z}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFPS(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VSHUFPS(ymm, ymm, ymm/m256, imm8)              [AVX]
            * VSHUFPS(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFPS(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFPS(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VSHUFPS(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFPS, self).__init__("VSHUFPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFPS\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUNPCKLPD(Instruction):
    """Unpack and Interleave Low Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUNPCKLPD(xmm, xmm, xmm/m128)              [AVX]
            * VUNPCKLPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VUNPCKLPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VUNPCKLPD(ymm, ymm, ymm/m256)              [AVX]
            * VUNPCKLPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VUNPCKLPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VUNPCKLPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VUNPCKLPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUNPCKLPD, self).__init__("VUNPCKLPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VUNPCKLPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VUNPCKLPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VUNPCKHPD(Instruction):
    """Unpack and Interleave High Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VUNPCKHPD(xmm, xmm, xmm/m128)              [AVX]
            * VUNPCKHPD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VUNPCKHPD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VUNPCKHPD(ymm, ymm, ymm/m256)              [AVX]
            * VUNPCKHPD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VUNPCKHPD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VUNPCKHPD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VUNPCKHPD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VUNPCKHPD, self).__init__("VUNPCKHPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VUNPCKHPD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VUNPCKHPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFPD(Instruction):
    """Shuffle Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFPD(xmm, xmm, xmm/m128, imm8)              [AVX]
            * VSHUFPD(xmm{k}{z}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFPD(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VSHUFPD(ymm, ymm, ymm/m256, imm8)              [AVX]
            * VSHUFPD(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFPD(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFPD(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VSHUFPD(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFPD, self).__init__("VSHUFPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFPD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xC6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xC6, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMPS(Instruction):
    """Permute Single-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMPS(ymm, ymm, ymm/m256)              [AVX2]
            * VPERMPS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMPS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMPS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMPS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMPS, self).__init__("VPERMPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMPS\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMILPS(Instruction):
    """Permute Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMILPS(xmm, xmm, xmm/m128)               [AVX]
            * VPERMILPS(xmm, xmm/m128, imm8)              [AVX]
            * VPERMILPS(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMILPS(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPERMILPS(xmm{k}{z}, xmm, m128/m32bcst)     [AVX512F and AVX512VL]
            * VPERMILPS(xmm{k}{z}, xmm, xmm)              [AVX512F and AVX512VL]
            * VPERMILPS(ymm, ymm, ymm/m256)               [AVX]
            * VPERMILPS(ymm, ymm/m256, imm8)              [AVX]
            * VPERMILPS(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMILPS(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPERMILPS(ymm{k}{z}, ymm, m256/m32bcst)     [AVX512F and AVX512VL]
            * VPERMILPS(ymm{k}{z}, ymm, ymm)              [AVX512F and AVX512VL]
            * VPERMILPS(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPERMILPS(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPERMILPS(zmm{k}{z}, zmm, m512/m32bcst)     [AVX512F]
            * VPERMILPS(zmm{k}{z}, zmm, zmm)              [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMILPS, self).__init__("VPERMILPS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMILPS\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x04, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x04, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[1].address) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x04, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x04, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x04, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x0C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMILPS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2PS(Instruction):
    """Full Permute of Single-Precision Floating-Point Values From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2PS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPERMT2PS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMT2PS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMT2PS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMT2PS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMT2PS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2PS, self).__init__("VPERMT2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2PS\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2PS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2PS(Instruction):
    """Full Permute of Single-Precision Floating-Point Values From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2PS(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPERMI2PS(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMI2PS(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMI2PS(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMI2PS(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMI2PS(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2PS, self).__init__("VPERMI2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2PS\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2PS " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMPD(Instruction):
    """Permute Double-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMPD(ymm, ymm/m256, imm8)              [AVX2]
            * VPERMPD(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMPD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPERMPD(ymm{k}{z}, ymm, m256/m64bcst)     [AVX512F and AVX512VL]
            * VPERMPD(ymm{k}{z}, ymm, ymm)              [AVX512F and AVX512VL]
            * VPERMPD(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPERMPD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPERMPD(zmm{k}{z}, zmm, m512/m64bcst)     [AVX512F]
            * VPERMPD(zmm{k}{z}, zmm, zmm)              [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMPD, self).__init__("VPERMPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMPD\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFD, 0x01, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x85, op[0].hcode, op[1].address) + bytearray([0x01]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x01]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x01, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x01]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x16]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x01, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x16, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMILPD(Instruction):
    """Permute Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMILPD(xmm, xmm, xmm/m128)               [AVX]
            * VPERMILPD(xmm, xmm/m128, imm8)              [AVX]
            * VPERMILPD(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMILPD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPERMILPD(xmm{k}{z}, xmm, m128/m64bcst)     [AVX512F and AVX512VL]
            * VPERMILPD(xmm{k}{z}, xmm, xmm)              [AVX512F and AVX512VL]
            * VPERMILPD(ymm, ymm, ymm/m256)               [AVX]
            * VPERMILPD(ymm, ymm/m256, imm8)              [AVX]
            * VPERMILPD(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMILPD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPERMILPD(ymm{k}{z}, ymm, m256/m64bcst)     [AVX512F and AVX512VL]
            * VPERMILPD(ymm{k}{z}, ymm, ymm)              [AVX512F and AVX512VL]
            * VPERMILPD(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPERMILPD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPERMILPD(zmm{k}{z}, zmm, m512/m64bcst)     [AVX512F]
            * VPERMILPD(zmm{k}{z}, zmm, zmm)              [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMILPD, self).__init__("VPERMILPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMILPD\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x05, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x05, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[1].address) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x05, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x05, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x0D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x05, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x0D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMILPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2PD(Instruction):
    """Full Permute of Double-Precision Floating-Point Values From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2PD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPERMT2PD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMT2PD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPERMT2PD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMT2PD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPERMT2PD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2PD, self).__init__("VPERMT2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2PD\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2PD(Instruction):
    """Full Permute of Double-Precision Floating-Point Values From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2PD(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPERMI2PD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMI2PD(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPERMI2PD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMI2PD(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPERMI2PD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2PD, self).__init__("VPERMI2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2PD\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x77]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x77, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVD(Instruction):
    """Move Doubleword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVD(r32/m32, xmm)    [AVX512F]
            * VMOVD(r32/m32, xmm)    [AVX]
            * VMOVD(xmm, r32/m32)    [AVX512F]
            * VMOVD(xmm, r32/m32)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVD, self).__init__("VMOVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[1].hcode, op[0], 0, vex3) + bytearray([0x7E, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x6E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x6E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m32(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x7E]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7D, 0x08, 0x7E, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, 0x08, 0x6E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address) + bytearray([0x6E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m32(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x7E]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVQ(Instruction):
    """Move Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVQ(r64/m64, xmm)    [AVX512F]
            * VMOVQ(r64/m64, xmm)    [AVX]
            * VMOVQ(xmm, r64/m64)    [AVX512F]
            * VMOVQ(xmm, r64/m64)    [AVX]
            * VMOVQ(xmm, xmm)        [AVX512F]
            * VMOVQ(xmm, xmm)        [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVQ, self).__init__("VMOVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVQ\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_r64(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0xF9, 0x7E, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_r64(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xF9, 0x6E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x7E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[1].hcode, op[0], 0, vex3) + bytearray([0xD6, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x81, op[0].hcode, op[1].address) + bytearray([0x6E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m64(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0xD6]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x81, op[1].hcode, op[0].address) + bytearray([0x7E]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, 0x08, 0x7E, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_r64(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, 0x08, 0x6E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x08, 0x7E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, 0x08, 0xD6, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address) + bytearray([0x6E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0x7E]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0xD6]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQA(Instruction):
    """Move Aligned Double Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQA(xmm, xmm/m128)    [AVX]
            * VMOVDQA(xmm/m128, xmm)    [AVX]
            * VMOVDQA(ymm, ymm/m256)    [AVX]
            * VMOVDQA(ymm/m256, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQA, self).__init__("VMOVDQA", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQA\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[1].hcode, op[0], 0, vex3) + bytearray([0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[1].hcode, op[0], 0, vex3) + bytearray([0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
        else:
            raise SyntaxError("Invalid operand types: VMOVDQA " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQA32(Instruction):
    """Move Aligned Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQA32(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVDQA32(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVDQA32(m512{k}{z}, zmm)        [AVX512F]
            * VMOVDQA32(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVDQA32(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVDQA32(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQA32, self).__init__("VMOVDQA32", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQA32\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQA32 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQA64(Instruction):
    """Move Aligned Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQA64(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVDQA64(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVDQA64(m512{k}{z}, zmm)        [AVX512F]
            * VMOVDQA64(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVDQA64(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVDQA64(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQA64, self).__init__("VMOVDQA64", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQA64\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQA64 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQU(Instruction):
    """Move Unaligned Double Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQU(xmm, xmm/m128)    [AVX]
            * VMOVDQU(xmm/m128, xmm)    [AVX]
            * VMOVDQU(ymm, ymm/m256)    [AVX]
            * VMOVDQU(ymm/m256, ymm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQU, self).__init__("VMOVDQU", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQU\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[1].hcode, op[0], 0, vex3) + bytearray([0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[1].hcode, op[0], 0, vex3) + bytearray([0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[1].hcode, op[0].address, 0, vex3) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
        else:
            raise SyntaxError("Invalid operand types: VMOVDQU " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQU8(Instruction):
    """Move Unaligned Byte Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQU8(m128{k}{z}, xmm)        [AVX512BW and AVX512VL]
            * VMOVDQU8(m256{k}{z}, ymm)        [AVX512BW and AVX512VL]
            * VMOVDQU8(m512{k}{z}, zmm)        [AVX512BW]
            * VMOVDQU8(xmm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VMOVDQU8(ymm{k}{z}, ymm/m256)    [AVX512BW and AVX512VL]
            * VMOVDQU8(zmm{k}{z}, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQU8, self).__init__("VMOVDQU8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQU8\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQU8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQU16(Instruction):
    """Move Unaligned Word Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQU16(m128{k}{z}, xmm)        [AVX512BW and AVX512VL]
            * VMOVDQU16(m256{k}{z}, ymm)        [AVX512BW and AVX512VL]
            * VMOVDQU16(m512{k}{z}, zmm)        [AVX512BW]
            * VMOVDQU16(xmm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VMOVDQU16(ymm{k}{z}, ymm/m256)    [AVX512BW and AVX512VL]
            * VMOVDQU16(zmm{k}{z}, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQU16, self).__init__("VMOVDQU16", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQU16\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQU16 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQU32(Instruction):
    """Move Unaligned Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQU32(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVDQU32(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVDQU32(m512{k}{z}, zmm)        [AVX512F]
            * VMOVDQU32(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVDQU32(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVDQU32(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQU32, self).__init__("VMOVDQU32", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQU32\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQU32 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVDQU64(Instruction):
    """Move Unaligned Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVDQU64(m128{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VMOVDQU64(m256{k}{z}, ymm)        [AVX512F and AVX512VL]
            * VMOVDQU64(m512{k}{z}, zmm)        [AVX512F]
            * VMOVDQU64(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VMOVDQU64(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VMOVDQU64(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVDQU64, self).__init__("VMOVDQU64", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVDQU64\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7F]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x6F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7F, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x6F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVDQU64 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VLDDQU(Instruction):
    """Load Unaligned Integer 128 Bits"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VLDDQU(xmm, m128)    [AVX]
            * VLDDQU(ymm, m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VLDDQU, self).__init__("VLDDQU", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VLDDQU\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xF0]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xF0]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VLDDQU " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTB(Instruction):
    """Broadcast Byte Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTB(xmm, xmm/m8)          [AVX2]
            * VPBROADCASTB(xmm{k}{z}, r32)       [AVX512BW and AVX512VL]
            * VPBROADCASTB(xmm{k}{z}, xmm/m8)    [AVX512BW and AVX512VL]
            * VPBROADCASTB(ymm, xmm/m8)          [AVX2]
            * VPBROADCASTB(ymm{k}{z}, r32)       [AVX512BW and AVX512VL]
            * VPBROADCASTB(ymm{k}{z}, xmm/m8)    [AVX512BW and AVX512VL]
            * VPBROADCASTB(zmm{k}{z}, r32)       [AVX512BW]
            * VPBROADCASTB(zmm{k}{z}, xmm/m8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTB, self).__init__("VPBROADCASTB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTB\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_m8(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m8(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m8(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=1)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m8(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=1)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m8(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=1)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTW(Instruction):
    """Broadcast Word Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTW(xmm, xmm/m16)          [AVX2]
            * VPBROADCASTW(xmm{k}{z}, r32)        [AVX512BW and AVX512VL]
            * VPBROADCASTW(xmm{k}{z}, xmm/m16)    [AVX512BW and AVX512VL]
            * VPBROADCASTW(ymm, xmm/m16)          [AVX2]
            * VPBROADCASTW(ymm{k}{z}, r32)        [AVX512BW and AVX512VL]
            * VPBROADCASTW(ymm{k}{z}, xmm/m16)    [AVX512BW and AVX512VL]
            * VPBROADCASTW(zmm{k}{z}, r32)        [AVX512BW]
            * VPBROADCASTW(zmm{k}{z}, xmm/m16)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTW, self).__init__("VPBROADCASTW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTW\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=2)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=2)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=2)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTD(Instruction):
    """Broadcast Doubleword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTD(xmm, xmm/m32)          [AVX2]
            * VPBROADCASTD(xmm{k}{z}, r32/m32)    [AVX512F and AVX512VL]
            * VPBROADCASTD(xmm{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VPBROADCASTD(ymm, xmm/m32)          [AVX2]
            * VPBROADCASTD(ymm{k}{z}, r32/m32)    [AVX512F and AVX512VL]
            * VPBROADCASTD(ymm{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VPBROADCASTD(zmm{k}{z}, r32/m32)    [AVX512F]
            * VPBROADCASTD(zmm{k}{z}, xmm)        [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTD, self).__init__("VPBROADCASTD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x58, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x58, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x58, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_r32(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x58, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x58, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x58]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTQ(Instruction):
    """Broadcast Quadword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTQ(xmm, xmm/m64)          [AVX2]
            * VPBROADCASTQ(xmm{k}{z}, r64/m64)    [AVX512F and AVX512VL]
            * VPBROADCASTQ(xmm{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VPBROADCASTQ(ymm, xmm/m64)          [AVX2]
            * VPBROADCASTQ(ymm{k}{z}, r64/m64)    [AVX512F and AVX512VL]
            * VPBROADCASTQ(ymm{k}{z}, xmm)        [AVX512F and AVX512VL]
            * VPBROADCASTQ(zmm{k}{z}, r64/m64)    [AVX512F]
            * VPBROADCASTQ(zmm{k}{z}, xmm)        [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTQ, self).__init__("VPBROADCASTQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_r64(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_r64(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_r64(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXPANDD(Instruction):
    """Load Sparse Packed Doubleword Integer Values from Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXPANDD(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPEXPANDD(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VPEXPANDD(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXPANDD, self).__init__("VPEXPANDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPEXPANDD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPEXPANDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXPANDQ(Instruction):
    """Load Sparse Packed Quadword Integer Values from Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXPANDQ(xmm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPEXPANDQ(ymm{k}{z}, ymm/m256)    [AVX512F and AVX512VL]
            * VPEXPANDQ(zmm{k}{z}, zmm/m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXPANDQ, self).__init__("VPEXPANDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPEXPANDQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x89, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x89]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPEXPANDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCOMPRESSD(Instruction):
    """Store Sparse Packed Doubleword Integer Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCOMPRESSD(m128{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPCOMPRESSD(m256{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPCOMPRESSD(m512{k}{z}, zmm)    [AVX512F]
            * VPCOMPRESSD(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPCOMPRESSD(ymm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPCOMPRESSD(zmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCOMPRESSD, self).__init__("VPCOMPRESSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPCOMPRESSD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCOMPRESSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCOMPRESSQ(Instruction):
    """Store Sparse Packed Quadword Integer Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCOMPRESSQ(m128{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPCOMPRESSQ(m256{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPCOMPRESSQ(m512{k}{z}, zmm)    [AVX512F]
            * VPCOMPRESSQ(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPCOMPRESSQ(ymm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPCOMPRESSQ(zmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCOMPRESSQ, self).__init__("VPCOMPRESSQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPCOMPRESSQ\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m512kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x8B, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCOMPRESSQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMASKMOVD(Instruction):
    """Conditional Move Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMASKMOVD(m128, xmm, xmm)    [AVX2]
            * VPMASKMOVD(m256, ymm, ymm)    [AVX2]
            * VPMASKMOVD(xmm, xmm, m128)    [AVX2]
            * VPMASKMOVD(ymm, ymm, m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMASKMOVD, self).__init__("VPMASKMOVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMASKMOVD\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x8C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x8C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x8E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x8E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VPMASKMOVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMASKMOVQ(Instruction):
    """Conditional Move Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMASKMOVQ(m128, xmm, xmm)    [AVX2]
            * VPMASKMOVQ(m256, ymm, ymm)    [AVX2]
            * VPMASKMOVQ(xmm, xmm, m128)    [AVX2]
            * VPMASKMOVQ(ymm, ymm, m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMASKMOVQ, self).__init__("VPMASKMOVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMASKMOVQ\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x8C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x8C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x8E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[2].hcode, op[0].address, op[1].hlcode) + bytearray([0x8E]) + modrm_sib_disp(op[2].lcode, op[0].address, sib, min_disp)))
            self.in_regs = (True, True, True)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VPMASKMOVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMASKMOVDQU(Instruction):
    """Store Selected Bytes of Double Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMASKMOVDQU(xmm, xmm)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMASKMOVDQU, self).__init__("VMASKMOVDQU", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMASKMOVDQU\" requires 2 operands")
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0xF7, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self._implicit_in_regs = {7: 15}
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.out_operands = (False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        else:
            raise SyntaxError("Invalid operand types: VMASKMOVDQU " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVNTDQ(Instruction):
    """Store Double Quadword Using Non-Temporal Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVNTDQ(m128, xmm)    [AVX512F and AVX512VL]
            * VMOVNTDQ(m128, xmm)    [AVX]
            * VMOVNTDQ(m256, ymm)    [AVX512F and AVX512VL]
            * VMOVNTDQ(m256, ymm)    [AVX]
            * VMOVNTDQ(m512, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVNTDQ, self).__init__("VMOVNTDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVNTDQ\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_m128(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[1].hcode, op[0].address, 0, vex3) + bytearray([0xE7]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m256(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[1].hcode, op[0].address, 0, vex3) + bytearray([0xE7]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m512(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[1].ehcode, op[0].address) + bytearray([0xE7]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0xE7]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m256(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[1].ehcode, op[0].address) + bytearray([0xE7]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVNTDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMOVNTDQA(Instruction):
    """Load Double Quadword Non-Temporal Aligned Hint"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMOVNTDQA(xmm, m128)    [AVX512F and AVX512VL]
            * VMOVNTDQA(xmm, m128)    [AVX]
            * VMOVNTDQA(ymm, m256)    [AVX2]
            * VMOVNTDQA(ymm, m256)    [AVX512F and AVX512VL]
            * VMOVNTDQA(zmm, m512)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMOVNTDQA, self).__init__("VMOVNTDQA", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VMOVNTDQA\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmm(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_evex_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_evex_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VMOVNTDQA " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXBW(Instruction):
    """Move Packed Byte Integers to Word Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXBW(xmm, xmm/m64)           [AVX]
            * VPMOVSXBW(xmm{k}{z}, xmm/m64)     [AVX512BW and AVX512VL]
            * VPMOVSXBW(ymm, xmm/m128)          [AVX2]
            * VPMOVSXBW(ymm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMOVSXBW(zmm{k}{z}, ymm/m256)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXBW, self).__init__("VPMOVSXBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXBW\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x20, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x20, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x20, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x20, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x20, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXBD(Instruction):
    """Move Packed Byte Integers to Doubleword Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXBD(xmm, xmm/m32)           [AVX]
            * VPMOVSXBD(xmm{k}{z}, xmm/m32)     [AVX512F and AVX512VL]
            * VPMOVSXBD(ymm, xmm/m64)           [AVX2]
            * VPMOVSXBD(ymm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVSXBD(zmm{k}{z}, xmm/m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXBD, self).__init__("VPMOVSXBD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXBD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x21, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x21, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x21, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x21, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x21, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXBD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXBQ(Instruction):
    """Move Packed Byte Integers to Quadword Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXBQ(xmm, xmm/m16)          [AVX]
            * VPMOVSXBQ(xmm{k}{z}, xmm/m16)    [AVX512F and AVX512VL]
            * VPMOVSXBQ(ymm, xmm/m32)          [AVX2]
            * VPMOVSXBQ(ymm{k}{z}, xmm/m32)    [AVX512F and AVX512VL]
            * VPMOVSXBQ(zmm{k}{z}, xmm/m64)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXBQ, self).__init__("VPMOVSXBQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXBQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x22, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x22, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x22, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x22, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x22, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=2)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXBQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXWD(Instruction):
    """Move Packed Word Integers to Doubleword Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXWD(xmm, xmm/m64)           [AVX]
            * VPMOVSXWD(xmm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVSXWD(ymm, xmm/m128)          [AVX2]
            * VPMOVSXWD(ymm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPMOVSXWD(zmm{k}{z}, ymm/m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXWD, self).__init__("VPMOVSXWD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXWD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x23, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x23, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x23, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x23, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x23, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXWD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXWQ(Instruction):
    """Move Packed Word Integers to Quadword Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXWQ(xmm, xmm/m32)           [AVX]
            * VPMOVSXWQ(xmm{k}{z}, xmm/m32)     [AVX512F and AVX512VL]
            * VPMOVSXWQ(ymm, xmm/m64)           [AVX2]
            * VPMOVSXWQ(ymm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVSXWQ(zmm{k}{z}, xmm/m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXWQ, self).__init__("VPMOVSXWQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXWQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x24, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x24]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x24, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x24]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x24, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x24, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x24, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXWQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSXDQ(Instruction):
    """Move Packed Doubleword Integers to Quadword Integers with Sign Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSXDQ(xmm, xmm/m64)           [AVX]
            * VPMOVSXDQ(xmm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVSXDQ(ymm, xmm/m128)          [AVX2]
            * VPMOVSXDQ(ymm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPMOVSXDQ(zmm{k}{z}, ymm/m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSXDQ, self).__init__("VPMOVSXDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSXDQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x25, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x25, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x25, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x25, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x25, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSXDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXBW(Instruction):
    """Move Packed Byte Integers to Word Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXBW(xmm, xmm/m64)           [AVX]
            * VPMOVZXBW(xmm{k}{z}, xmm/m64)     [AVX512BW and AVX512VL]
            * VPMOVZXBW(ymm, xmm/m128)          [AVX2]
            * VPMOVZXBW(ymm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMOVZXBW(zmm{k}{z}, ymm/m256)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXBW, self).__init__("VPMOVZXBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXBW\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x30, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x30]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x30, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x30]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x30, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x30, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x30, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXBD(Instruction):
    """Move Packed Byte Integers to Doubleword Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXBD(xmm, xmm/m32)           [AVX]
            * VPMOVZXBD(xmm{k}{z}, xmm/m32)     [AVX512F and AVX512VL]
            * VPMOVZXBD(ymm, xmm/m64)           [AVX2]
            * VPMOVZXBD(ymm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVZXBD(zmm{k}{z}, xmm/m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXBD, self).__init__("VPMOVZXBD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXBD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x31, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x31]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x31, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x31]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x31, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x31, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x31, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXBD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXBQ(Instruction):
    """Move Packed Byte Integers to Quadword Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXBQ(xmm, xmm/m16)          [AVX]
            * VPMOVZXBQ(xmm{k}{z}, xmm/m16)    [AVX512F and AVX512VL]
            * VPMOVZXBQ(ymm, xmm/m32)          [AVX2]
            * VPMOVZXBQ(ymm{k}{z}, xmm/m32)    [AVX512F and AVX512VL]
            * VPMOVZXBQ(zmm{k}{z}, xmm/m64)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXBQ, self).__init__("VPMOVZXBQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXBQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x32, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x32]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x32, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x32]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x32, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x32, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x32, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m16(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=2)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXBQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXWD(Instruction):
    """Move Packed Word Integers to Doubleword Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXWD(xmm, xmm/m64)           [AVX]
            * VPMOVZXWD(xmm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVZXWD(ymm, xmm/m128)          [AVX2]
            * VPMOVZXWD(ymm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPMOVZXWD(zmm{k}{z}, ymm/m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXWD, self).__init__("VPMOVZXWD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXWD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x33, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x33]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x33, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x33]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x33, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x33, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x33, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXWD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXWQ(Instruction):
    """Move Packed Word Integers to Quadword Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXWQ(xmm, xmm/m32)           [AVX]
            * VPMOVZXWQ(xmm{k}{z}, xmm/m32)     [AVX512F and AVX512VL]
            * VPMOVZXWQ(ymm, xmm/m64)           [AVX2]
            * VPMOVZXWQ(ymm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVZXWQ(zmm{k}{z}, xmm/m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXWQ, self).__init__("VPMOVZXWQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXWQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x34, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x34]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x34, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x34]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x34, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x34, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x34, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m32(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXWQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVZXDQ(Instruction):
    """Move Packed Doubleword Integers to Quadword Integers with Zero Extension"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVZXDQ(xmm, xmm/m64)           [AVX]
            * VPMOVZXDQ(xmm{k}{z}, xmm/m64)     [AVX512F and AVX512VL]
            * VPMOVZXDQ(ymm, xmm/m128)          [AVX2]
            * VPMOVZXDQ(ymm{k}{z}, xmm/m128)    [AVX512F and AVX512VL]
            * VPMOVZXDQ(zmm{k}{z}, ymm/m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVZXDQ, self).__init__("VPMOVZXDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVZXDQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x35, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x35]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x35, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x35]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x35, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x35, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x35, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVZXDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVWB(Instruction):
    """Down Convert Packed Word Values to Byte Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVWB(m128{k}{z}, ymm)    [AVX512BW and AVX512VL]
            * VPMOVWB(m256{k}{z}, zmm)    [AVX512BW]
            * VPMOVWB(m64{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVWB(xmm{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVWB(xmm{k}{z}, ymm)     [AVX512BW and AVX512VL]
            * VPMOVWB(ymm{k}{z}, zmm)     [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVWB, self).__init__("VPMOVWB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVWB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x30, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x30, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x30, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x30]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVWB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVDB(Instruction):
    """Down Convert Packed Doubleword Values to Byte Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVDB(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVDB(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVDB(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVDB(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVDB(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVDB(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVDB, self).__init__("VPMOVDB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVDB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x31, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x31, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x31, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x31]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVDB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVDW(Instruction):
    """Down Convert Packed Doubleword Values to Word Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVDW(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVDW(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVDW(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVDW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVDW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVDW(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVDW, self).__init__("VPMOVDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVDW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x33, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x33, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x33, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x33]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVQB(Instruction):
    """Down Convert Packed Quadword Values to Byte Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVQB(m16{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVQB(m32{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVQB(m64{k}{z}, zmm)    [AVX512F]
            * VPMOVQB(xmm{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVQB(xmm{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVQB(xmm{k}{z}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVQB, self).__init__("VPMOVQB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVQB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x32, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x32, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m16kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=2)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x32, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x32]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVQB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVQW(Instruction):
    """Down Convert Packed Quadword Values to Word Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVQW(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVQW(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVQW(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVQW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVQW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVQW(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVQW, self).__init__("VPMOVQW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVQW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x34, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x34, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x34, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x34]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVQW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVQD(Instruction):
    """Down Convert Packed Quadword Values to Doubleword Values with Truncation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVQD(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVQD(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVQD(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVQD(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVQD(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVQD(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVQD, self).__init__("VPMOVQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVQD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x35, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x35, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x35, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x35]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVQD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSWB(Instruction):
    """Down Convert Packed Word Values to Byte Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSWB(m128{k}{z}, ymm)    [AVX512BW and AVX512VL]
            * VPMOVSWB(m256{k}{z}, zmm)    [AVX512BW]
            * VPMOVSWB(m64{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVSWB(xmm{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVSWB(xmm{k}{z}, ymm)     [AVX512BW and AVX512VL]
            * VPMOVSWB(ymm{k}{z}, zmm)     [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSWB, self).__init__("VPMOVSWB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSWB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x20, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x20, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x20, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x20]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSWB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSDB(Instruction):
    """Down Convert Packed Doubleword Values to Byte Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSDB(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVSDB(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSDB(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSDB(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSDB(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSDB(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSDB, self).__init__("VPMOVSDB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSDB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x21, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x21, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x21, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x21]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSDB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSDW(Instruction):
    """Down Convert Packed Doubleword Values to Word Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSDW(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVSDW(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVSDW(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSDW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSDW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSDW(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSDW, self).__init__("VPMOVSDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSDW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x23, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x23, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x23, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x23]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSQB(Instruction):
    """Down Convert Packed Quadword Values to Byte Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSQB(m16{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVSQB(m32{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVSQB(m64{k}{z}, zmm)    [AVX512F]
            * VPMOVSQB(xmm{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVSQB(xmm{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVSQB(xmm{k}{z}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSQB, self).__init__("VPMOVSQB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSQB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x22, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x22, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m16kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=2)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x22, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x22]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSQB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSQW(Instruction):
    """Down Convert Packed Quadword Values to Word Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSQW(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVSQW(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSQW(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSQW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSQW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSQW(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSQW, self).__init__("VPMOVSQW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSQW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x24, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x24, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x24, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x24]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSQW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVSQD(Instruction):
    """Down Convert Packed Quadword Values to Doubleword Values with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVSQD(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVSQD(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVSQD(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSQD(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVSQD(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVSQD(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVSQD, self).__init__("VPMOVSQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVSQD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x25, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x25, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x25, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x25]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVSQD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSWB(Instruction):
    """Down Convert Packed Word Values to Byte Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSWB(m128{k}{z}, ymm)    [AVX512BW and AVX512VL]
            * VPMOVUSWB(m256{k}{z}, zmm)    [AVX512BW]
            * VPMOVUSWB(m64{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVUSWB(xmm{k}{z}, xmm)     [AVX512BW and AVX512VL]
            * VPMOVUSWB(xmm{k}{z}, ymm)     [AVX512BW and AVX512VL]
            * VPMOVUSWB(ymm{k}{z}, zmm)     [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSWB, self).__init__("VPMOVUSWB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSWB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x10, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x10, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x10, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSWB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSDB(Instruction):
    """Down Convert Packed Doubleword Values to Byte Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSDB(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVUSDB(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSDB(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSDB(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSDB(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSDB(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSDB, self).__init__("VPMOVUSDB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSDB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x11, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSDB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSDW(Instruction):
    """Down Convert Packed Doubleword Values to Word Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSDW(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVUSDW(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVUSDW(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSDW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSDW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSDW(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSDW, self).__init__("VPMOVUSDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSDW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x13, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x13, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x13, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSQB(Instruction):
    """Down Convert Packed Quadword Values to Byte Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSQB(m16{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVUSQB(m32{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVUSQB(m64{k}{z}, zmm)    [AVX512F]
            * VPMOVUSQB(xmm{k}{z}, xmm)    [AVX512F and AVX512VL]
            * VPMOVUSQB(xmm{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVUSQB(xmm{k}{z}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSQB, self).__init__("VPMOVUSQB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSQB\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x12, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x12, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m16kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=2)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x12, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSQB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSQW(Instruction):
    """Down Convert Packed Quadword Values to Word Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSQW(m128{k}{z}, zmm)    [AVX512F]
            * VPMOVUSQW(m32{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSQW(m64{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSQW(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSQW(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSQW(xmm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSQW, self).__init__("VPMOVUSQW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSQW\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x14, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x14]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x14, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m32kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x14]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x14, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x14]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSQW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVUSQD(Instruction):
    """Down Convert Packed Quadword Values to Doubleword Values with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVUSQD(m128{k}{z}, ymm)    [AVX512F and AVX512VL]
            * VPMOVUSQD(m256{k}{z}, zmm)    [AVX512F]
            * VPMOVUSQD(m64{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSQD(xmm{k}{z}, xmm)     [AVX512F and AVX512VL]
            * VPMOVUSQD(xmm{k}{z}, ymm)     [AVX512F and AVX512VL]
            * VPMOVUSQD(ymm{k}{z}, zmm)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVUSQD, self).__init__("VPMOVUSQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVUSQD\" requires 2 operands")
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x15, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x15]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x15, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x15]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 242, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x15, 0xC0 | op[1].lcode << 3 | op[0].lcode])))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x15]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (True, True)
            self.out_regs = (False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMOVUSQD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXTRB(Instruction):
    """Extract Byte"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXTRB(m8, xmm, imm8)     [AVX512BW]
            * VPEXTRB(m8, xmm, imm8)     [AVX]
            * VPEXTRB(r32, xmm, imm8)    [AVX512BW]
            * VPEXTRB(r32, xmm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXTRB, self).__init__("VPEXTRB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPEXTRB\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x79, 0x14, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m8(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[1].hcode, op[0].address) + bytearray([0x14]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, 0x08, 0x14, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m8(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x14]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=1) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPEXTRB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXTRW(Instruction):
    """Extract Word"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXTRW(m16, xmm, imm8)    [AVX512BW]
            * VPEXTRW(m16, xmm, imm8)    [AVX]
            * VPEXTRW(r32, xmm, imm8)    [AVX512BW]
            * VPEXTRW(r32, xmm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXTRW, self).__init__("VPEXTRW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPEXTRW\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0xC5, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x79, 0x15, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m16(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[1].hcode, op[0].address) + bytearray([0x15]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, 0x08, 0x15, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, 0x08, 0xC5, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_m16(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x15]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=2) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPEXTRW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXTRD(Instruction):
    """Extract Doubleword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXTRD(r32/m32, xmm, imm8)    [AVX512DQ]
            * VPEXTRD(r32/m32, xmm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXTRD, self).__init__("VPEXTRD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPEXTRD\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x79, 0x16, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m32(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[1].hcode, op[0].address) + bytearray([0x16]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, 0x08, 0x16, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_m32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[1].ehcode, op[0].address) + bytearray([0x16]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPEXTRD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPEXTRQ(Instruction):
    """Extract Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPEXTRQ(r64/m64, xmm, imm8)    [AVX512DQ]
            * VPEXTRQ(r64/m64, xmm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPEXTRQ, self).__init__("VPEXTRQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPEXTRQ\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_r64(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0xF9, 0x16, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_m64(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x81, op[1].hcode, op[0].address) + bytearray([0x16]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, 0x08, 0x16, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_m64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[1].ehcode, op[0].address) + bytearray([0x16]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPEXTRQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPINSRB(Instruction):
    """Insert Byte"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPINSRB(xmm, xmm, m8, imm8)     [AVX512BW]
            * VPINSRB(xmm, xmm, m8, imm8)     [AVX]
            * VPINSRB(xmm, xmm, r32, imm8)    [AVX512BW]
            * VPINSRB(xmm, xmm, r32, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPINSRB, self).__init__("VPINSRB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPINSRB\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x20, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m8(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x20, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m8(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x20]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=1) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPINSRB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPINSRW(Instruction):
    """Insert Word"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPINSRW(xmm, xmm, m16, imm8)    [AVX512BW]
            * VPINSRW(xmm, xmm, m16, imm8)    [AVX]
            * VPINSRW(xmm, xmm, r32, imm8)    [AVX512BW]
            * VPINSRW(xmm, xmm, r32, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPINSRW, self).__init__("VPINSRW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPINSRW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xC4, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m16(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0xC4, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m16(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=2) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPINSRW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPINSRD(Instruction):
    """Insert Doubleword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPINSRD(xmm, xmm, r32/m32, imm8)    [AVX512DQ]
            * VPINSRD(xmm, xmm, r32/m32, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPINSRD, self).__init__("VPINSRD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPINSRD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x22, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x22, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPINSRD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPINSRQ(Instruction):
    """Insert Quadword"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPINSRQ(xmm, xmm, r64/m64, imm8)    [AVX512DQ]
            * VPINSRQ(xmm, xmm, r64/m64, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPINSRQ, self).__init__("VPINSRQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPINSRQ\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xF9 ^ (op[1].hlcode << 3), 0x22, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x81, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x22, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x22]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPINSRQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPGATHERDD(Instruction):
    """Gather Packed Doubleword Values Using Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPGATHERDD(xmm, vm32x, xmm)    [AVX2]
            * VPGATHERDD(xmm{k}, vm32x)      [AVX512F and AVX512VL]
            * VPGATHERDD(ymm, vm32y, ymm)    [AVX2]
            * VPGATHERDD(ymm{k}, vm32y)      [AVX512F and AVX512VL]
            * VPGATHERDD(zmm{k}, vm32z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPGATHERDD, self).__init__("VPGATHERDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VPGATHERDD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmy(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VPGATHERDD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VPGATHERDD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPGATHERDQ(Instruction):
    """Gather Packed Quadword Values Using Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPGATHERDQ(xmm, vm32x, xmm)    [AVX2]
            * VPGATHERDQ(xmm{k}, vm32x)      [AVX512F and AVX512VL]
            * VPGATHERDQ(ymm, vm32x, ymm)    [AVX2]
            * VPGATHERDQ(ymm{k}, vm32x)      [AVX512F and AVX512VL]
            * VPGATHERDQ(zmm{k}, vm32y)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPGATHERDQ, self).__init__("VPGATHERDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VPGATHERDQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmx(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x90]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VPGATHERDQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VPGATHERDQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPGATHERQD(Instruction):
    """Gather Packed Doubleword Values Using Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPGATHERQD(xmm, vm64x, xmm)    [AVX2]
            * VPGATHERQD(xmm, vm64y, xmm)    [AVX2]
            * VPGATHERQD(xmm{k}, vm64x)      [AVX512F and AVX512VL]
            * VPGATHERQD(xmm{k}, vm64y)      [AVX512F and AVX512VL]
            * VPGATHERQD(ymm{k}, vm64z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPGATHERQD, self).__init__("VPGATHERQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VPGATHERQD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_xmm(self.operands[0]) and is_vmy(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VPGATHERQD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VPGATHERQD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPGATHERQQ(Instruction):
    """Gather Packed Quadword Values Using Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPGATHERQQ(xmm, vm64x, xmm)    [AVX2]
            * VPGATHERQQ(xmm{k}, vm64x)      [AVX512F and AVX512VL]
            * VPGATHERQQ(ymm, vm64y, ymm)    [AVX2]
            * VPGATHERQQ(ymm{k}, vm64y)      [AVX512F and AVX512VL]
            * VPGATHERQQ(zmm{k}, vm64z)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPGATHERQQ, self).__init__("VPGATHERQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (True, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmk(self.operands[0]) and is_vmz(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmk(self.operands[0]) and is_evex_vmx(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmk(self.operands[0]) and is_evex_vmy(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VPGATHERQQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (True, True, True)
            self.out_regs = (True, False, True)
            self.out_operands = (True, False, True)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            if is_xmm(self.operands[0]) and is_vmx(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            elif is_ymm(self.operands[0]) and is_vmy(self.operands[1]) and is_ymm(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[1].address, op[2].hlcode) + bytearray([0x91]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            else:
                raise SyntaxError("Invalid operand types: VPGATHERQQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VPGATHERQQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSCATTERDD(Instruction):
    """Scatter Packed Doubleword Values with Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSCATTERDD(vm32x{k}, xmm)    [AVX512F and AVX512VL]
            * VPSCATTERDD(vm32y{k}, ymm)    [AVX512F and AVX512VL]
            * VPSCATTERDD(vm32z{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSCATTERDD, self).__init__("VPSCATTERDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPSCATTERDD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSCATTERDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSCATTERDQ(Instruction):
    """Scatter Packed Quadword Values with Signed Doubleword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSCATTERDQ(vm32x{k}, xmm)    [AVX512F and AVX512VL]
            * VPSCATTERDQ(vm32x{k}, ymm)    [AVX512F and AVX512VL]
            * VPSCATTERDQ(vm32y{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSCATTERDQ, self).__init__("VPSCATTERDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPSCATTERDQ\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmyk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA0]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSCATTERDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSCATTERQD(Instruction):
    """Scatter Packed Doubleword Values with Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSCATTERQD(vm64x{k}, xmm)    [AVX512F and AVX512VL]
            * VPSCATTERQD(vm64y{k}, xmm)    [AVX512F and AVX512VL]
            * VPSCATTERQD(vm64z{k}, ymm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSCATTERQD, self).__init__("VPSCATTERQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPSCATTERQD\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=4)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSCATTERQD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSCATTERQQ(Instruction):
    """Scatter Packed Quadword Values with Signed Quadword Indices"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSCATTERQQ(vm64x{k}, xmm)    [AVX512F and AVX512VL]
            * VPSCATTERQQ(vm64y{k}, ymm)    [AVX512F and AVX512VL]
            * VPSCATTERQQ(vm64z{k}, zmm)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSCATTERQQ, self).__init__("VPSCATTERQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPSCATTERQQ\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_vmzk(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_vmxk(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_vmyk(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode) + bytearray([0xA1]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSCATTERQQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCONFLICTD(Instruction):
    """Detect Conflicts Within a Vector of Packed Doubleword Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCONFLICTD(xmm{k}{z}, m128/m32bcst)    [AVX512VL and AVX512CD]
            * VPCONFLICTD(xmm{k}{z}, xmm)             [AVX512VL and AVX512CD]
            * VPCONFLICTD(ymm{k}{z}, m256/m32bcst)    [AVX512VL and AVX512CD]
            * VPCONFLICTD(ymm{k}{z}, ymm)             [AVX512VL and AVX512CD]
            * VPCONFLICTD(zmm{k}{z}, m512/m32bcst)    [AVX512CD]
            * VPCONFLICTD(zmm{k}{z}, zmm)             [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCONFLICTD, self).__init__("VPCONFLICTD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPCONFLICTD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPCONFLICTD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCONFLICTQ(Instruction):
    """Detect Conflicts Within a Vector of Packed Quadword Values into Dense Memory/Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCONFLICTQ(xmm{k}{z}, m128/m64bcst)    [AVX512VL and AVX512CD]
            * VPCONFLICTQ(xmm{k}{z}, xmm)             [AVX512VL and AVX512CD]
            * VPCONFLICTQ(ymm{k}{z}, m256/m64bcst)    [AVX512VL and AVX512CD]
            * VPCONFLICTQ(ymm{k}{z}, ymm)             [AVX512VL and AVX512CD]
            * VPCONFLICTQ(zmm{k}{z}, m512/m64bcst)    [AVX512CD]
            * VPCONFLICTQ(zmm{k}{z}, zmm)             [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCONFLICTQ, self).__init__("VPCONFLICTQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPCONFLICTQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xC4]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xC4, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPCONFLICTQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPLZCNTD(Instruction):
    """Count the Number of Leading Zero Bits for Packed Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPLZCNTD(xmm{k}{z}, m128/m32bcst)    [AVX512VL and AVX512CD]
            * VPLZCNTD(xmm{k}{z}, xmm)             [AVX512VL and AVX512CD]
            * VPLZCNTD(ymm{k}{z}, m256/m32bcst)    [AVX512VL and AVX512CD]
            * VPLZCNTD(ymm{k}{z}, ymm)             [AVX512VL and AVX512CD]
            * VPLZCNTD(zmm{k}{z}, m512/m32bcst)    [AVX512CD]
            * VPLZCNTD(zmm{k}{z}, zmm)             [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPLZCNTD, self).__init__("VPLZCNTD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPLZCNTD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPLZCNTD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPLZCNTQ(Instruction):
    """Count the Number of Leading Zero Bits for Packed Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPLZCNTQ(xmm{k}{z}, m128/m64bcst)    [AVX512VL and AVX512CD]
            * VPLZCNTQ(xmm{k}{z}, xmm)             [AVX512VL and AVX512CD]
            * VPLZCNTQ(ymm{k}{z}, m256/m64bcst)    [AVX512VL and AVX512CD]
            * VPLZCNTQ(ymm{k}{z}, ymm)             [AVX512VL and AVX512CD]
            * VPLZCNTQ(zmm{k}{z}, m512/m64bcst)    [AVX512CD]
            * VPLZCNTQ(zmm{k}{z}, zmm)             [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPLZCNTQ, self).__init__("VPLZCNTQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPLZCNTQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x44]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x44, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPLZCNTQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTEST(Instruction):
    """Packed Logical Compare"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTEST(xmm, xmm/m128)    [AVX]
            * VPTEST(ymm, ymm/m256)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTEST, self).__init__("VPTEST", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPTEST\" requires 2 operands")
        self.in_regs = (True, True)
        self.out_regs = (False, False)
        self.out_operands = (False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x17, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x17]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x17, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x17]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VPTEST " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVMSKB(Instruction):
    """Move Byte Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVMSKB(r32, xmm)    [AVX]
            * VPMOVMSKB(r32, ymm)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVMSKB, self).__init__("VPMOVMSKB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVMSKB\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0xD7, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_r32(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0xD7, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPMOVMSKB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDB(Instruction):
    """Add Packed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDB(xmm, xmm, xmm/m128)          [AVX]
            * VPADDB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDB(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDB, self).__init__("VPADDB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xFC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xFC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xFC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDW(Instruction):
    """Add Packed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDW(xmm, xmm, xmm/m128)          [AVX]
            * VPADDW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDW(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDW, self).__init__("VPADDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xFD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xFD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xFD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xFD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDD(Instruction):
    """Add Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDD(xmm, xmm, xmm/m128)              [AVX]
            * VPADDD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPADDD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPADDD(ymm, ymm, ymm/m256)              [AVX2]
            * VPADDD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPADDD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPADDD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPADDD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDD, self).__init__("VPADDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xFE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xFE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xFE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPADDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDQ(Instruction):
    """Add Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPADDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPADDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPADDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPADDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPADDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPADDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPADDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDQ, self).__init__("VPADDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xD4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xD4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xD4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPADDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDSB(Instruction):
    """Add Packed Signed Byte Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDSB(xmm, xmm, xmm/m128)          [AVX]
            * VPADDSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDSB, self).__init__("VPADDSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDSW(Instruction):
    """Add Packed Signed Word Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDSW(xmm, xmm, xmm/m128)          [AVX]
            * VPADDSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDSW, self).__init__("VPADDSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xED, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xED]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xED, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xED]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xED, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xED]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xED, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xED]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xED, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xED]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDUSB(Instruction):
    """Add Packed Unsigned Byte Integers with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDUSB(xmm, xmm, xmm/m128)          [AVX]
            * VPADDUSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDUSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDUSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDUSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDUSB, self).__init__("VPADDUSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDUSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDC, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDC]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDUSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPADDUSW(Instruction):
    """Add Packed Unsigned Word Integers with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPADDUSW(xmm, xmm, xmm/m128)          [AVX]
            * VPADDUSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPADDUSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPADDUSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPADDUSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPADDUSW, self).__init__("VPADDUSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPADDUSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDD, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDD]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPADDUSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHADDW(Instruction):
    """Packed Horizontal Add Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHADDW(xmm, xmm, xmm/m128)    [AVX]
            * VPHADDW(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHADDW, self).__init__("VPHADDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHADDW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x01, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x01]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x01, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x01]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHADDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHADDD(Instruction):
    """Packed Horizontal Add Doubleword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHADDD(xmm, xmm, xmm/m128)    [AVX]
            * VPHADDD(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHADDD, self).__init__("VPHADDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHADDD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x02, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x02]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x02, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x02]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHADDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHADDSW(Instruction):
    """Packed Horizontal Add Signed Word Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHADDSW(xmm, xmm, xmm/m128)    [AVX]
            * VPHADDSW(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHADDSW, self).__init__("VPHADDSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHADDSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHADDSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBB(Instruction):
    """Subtract Packed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBB(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBB(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBB, self).__init__("VPSUBB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBW(Instruction):
    """Subtract Packed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBW(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBW(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBW, self).__init__("VPSUBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBD(Instruction):
    """Subtract Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBD(xmm, xmm, xmm/m128)              [AVX]
            * VPSUBD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPSUBD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSUBD(ymm, ymm, ymm/m256)              [AVX2]
            * VPSUBD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPSUBD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSUBD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPSUBD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBD, self).__init__("VPSUBD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xFA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xFA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xFA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPSUBD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBQ(Instruction):
    """Subtract Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBQ(xmm, xmm, xmm/m128)              [AVX]
            * VPSUBQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPSUBQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSUBQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPSUBQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPSUBQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSUBQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPSUBQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBQ, self).__init__("VPSUBQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xFB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xFB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xFB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xFB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xFB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xFB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPSUBQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBSB(Instruction):
    """Subtract Packed Signed Byte Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBSB(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBSB, self).__init__("VPSUBSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBSW(Instruction):
    """Subtract Packed Signed Word Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBSW(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBSW, self).__init__("VPSUBSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBUSB(Instruction):
    """Subtract Packed Unsigned Byte Integers with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBUSB(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBUSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBUSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBUSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBUSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBUSB, self).__init__("VPSUBUSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBUSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD8, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD8]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBUSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSUBUSW(Instruction):
    """Subtract Packed Unsigned Word Integers with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSUBUSW(xmm, xmm, xmm/m128)          [AVX]
            * VPSUBUSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSUBUSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPSUBUSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSUBUSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSUBUSW, self).__init__("VPSUBUSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSUBUSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD9, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD9]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSUBUSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHSUBW(Instruction):
    """Packed Horizontal Subtract Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHSUBW(xmm, xmm, xmm/m128)    [AVX]
            * VPHSUBW(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHSUBW, self).__init__("VPHSUBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHSUBW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x05, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x05, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x05]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHSUBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHSUBD(Instruction):
    """Packed Horizontal Subtract Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHSUBD(xmm, xmm, xmm/m128)    [AVX]
            * VPHSUBD(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHSUBD, self).__init__("VPHSUBD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHSUBD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x06, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x06]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x06, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x06]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHSUBD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHSUBSW(Instruction):
    """Packed Horizontal Subtract Signed Word Integers with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHSUBSW(xmm, xmm, xmm/m128)    [AVX]
            * VPHSUBSW(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHSUBSW, self).__init__("VPHSUBSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPHSUBSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x07, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x07]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x07, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x07]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPHSUBSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXSB(Instruction):
    """Maximum of Packed Signed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXSB(xmm, xmm, xmm/m128)          [AVX]
            * VPMAXSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMAXSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPMAXSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMAXSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXSB, self).__init__("VPMAXSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMAXSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXSW(Instruction):
    """Maximum of Packed Signed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXSW(xmm, xmm, xmm/m128)          [AVX]
            * VPMAXSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMAXSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMAXSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMAXSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXSW, self).__init__("VPMAXSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMAXSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXSD(Instruction):
    """Maximum of Packed Signed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXSD(xmm, xmm, xmm/m128)              [AVX]
            * VPMAXSD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPMAXSD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMAXSD(ymm, ymm, ymm/m256)              [AVX2]
            * VPMAXSD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPMAXSD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMAXSD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPMAXSD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXSD, self).__init__("VPMAXSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXSD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMAXSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXSQ(Instruction):
    """Maximum of Packed Signed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXSQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMAXSQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMAXSQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMAXSQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMAXSQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMAXSQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXSQ, self).__init__("VPMAXSQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXSQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMAXSQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXUB(Instruction):
    """Maximum of Packed Unsigned Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXUB(xmm, xmm, xmm/m128)          [AVX]
            * VPMAXUB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMAXUB(ymm, ymm, ymm/m256)          [AVX2]
            * VPMAXUB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMAXUB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXUB, self).__init__("VPMAXUB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXUB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDE, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDE]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMAXUB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXUW(Instruction):
    """Maximum of Packed Unsigned Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXUW(xmm, xmm, xmm/m128)          [AVX]
            * VPMAXUW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMAXUW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMAXUW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMAXUW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXUW, self).__init__("VPMAXUW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXUW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMAXUW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXUD(Instruction):
    """Maximum of Packed Unsigned Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXUD(xmm, xmm, xmm/m128)              [AVX]
            * VPMAXUD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPMAXUD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMAXUD(ymm, ymm, ymm/m256)              [AVX2]
            * VPMAXUD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPMAXUD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMAXUD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPMAXUD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXUD, self).__init__("VPMAXUD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXUD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMAXUD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMAXUQ(Instruction):
    """Maximum of Packed Unsigned Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMAXUQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMAXUQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMAXUQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMAXUQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMAXUQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMAXUQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMAXUQ, self).__init__("VPMAXUQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMAXUQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMAXUQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINSB(Instruction):
    """Minimum of Packed Signed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINSB(xmm, xmm, xmm/m128)          [AVX]
            * VPMINSB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMINSB(ymm, ymm, ymm/m256)          [AVX2]
            * VPMINSB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMINSB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINSB, self).__init__("VPMINSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINSB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMINSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINSW(Instruction):
    """Minimum of Packed Signed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINSW(xmm, xmm, xmm/m128)          [AVX]
            * VPMINSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMINSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMINSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMINSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINSW, self).__init__("VPMINSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xEA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMINSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINSD(Instruction):
    """Minimum of Packed Signed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINSD(xmm, xmm, xmm/m128)              [AVX]
            * VPMINSD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPMINSD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMINSD(ymm, ymm, ymm/m256)              [AVX2]
            * VPMINSD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPMINSD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMINSD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPMINSD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINSD, self).__init__("VPMINSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINSD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMINSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINSQ(Instruction):
    """Minimum of Packed Signed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINSQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMINSQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMINSQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMINSQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMINSQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMINSQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINSQ, self).__init__("VPMINSQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINSQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x39]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x39, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMINSQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINUB(Instruction):
    """Minimum of Packed Unsigned Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINUB(xmm, xmm, xmm/m128)          [AVX]
            * VPMINUB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMINUB(ymm, ymm, ymm/m256)          [AVX2]
            * VPMINUB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMINUB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINUB, self).__init__("VPMINUB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINUB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDA, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xDA]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMINUB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINUW(Instruction):
    """Minimum of Packed Unsigned Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINUW(xmm, xmm, xmm/m128)          [AVX]
            * VPMINUW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMINUW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMINUW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMINUW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINUW, self).__init__("VPMINUW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINUW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMINUW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINUD(Instruction):
    """Minimum of Packed Unsigned Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINUD(xmm, xmm, xmm/m128)              [AVX]
            * VPMINUD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPMINUD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMINUD(ymm, ymm, ymm/m256)              [AVX2]
            * VPMINUD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPMINUD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMINUD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPMINUD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINUD, self).__init__("VPMINUD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINUD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMINUD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMINUQ(Instruction):
    """Minimum of Packed Unsigned Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMINUQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMINUQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMINUQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMINUQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMINUQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMINUQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMINUQ, self).__init__("VPMINUQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMINUQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x3B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMINUQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLW(Instruction):
    """Shift Packed Word Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLW(xmm, xmm, imm8)               [AVX]
            * VPSLLW(xmm, xmm, xmm/m128)           [AVX]
            * VPSLLW(xmm{k}{z}, xmm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSLLW(xmm{k}{z}, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSLLW(ymm, ymm, imm8)               [AVX2]
            * VPSLLW(ymm, ymm, xmm/m128)           [AVX2]
            * VPSLLW(ymm{k}{z}, ymm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSLLW(ymm{k}{z}, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSLLW(zmm{k}{z}, zmm, xmm/m128)     [AVX512BW]
            * VPSLLW(zmm{k}{z}, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLW, self).__init__("VPSLLW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLW\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x71, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x71, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x71, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSLLW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLD(Instruction):
    """Shift Packed Doubleword Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLD(xmm, xmm, imm8)                   [AVX]
            * VPSLLD(xmm, xmm, xmm/m128)               [AVX]
            * VPSLLD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSLLD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSLLD(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSLLD(ymm, ymm, imm8)                   [AVX2]
            * VPSLLD(ymm, ymm, xmm/m128)               [AVX2]
            * VPSLLD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSLLD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSLLD(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSLLD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPSLLD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSLLD(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLD, self).__init__("VPSLLD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLD\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSLLD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLQ(Instruction):
    """Shift Packed Quadword Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLQ(xmm, xmm, imm8)                   [AVX]
            * VPSLLQ(xmm, xmm, xmm/m128)               [AVX]
            * VPSLLQ(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSLLQ(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSLLQ(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSLLQ(ymm, ymm, imm8)                   [AVX2]
            * VPSLLQ(ymm, ymm, xmm/m128)               [AVX2]
            * VPSLLQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSLLQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSLLQ(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSLLQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPSLLQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSLLQ(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLQ, self).__init__("VPSLLQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLQ\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x73, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(6, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x73, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x73, 0xF0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSLLQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLW(Instruction):
    """Shift Packed Word Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLW(xmm, xmm, imm8)               [AVX]
            * VPSRLW(xmm, xmm, xmm/m128)           [AVX]
            * VPSRLW(xmm{k}{z}, xmm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSRLW(xmm{k}{z}, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSRLW(ymm, ymm, imm8)               [AVX2]
            * VPSRLW(ymm, ymm, xmm/m128)           [AVX2]
            * VPSRLW(ymm{k}{z}, ymm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSRLW(ymm{k}{z}, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSRLW(zmm{k}{z}, zmm, xmm/m128)     [AVX512BW]
            * VPSRLW(zmm{k}{z}, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLW, self).__init__("VPSRLW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLW\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x71, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x71, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x71, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSRLW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLD(Instruction):
    """Shift Packed Doubleword Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLD(xmm, xmm, imm8)                   [AVX]
            * VPSRLD(xmm, xmm, xmm/m128)               [AVX]
            * VPSRLD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRLD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSRLD(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRLD(ymm, ymm, imm8)                   [AVX2]
            * VPSRLD(ymm, ymm, xmm/m128)               [AVX2]
            * VPSRLD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRLD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSRLD(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRLD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPSRLD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSRLD(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLD, self).__init__("VPSRLD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLD\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRLD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLQ(Instruction):
    """Shift Packed Quadword Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLQ(xmm, xmm, imm8)                   [AVX]
            * VPSRLQ(xmm, xmm, xmm/m128)               [AVX]
            * VPSRLQ(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRLQ(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSRLQ(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRLQ(ymm, ymm, imm8)                   [AVX2]
            * VPSRLQ(ymm, ymm, xmm/m128)               [AVX2]
            * VPSRLQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRLQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSRLQ(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRLQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPSRLQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSRLQ(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLQ, self).__init__("VPSRLQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLQ\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x73, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x73]) + modrm_sib_disp(2, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x73, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x73, 0xD0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRLQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAW(Instruction):
    """Shift Packed Word Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAW(xmm, xmm, imm8)               [AVX]
            * VPSRAW(xmm, xmm, xmm/m128)           [AVX]
            * VPSRAW(xmm{k}{z}, xmm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSRAW(xmm{k}{z}, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSRAW(ymm, ymm, imm8)               [AVX2]
            * VPSRAW(ymm, ymm, xmm/m128)           [AVX2]
            * VPSRAW(ymm{k}{z}, ymm, xmm/m128)     [AVX512BW and AVX512VL]
            * VPSRAW(ymm{k}{z}, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSRAW(zmm{k}{z}, zmm, xmm/m128)     [AVX512BW]
            * VPSRAW(zmm{k}{z}, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAW, self).__init__("VPSRAW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAW\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x71, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x71, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x71, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x71, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE1, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE1]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x71]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSRAW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAD(Instruction):
    """Shift Packed Doubleword Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAD(xmm, xmm, imm8)                   [AVX]
            * VPSRAD(xmm, xmm, xmm/m128)               [AVX]
            * VPSRAD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRAD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSRAD(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRAD(ymm, ymm, imm8)                   [AVX2]
            * VPSRAD(ymm, ymm, xmm/m128)               [AVX2]
            * VPSRAD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRAD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSRAD(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRAD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPSRAD(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSRAD(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAD, self).__init__("VPSRAD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAD\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRAD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAQ(Instruction):
    """Shift Packed Quadword Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAQ(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRAQ(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSRAQ(xmm{k}{z}, xmm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRAQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPSRAQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSRAQ(ymm{k}{z}, ymm, xmm/m128)         [AVX512F and AVX512VL]
            * VPSRAQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPSRAQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPSRAQ(zmm{k}{z}, zmm, xmm/m128)         [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAQ, self).__init__("VPSRAQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAQ\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(4, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xE0 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE2, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE2]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRAQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPROLD(Instruction):
    """Rotate Packed Doubleword Left"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPROLD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPROLD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPROLD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPROLD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPROLD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPROLD(zmm{k}{z}, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPROLD, self).__init__("VPROLD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPROLD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPROLD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPROLQ(Instruction):
    """Rotate Packed Quadword Left"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPROLQ(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPROLQ(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPROLQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPROLQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPROLQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPROLQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPROLQ, self).__init__("VPROLQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPROLQ\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(1, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xC8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPROLQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPRORD(Instruction):
    """Rotate Packed Doubleword Right"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPRORD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPRORD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPRORD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPRORD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPRORD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPRORD(zmm{k}{z}, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPRORD, self).__init__("VPRORD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPRORD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPRORD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPRORQ(Instruction):
    """Rotate Packed Quadword Right"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPRORQ(xmm{k}{z}, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPRORQ(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPRORQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPRORQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPRORQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPRORQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPRORQ, self).__init__("VPRORQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPRORQ\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, 0, op[1].address, op[0].code, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x72]) + modrm_sib_disp(0, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0xFD ^ (op[0].hlcode << 3), (op[0].zcode << 7) | (op[0].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x72, 0xC0 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPRORQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLVW(Instruction):
    """Variable Shift Packed Word Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLVW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSLLVW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSLLVW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLVW, self).__init__("VPSLLVW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLVW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x12, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x12, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x12, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x12]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSLLVW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLVD(Instruction):
    """Variable Shift Packed Doubleword Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLVD(xmm, xmm, xmm/m128)              [AVX2]
            * VPSLLVD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPSLLVD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSLLVD(ymm, ymm, ymm/m256)              [AVX2]
            * VPSLLVD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPSLLVD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSLLVD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPSLLVD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLVD, self).__init__("VPSLLVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLVD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSLLVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLVQ(Instruction):
    """Variable Shift Packed Quadword Data Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLVQ(xmm, xmm, xmm/m128)              [AVX2]
            * VPSLLVQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPSLLVQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSLLVQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPSLLVQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPSLLVQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSLLVQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPSLLVQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLVQ, self).__init__("VPSLLVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLVQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xF9 ^ (op[1].hlcode << 3), 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xFD ^ (op[1].hlcode << 3), 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x47]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x47, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSLLVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLVW(Instruction):
    """Variable Shift Packed Word Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLVW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSRLVW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSRLVW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLVW, self).__init__("VPSRLVW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLVW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x10, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x10]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSRLVW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLVD(Instruction):
    """Variable Shift Packed Doubleword Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLVD(xmm, xmm, xmm/m128)              [AVX2]
            * VPSRLVD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPSRLVD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSRLVD(ymm, ymm, ymm/m256)              [AVX2]
            * VPSRLVD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPSRLVD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSRLVD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPSRLVD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLVD, self).__init__("VPSRLVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLVD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRLVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLVQ(Instruction):
    """Variable Shift Packed Quadword Data Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLVQ(xmm, xmm, xmm/m128)              [AVX2]
            * VPSRLVQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPSRLVQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSRLVQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPSRLVQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPSRLVQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSRLVQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPSRLVQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLVQ, self).__init__("VPSRLVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLVQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xF9 ^ (op[1].hlcode << 3), 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x81, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xFD ^ (op[1].hlcode << 3), 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x85, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x45]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x45, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRLVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAVW(Instruction):
    """Variable Shift Packed Word Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAVW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSRAVW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSRAVW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAVW, self).__init__("VPSRAVW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAVW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x11, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x11, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x11, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x11]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSRAVW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAVD(Instruction):
    """Variable Shift Packed Doubleword Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAVD(xmm, xmm, xmm/m128)              [AVX2]
            * VPSRAVD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPSRAVD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSRAVD(ymm, ymm, ymm/m256)              [AVX2]
            * VPSRAVD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPSRAVD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSRAVD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPSRAVD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAVD, self).__init__("VPSRAVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAVD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRAVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRAVQ(Instruction):
    """Variable Shift Packed Quadword Data Right Arithmetic"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRAVQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPSRAVQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPSRAVQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPSRAVQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPSRAVQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPSRAVQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRAVQ, self).__init__("VPSRAVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRAVQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSRAVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPROLVD(Instruction):
    """Variable Rotate Packed Doubleword Left"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPROLVD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPROLVD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPROLVD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPROLVD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPROLVD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPROLVD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPROLVD, self).__init__("VPROLVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPROLVD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPROLVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPROLVQ(Instruction):
    """Variable Rotate Packed Quadword Left"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPROLVQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPROLVQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPROLVQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPROLVQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPROLVQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPROLVQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPROLVQ, self).__init__("VPROLVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPROLVQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x15]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x15, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPROLVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPRORVD(Instruction):
    """Variable Rotate Packed Doubleword Right"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPRORVD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPRORVD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPRORVD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPRORVD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPRORVD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPRORVD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPRORVD, self).__init__("VPRORVD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPRORVD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPRORVD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPRORVQ(Instruction):
    """Variable Rotate Packed Quadword Right"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPRORVQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPRORVQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPRORVQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPRORVQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPRORVQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPRORVQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPRORVQ, self).__init__("VPRORVQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPRORVQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x14]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x14, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPRORVQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULLW(Instruction):
    """Multiply Packed Signed Word Integers and Store Low Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULLW(xmm, xmm, xmm/m128)          [AVX]
            * VPMULLW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMULLW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMULLW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMULLW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULLW, self).__init__("VPMULLW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULLW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xD5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xD5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xD5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xD5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xD5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xD5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMULLW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULHW(Instruction):
    """Multiply Packed Signed Word Integers and Store High Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULHW(xmm, xmm, xmm/m128)          [AVX]
            * VPMULHW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMULHW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMULHW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMULHW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULHW, self).__init__("VPMULHW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULHW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMULHW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULHUW(Instruction):
    """Multiply Packed Unsigned Word Integers and Store High Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULHUW(xmm, xmm, xmm/m128)          [AVX]
            * VPMULHUW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMULHUW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMULHUW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMULHUW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULHUW, self).__init__("VPMULHUW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULHUW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMULHUW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULLD(Instruction):
    """Multiply Packed Signed Doubleword Integers and Store Low Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULLD(xmm, xmm, xmm/m128)              [AVX]
            * VPMULLD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPMULLD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMULLD(ymm, ymm, ymm/m256)              [AVX2]
            * VPMULLD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPMULLD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMULLD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPMULLD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULLD, self).__init__("VPMULLD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULLD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMULLD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULLQ(Instruction):
    """Multiply Packed Signed Quadword Integers and Store Low Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULLQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VPMULLQ(xmm{k}{z}, xmm, xmm)             [AVX512DQ and AVX512VL]
            * VPMULLQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VPMULLQ(ymm{k}{z}, ymm, ymm)             [AVX512DQ and AVX512VL]
            * VPMULLQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512DQ]
            * VPMULLQ(zmm{k}{z}, zmm, zmm)             [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULLQ, self).__init__("VPMULLQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULLQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x40]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x40, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPMULLQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULDQ(Instruction):
    """Multiply Packed Signed Doubleword Integers and Store Quadword Result"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPMULDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMULDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMULDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPMULDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMULDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMULDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMULDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULDQ, self).__init__("VPMULDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x28, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x28, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x28, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x28, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x28]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x28, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMULDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULUDQ(Instruction):
    """Multiply Packed Unsigned Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULUDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPMULUDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPMULUDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPMULUDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPMULUDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPMULUDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPMULUDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPMULUDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULUDQ, self).__init__("VPMULUDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULUDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xF4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xF4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xF4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPMULUDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULHRSW(Instruction):
    """Packed Multiply Signed Word Integers and Store High Result with Round and Scale"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULHRSW(xmm, xmm, xmm/m128)          [AVX]
            * VPMULHRSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMULHRSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMULHRSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMULHRSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULHRSW, self).__init__("VPMULHRSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULHRSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x0B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMULHRSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMADDWD(Instruction):
    """Multiply and Add Packed Signed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMADDWD(xmm, xmm, xmm/m128)          [AVX]
            * VPMADDWD(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMADDWD(ymm, ymm, ymm/m256)          [AVX2]
            * VPMADDWD(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMADDWD(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMADDWD, self).__init__("VPMADDWD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMADDWD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xF5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xF5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xF5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xF5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMADDWD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMADDUBSW(Instruction):
    """Multiply and Add Packed Signed and Unsigned Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMADDUBSW(xmm, xmm, xmm/m128)          [AVX]
            * VPMADDUBSW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPMADDUBSW(ymm, ymm, ymm/m256)          [AVX2]
            * VPMADDUBSW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPMADDUBSW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMADDUBSW, self).__init__("VPMADDUBSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMADDUBSW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x04, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x04, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x04, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x04, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x04, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x04]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMADDUBSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMADD52LUQ(Instruction):
    """Packed Multiply of Unsigned 52-bit Integers and Add the Low 52-bit Products to Quadword Accumulators"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMADD52LUQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512VL and AVX512IFMA]
            * VPMADD52LUQ(xmm{k}{z}, xmm, xmm)             [AVX512VL and AVX512IFMA]
            * VPMADD52LUQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512VL and AVX512IFMA]
            * VPMADD52LUQ(ymm{k}{z}, ymm, ymm)             [AVX512VL and AVX512IFMA]
            * VPMADD52LUQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512IFMA]
            * VPMADD52LUQ(zmm{k}{z}, zmm, zmm)             [AVX512IFMA]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMADD52LUQ, self).__init__("VPMADD52LUQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMADD52LUQ\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xB4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xB4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB4]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xB4, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma])
        else:
            raise SyntaxError("Invalid operand types: VPMADD52LUQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMADD52HUQ(Instruction):
    """Packed Multiply of Unsigned 52-bit Unsigned Integers and Add High 52-bit Products to Quadword Accumulators"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMADD52HUQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512VL and AVX512IFMA]
            * VPMADD52HUQ(xmm{k}{z}, xmm, xmm)             [AVX512VL and AVX512IFMA]
            * VPMADD52HUQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512VL and AVX512IFMA]
            * VPMADD52HUQ(ymm{k}{z}, ymm, ymm)             [AVX512VL and AVX512IFMA]
            * VPMADD52HUQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512IFMA]
            * VPMADD52HUQ(zmm{k}{z}, zmm, zmm)             [AVX512IFMA]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMADD52HUQ, self).__init__("VPMADD52HUQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMADD52HUQ\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xB5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xB5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma, peachpy.x86_64.isa.avx512vl])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xB5]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xB5, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512ifma])
        else:
            raise SyntaxError("Invalid operand types: VPMADD52HUQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPAVGB(Instruction):
    """Average Packed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPAVGB(xmm, xmm, xmm/m128)          [AVX]
            * VPAVGB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPAVGB(ymm, ymm, ymm/m256)          [AVX2]
            * VPAVGB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPAVGB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPAVGB, self).__init__("VPAVGB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPAVGB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE0, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE0]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPAVGB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPAVGW(Instruction):
    """Average Packed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPAVGW(xmm, xmm, xmm/m128)          [AVX]
            * VPAVGW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPAVGW(ymm, ymm, ymm/m256)          [AVX2]
            * VPAVGW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPAVGW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPAVGW, self).__init__("VPAVGW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPAVGW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xE3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xE3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xE3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xE3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xE3, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0xE3]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPAVGW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSADBW(Instruction):
    """Compute Sum of Absolute Differences"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSADBW(xmm, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSADBW(xmm, xmm, xmm/m128)    [AVX]
            * VPSADBW(ymm, ymm, ymm/m256)    [AVX2]
            * VPSADBW(ymm, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSADBW(zmm, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSADBW, self).__init__("VPSADBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSADBW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF6, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xF6, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xF6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmm(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0xF6, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_zmm(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code) + bytearray([0xF6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0xF6, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0xF6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x20, 0xF6, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_evex_ymm(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code) + bytearray([0xF6]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSADBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VMPSADBW(Instruction):
    """Compute Multiple Packed Sums of Absolute Difference"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VMPSADBW(xmm, xmm, xmm/m128, imm8)    [AVX]
            * VMPSADBW(ymm, ymm, ymm/m256, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VMPSADBW, self).__init__("VMPSADBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VMPSADBW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x42, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x42, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VMPSADBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VDBPSADBW(Instruction):
    """Double Block Packed Sum-Absolute-Differences on Unsigned Bytes"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VDBPSADBW(xmm{k}{z}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VDBPSADBW(ymm{k}{z}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VDBPSADBW(zmm{k}{z}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VDBPSADBW, self).__init__("VDBPSADBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VDBPSADBW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x42, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x42, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x42, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x42]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VDBPSADBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPHMINPOSUW(Instruction):
    """Packed Horizontal Minimum of Unsigned Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPHMINPOSUW(xmm, xmm/m128)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPHMINPOSUW, self).__init__("VPHMINPOSUW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPHMINPOSUW\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x41, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x41]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
        else:
            raise SyntaxError("Invalid operand types: VPHMINPOSUW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPEQB(Instruction):
    """Compare Packed Byte Data for Equality"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPEQB(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPCMPEQB(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPCMPEQB(k{k}, zmm, zmm/m512)    [AVX512BW]
            * VPCMPEQB(xmm, xmm, xmm/m128)     [AVX]
            * VPCMPEQB(ymm, ymm, ymm/m256)     [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPEQB, self).__init__("VPCMPEQB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPEQB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x74, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x74]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x74, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x74]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x74, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x74]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x74, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x74]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x74, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x74]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPEQB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPEQW(Instruction):
    """Compare Packed Word Data for Equality"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPEQW(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPCMPEQW(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPCMPEQW(k{k}, zmm, zmm/m512)    [AVX512BW]
            * VPCMPEQW(xmm, xmm, xmm/m128)     [AVX]
            * VPCMPEQW(ymm, ymm, ymm/m256)     [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPEQW, self).__init__("VPCMPEQW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPEQW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPEQW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPEQD(Instruction):
    """Compare Packed Doubleword Data for Equality"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPEQD(k{k}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPCMPEQD(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPCMPEQD(k{k}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPCMPEQD(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPCMPEQD(k{k}, zmm, m512/m32bcst)    [AVX512F]
            * VPCMPEQD(k{k}, zmm, zmm)             [AVX512F]
            * VPCMPEQD(xmm, xmm, xmm/m128)         [AVX]
            * VPCMPEQD(ymm, ymm, ymm/m256)         [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPEQD, self).__init__("VPCMPEQD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPEQD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPCMPEQD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPEQQ(Instruction):
    """Compare Packed Quadword Data for Equality"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPEQQ(k{k}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPCMPEQQ(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPCMPEQQ(k{k}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPCMPEQQ(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPCMPEQQ(k{k}, zmm, m512/m64bcst)    [AVX512F]
            * VPCMPEQQ(k{k}, zmm, zmm)             [AVX512F]
            * VPCMPEQQ(xmm, xmm, xmm/m128)         [AVX]
            * VPCMPEQQ(ymm, ymm, ymm/m256)         [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPEQQ, self).__init__("VPCMPEQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPEQQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x29, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x29]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x29, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x29]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x29]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x29, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x29]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x29, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x29]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x29, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPCMPEQQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPGTB(Instruction):
    """Compare Packed Signed Byte Integers for Greater Than"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPGTB(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPCMPGTB(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPCMPGTB(k{k}, zmm, zmm/m512)    [AVX512BW]
            * VPCMPGTB(xmm, xmm, xmm/m128)     [AVX]
            * VPCMPGTB(ymm, ymm, ymm/m256)     [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPGTB, self).__init__("VPCMPGTB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPGTB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPGTB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPGTW(Instruction):
    """Compare Packed Signed Word Integers for Greater Than"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPGTW(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPCMPGTW(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPCMPGTW(k{k}, zmm, zmm/m512)    [AVX512BW]
            * VPCMPGTW(xmm, xmm, xmm/m128)     [AVX]
            * VPCMPGTW(ymm, ymm, ymm/m256)     [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPGTW, self).__init__("VPCMPGTW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPGTW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x65, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x65]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPGTW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPGTD(Instruction):
    """Compare Packed Signed Doubleword Integers for Greater Than"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPGTD(k{k}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPCMPGTD(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPCMPGTD(k{k}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPCMPGTD(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPCMPGTD(k{k}, zmm, m512/m32bcst)    [AVX512F]
            * VPCMPGTD(k{k}, zmm, zmm)             [AVX512F]
            * VPCMPGTD(xmm, xmm, xmm/m128)         [AVX]
            * VPCMPGTD(ymm, ymm, ymm/m256)         [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPGTD, self).__init__("VPCMPGTD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPGTD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPCMPGTD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPGTQ(Instruction):
    """Compare Packed Data for Greater Than"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPGTQ(k{k}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPCMPGTQ(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPCMPGTQ(k{k}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPCMPGTQ(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPCMPGTQ(k{k}, zmm, m512/m64bcst)    [AVX512F]
            * VPCMPGTQ(k{k}, zmm, zmm)             [AVX512F]
            * VPCMPGTQ(xmm, xmm, xmm/m128)         [AVX]
            * VPCMPGTQ(ymm, ymm, ymm/m256)         [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPGTQ, self).__init__("VPCMPGTQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPGTQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x37, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x37]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x37, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x37]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x37]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x37, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x37]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x37, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x37]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x37, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            self._cancelling_inputs = True
        else:
            raise SyntaxError("Invalid operand types: VPCMPGTQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPB(Instruction):
    """Compare Packed Signed Byte Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPB(k{k}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPCMPB(k{k}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPCMPB(k{k}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPB, self).__init__("VPCMPB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPB\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPW(Instruction):
    """Compare Packed Signed Word Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPW(k{k}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPCMPW(k{k}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPCMPW(k{k}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPW, self).__init__("VPCMPW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPD(Instruction):
    """Compare Packed Signed Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPD(k{k}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPD(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPCMPD(k{k}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPD(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPCMPD(k{k}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VPCMPD(k{k}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPD, self).__init__("VPCMPD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCMPD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPQ(Instruction):
    """Compare Packed Signed Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPQ(k{k}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPQ(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPCMPQ(k{k}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPQ(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPCMPQ(k{k}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VPCMPQ(k{k}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPQ, self).__init__("VPCMPQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPQ\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x1F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCMPQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPUB(Instruction):
    """Compare Packed Unsigned Byte Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPUB(k{k}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPCMPUB(k{k}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPCMPUB(k{k}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPUB, self).__init__("VPCMPUB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPUB\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPUB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPUW(Instruction):
    """Compare Packed Unsigned Word Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPUW(k{k}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPCMPUW(k{k}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPCMPUW(k{k}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPUW, self).__init__("VPCMPUW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPUW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x3E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x3E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPCMPUW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPUD(Instruction):
    """Compare Packed Unsigned Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPUD(k{k}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPUD(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPCMPUD(k{k}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPUD(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPCMPUD(k{k}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VPCMPUD(k{k}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPUD, self).__init__("VPCMPUD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPUD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCMPUD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPUQ(Instruction):
    """Compare Packed Unsigned Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPUQ(k{k}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPUQ(k{k}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPCMPUQ(k{k}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPCMPUQ(k{k}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPCMPUQ(k{k}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VPCMPUQ(k{k}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPUQ, self).__init__("VPCMPUQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPCMPUQ\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x1E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPCMPUQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPABSB(Instruction):
    """Packed Absolute Value of Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPABSB(xmm, xmm/m128)          [AVX]
            * VPABSB(xmm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VPABSB(ymm, ymm/m256)          [AVX2]
            * VPABSB(ymm{k}{z}, ymm/m256)    [AVX512BW and AVX512VL]
            * VPABSB(zmm{k}{z}, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPABSB, self).__init__("VPABSB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPABSB\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x1C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x1C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x1C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x1C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x1C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x1C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPABSB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPABSW(Instruction):
    """Packed Absolute Value of Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPABSW(xmm, xmm/m128)          [AVX]
            * VPABSW(xmm{k}{z}, xmm/m128)    [AVX512BW and AVX512VL]
            * VPABSW(ymm, ymm/m256)          [AVX2]
            * VPABSW(ymm{k}{z}, ymm/m256)    [AVX512BW and AVX512VL]
            * VPABSW(zmm{k}{z}, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPABSW, self).__init__("VPABSW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPABSW\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x1D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x1D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x1D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x1D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x1D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x1D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPABSW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPABSD(Instruction):
    """Packed Absolute Value of Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPABSD(xmm, xmm/m128)              [AVX]
            * VPABSD(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPABSD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VPABSD(ymm, ymm/m256)              [AVX2]
            * VPABSD(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPABSD(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VPABSD(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VPABSD(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPABSD, self).__init__("VPABSD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPABSD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x1E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x1E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1E]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x1E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x1E, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPABSD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPABSQ(Instruction):
    """Packed Absolute Value of Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPABSQ(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPABSQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VPABSQ(ymm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPABSQ(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VPABSQ(zmm{k}{z}, m512/m64bcst)    [AVX512F]
            * VPABSQ(zmm{k}{z}, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPABSQ, self).__init__("VPABSQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPABSQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x1F]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x1F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x1F, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPABSQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSIGNB(Instruction):
    """Packed Sign of Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSIGNB(xmm, xmm, xmm/m128)    [AVX]
            * VPSIGNB(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSIGNB, self).__init__("VPSIGNB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSIGNB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x08, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x08, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x08]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPSIGNB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSIGNW(Instruction):
    """Packed Sign of Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSIGNW(xmm, xmm, xmm/m128)    [AVX]
            * VPSIGNW(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSIGNW, self).__init__("VPSIGNW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSIGNW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x09, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x09, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x09]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPSIGNW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSIGND(Instruction):
    """Packed Sign of Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSIGND(xmm, xmm, xmm/m128)    [AVX]
            * VPSIGND(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSIGND, self).__init__("VPSIGND", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSIGND\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPSIGND " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPAND(Instruction):
    """Packed Bitwise Logical AND"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPAND(xmm, xmm, xmm/m128)    [AVX]
            * VPAND(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPAND, self).__init__("VPAND", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPAND\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPAND " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPANDD(Instruction):
    """Bitwise Logical AND of Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPANDD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPANDD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPANDD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPANDD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPANDD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPANDD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPANDD, self).__init__("VPANDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPANDD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPANDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPANDQ(Instruction):
    """Bitwise Logical AND of Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPANDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPANDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPANDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPANDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPANDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPANDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPANDQ, self).__init__("VPANDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPANDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPANDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPANDN(Instruction):
    """Packed Bitwise Logical AND NOT"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPANDN(xmm, xmm, xmm/m128)    [AVX]
            * VPANDN(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPANDN, self).__init__("VPANDN", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPANDN\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPANDN " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPANDND(Instruction):
    """Bitwise Logical AND NOT of Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPANDND(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPANDND(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPANDND(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPANDND(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPANDND(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPANDND(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPANDND, self).__init__("VPANDND", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPANDND\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPANDND " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPANDNQ(Instruction):
    """Bitwise Logical AND NOT of Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPANDNQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPANDNQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPANDNQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPANDNQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPANDNQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPANDNQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPANDNQ, self).__init__("VPANDNQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPANDNQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xDF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xDF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPANDNQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPOR(Instruction):
    """Packed Bitwise Logical OR"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPOR(xmm, xmm, xmm/m128)    [AVX]
            * VPOR(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPOR, self).__init__("VPOR", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPOR\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPOR " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPORD(Instruction):
    """Bitwise Logical OR of Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPORD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPORD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPORD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPORD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPORD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPORD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPORD, self).__init__("VPORD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPORD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPORD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPORQ(Instruction):
    """Bitwise Logical OR of Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPORQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPORQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPORQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPORQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPORQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPORQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPORQ, self).__init__("VPORQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPORQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEB]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEB, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPORQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPXOR(Instruction):
    """Packed Bitwise Logical Exclusive OR"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPXOR(xmm, xmm, xmm/m128)    [AVX]
            * VPXOR(ymm, ymm, ymm/m256)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPXOR, self).__init__("VPXOR", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPXOR\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            self._cancelling_inputs = True
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
            self._cancelling_inputs = True
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPXOR " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPXORD(Instruction):
    """Bitwise Logical Exclusive OR of Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPXORD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPXORD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPXORD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPXORD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPXORD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPXORD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPXORD, self).__init__("VPXORD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPXORD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPXORD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPXORQ(Instruction):
    """Bitwise Logical Exclusive OR of Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPXORQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPXORQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPXORQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPXORQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPXORQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPXORQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPXORQ, self).__init__("VPXORQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPXORQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0xEF]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0xEF, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPXORQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTERNLOGD(Instruction):
    """Bitwise Ternary Logical Operation on Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTERNLOGD(xmm{k}{z}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPTERNLOGD(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPTERNLOGD(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPTERNLOGD(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPTERNLOGD(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VPTERNLOGD(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTERNLOGD, self).__init__("VPTERNLOGD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPTERNLOGD\" requires 4 operands")
        self.in_regs = (True, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTERNLOGD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTERNLOGQ(Instruction):
    """Bitwise Ternary Logical Operation on Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTERNLOGQ(xmm{k}{z}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPTERNLOGQ(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VPTERNLOGQ(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPTERNLOGQ(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VPTERNLOGQ(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VPTERNLOGQ(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTERNLOGQ, self).__init__("VPTERNLOGQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPTERNLOGQ\" requires 4 operands")
        self.in_regs = (True, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x25]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x25, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTERNLOGQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDW(Instruction):
    """Blend Packed Words"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDW(xmm, xmm, xmm/m128, imm8)    [AVX]
            * VPBLENDW(ymm, ymm, ymm/m256, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDW, self).__init__("VPBLENDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPBLENDW\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0E, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDVB(Instruction):
    """Variable Blend Packed Bytes"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDVB(xmm, xmm, xmm/m128, xmm)    [AVX]
            * VPBLENDVB(ymm, ymm, ymm/m256, ymm)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDVB, self).__init__("VPBLENDVB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPBLENDVB\" requires 4 operands")
        self.in_regs = (False, True, True, True)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x4C, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_xmm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x4C, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3].hlcode << 4])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_ymm(self.operands[3]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x4C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3].hlcode << 4])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDVB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDD(Instruction):
    """Blend Packed Doublewords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDD(xmm, xmm, xmm/m128, imm8)    [AVX2]
            * VPBLENDD(ymm, ymm, ymm/m256, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDD, self).__init__("VPBLENDD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPBLENDD\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x02, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x02]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x02, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x02]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VPBLENDD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDMB(Instruction):
    """Blend Byte Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDMB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPBLENDMB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPBLENDMB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDMB, self).__init__("VPBLENDMB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPBLENDMB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDMB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDMW(Instruction):
    """Blend Word Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDMW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPBLENDMW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPBLENDMW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDMW, self).__init__("VPBLENDMW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPBLENDMW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x66, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x66]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDMW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDMD(Instruction):
    """Blend Doubleword Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDMD(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPBLENDMD(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPBLENDMD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPBLENDMD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPBLENDMD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPBLENDMD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDMD, self).__init__("VPBLENDMD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPBLENDMD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDMD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBLENDMQ(Instruction):
    """Blend Quadword Vectors Using an OpMask Control"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBLENDMQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPBLENDMQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPBLENDMQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPBLENDMQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPBLENDMQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPBLENDMQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBLENDMQ, self).__init__("VPBLENDMQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPBLENDMQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x64]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x64, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPBLENDMQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKLBW(Instruction):
    """Unpack and Interleave Low-Order Bytes into Words"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKLBW(xmm, xmm, xmm/m128)          [AVX]
            * VPUNPCKLBW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPUNPCKLBW(ymm, ymm, ymm/m256)          [AVX2]
            * VPUNPCKLBW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPUNPCKLBW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKLBW, self).__init__("VPUNPCKLBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKLBW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x60, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x60, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x60, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x60, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x60, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKLBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKLWD(Instruction):
    """Unpack and Interleave Low-Order Words into Doublewords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKLWD(xmm, xmm, xmm/m128)          [AVX]
            * VPUNPCKLWD(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPUNPCKLWD(ymm, ymm, ymm/m256)          [AVX2]
            * VPUNPCKLWD(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPUNPCKLWD(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKLWD, self).__init__("VPUNPCKLWD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKLWD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x61, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x61, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x61, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x61, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x61, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKLWD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKLDQ(Instruction):
    """Unpack and Interleave Low-Order Doublewords into Quadwords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKLDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPUNPCKLDQ(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPUNPCKLDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPUNPCKLDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPUNPCKLDQ(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPUNPCKLDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPUNPCKLDQ(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPUNPCKLDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKLDQ, self).__init__("VPUNPCKLDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKLDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x62, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x62, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x62, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x62, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x62, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKLDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKLQDQ(Instruction):
    """Unpack and Interleave Low-Order Quadwords into Double Quadwords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKLQDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPUNPCKLQDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPUNPCKLQDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPUNPCKLQDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPUNPCKLQDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPUNPCKLQDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPUNPCKLQDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPUNPCKLQDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKLQDQ, self).__init__("VPUNPCKLQDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKLQDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x6C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x6C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6C]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x6C, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKLQDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKHBW(Instruction):
    """Unpack and Interleave High-Order Bytes into Words"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKHBW(xmm, xmm, xmm/m128)          [AVX]
            * VPUNPCKHBW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPUNPCKHBW(ymm, ymm, ymm/m256)          [AVX2]
            * VPUNPCKHBW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPUNPCKHBW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKHBW, self).__init__("VPUNPCKHBW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKHBW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x68, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x68]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x68, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x68]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x68, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x68]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x68, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x68]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x68, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x68]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKHBW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKHWD(Instruction):
    """Unpack and Interleave High-Order Words into Doublewords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKHWD(xmm, xmm, xmm/m128)          [AVX]
            * VPUNPCKHWD(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPUNPCKHWD(ymm, ymm, ymm/m256)          [AVX2]
            * VPUNPCKHWD(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPUNPCKHWD(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKHWD, self).__init__("VPUNPCKHWD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKHWD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x69, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x69]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x69, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x69]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x69, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x69]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x69, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x69]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x69, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x69]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKHWD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKHDQ(Instruction):
    """Unpack and Interleave High-Order Doublewords into Quadwords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKHDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPUNPCKHDQ(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPUNPCKHDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPUNPCKHDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPUNPCKHDQ(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPUNPCKHDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPUNPCKHDQ(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPUNPCKHDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKHDQ, self).__init__("VPUNPCKHDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKHDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x6A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x6A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x6A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKHDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPUNPCKHQDQ(Instruction):
    """Unpack and Interleave High-Order Quadwords into Double Quadwords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPUNPCKHQDQ(xmm, xmm, xmm/m128)              [AVX]
            * VPUNPCKHQDQ(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPUNPCKHQDQ(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPUNPCKHQDQ(ymm, ymm, ymm/m256)              [AVX2]
            * VPUNPCKHQDQ(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPUNPCKHQDQ(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPUNPCKHQDQ(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPUNPCKHQDQ(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPUNPCKHQDQ, self).__init__("VPUNPCKHQDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPUNPCKHQDQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x6D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x6D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x6D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPUNPCKHQDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPACKSSWB(Instruction):
    """Pack Words into Bytes with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPACKSSWB(xmm, xmm, xmm/m128)          [AVX]
            * VPACKSSWB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPACKSSWB(ymm, ymm, ymm/m256)          [AVX2]
            * VPACKSSWB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPACKSSWB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPACKSSWB, self).__init__("VPACKSSWB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPACKSSWB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x63, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x63, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x63, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x63, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x63, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPACKSSWB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPACKSSDW(Instruction):
    """Pack Doublewords into Words with Signed Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPACKSSDW(xmm, xmm, xmm/m128)              [AVX]
            * VPACKSSDW(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512BW and AVX512VL]
            * VPACKSSDW(xmm{k}{z}, xmm, xmm)             [AVX512BW and AVX512VL]
            * VPACKSSDW(ymm, ymm, ymm/m256)              [AVX2]
            * VPACKSSDW(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512BW and AVX512VL]
            * VPACKSSDW(ymm{k}{z}, ymm, ymm)             [AVX512BW and AVX512VL]
            * VPACKSSDW(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512BW]
            * VPACKSSDW(zmm{k}{z}, zmm, zmm)             [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPACKSSDW, self).__init__("VPACKSSDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPACKSSDW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x6B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x6B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x6B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x6B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x6B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x6B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPACKSSDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPACKUSWB(Instruction):
    """Pack Words into Bytes with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPACKUSWB(xmm, xmm, xmm/m128)          [AVX]
            * VPACKUSWB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPACKUSWB(ymm, ymm, ymm/m256)          [AVX2]
            * VPACKUSWB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPACKUSWB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPACKUSWB, self).__init__("VPACKUSWB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPACKUSWB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x67, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x67, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x67, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x67, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x67, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x67]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPACKUSWB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPACKUSDW(Instruction):
    """Pack Doublewords into Words with Unsigned Saturation"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPACKUSDW(xmm, xmm, xmm/m128)              [AVX]
            * VPACKUSDW(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512BW and AVX512VL]
            * VPACKUSDW(xmm{k}{z}, xmm, xmm)             [AVX512BW and AVX512VL]
            * VPACKUSDW(ymm, ymm, ymm/m256)              [AVX2]
            * VPACKUSDW(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512BW and AVX512VL]
            * VPACKUSDW(ymm{k}{z}, ymm, ymm)             [AVX512BW and AVX512VL]
            * VPACKUSDW(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512BW]
            * VPACKUSDW(zmm{k}{z}, zmm, zmm)             [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPACKUSDW, self).__init__("VPACKUSDW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPACKUSDW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x2B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x2B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x2B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x2B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x2B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x2B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPACKUSDW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSHUFB(Instruction):
    """Packed Shuffle Bytes"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSHUFB(xmm, xmm, xmm/m128)          [AVX]
            * VPSHUFB(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPSHUFB(ymm, ymm, ymm/m256)          [AVX2]
            * VPSHUFB(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPSHUFB(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSHUFB, self).__init__("VPSHUFB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSHUFB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x00, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x00, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x00, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x00, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x00, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSHUFB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSHUFLW(Instruction):
    """Shuffle Packed Low Words"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSHUFLW(xmm, xmm/m128, imm8)          [AVX]
            * VPSHUFLW(xmm{k}{z}, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSHUFLW(ymm, ymm/m256, imm8)          [AVX2]
            * VPSHUFLW(ymm{k}{z}, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSHUFLW(zmm{k}{z}, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSHUFLW, self).__init__("VPSHUFLW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSHUFLW\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSHUFLW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSHUFHW(Instruction):
    """Shuffle Packed High Words"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSHUFHW(xmm, xmm/m128, imm8)          [AVX]
            * VPSHUFHW(xmm{k}{z}, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSHUFHW(ymm, ymm/m256, imm8)          [AVX2]
            * VPSHUFHW(ymm{k}{z}, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSHUFHW(zmm{k}{z}, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSHUFHW, self).__init__("VPSHUFHW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSHUFHW\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSHUFHW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSHUFD(Instruction):
    """Shuffle Packed Doublewords"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSHUFD(xmm, xmm/m128, imm8)              [AVX]
            * VPSHUFD(xmm{k}{z}, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSHUFD(xmm{k}{z}, xmm, imm8)             [AVX512F and AVX512VL]
            * VPSHUFD(ymm, ymm/m256, imm8)              [AVX2]
            * VPSHUFD(ymm{k}{z}, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VPSHUFD(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPSHUFD(zmm{k}{z}, m512/m32bcst, imm8)    [AVX512F]
            * VPSHUFD(zmm{k}{z}, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSHUFD, self).__init__("VPSHUFD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSHUFD\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x70]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x70, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPSHUFD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMB(Instruction):
    """Permute Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMB(xmm{k}{z}, xmm, xmm/m128)    [AVX512VL and AVX512VBMI]
            * VPERMB(ymm{k}{z}, ymm, ymm/m256)    [AVX512VL and AVX512VBMI]
            * VPERMB(zmm{k}{z}, zmm, zmm/m512)    [AVX512VBMI]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMB, self).__init__("VPERMB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        else:
            raise SyntaxError("Invalid operand types: VPERMB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMW(Instruction):
    """Permute Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMW(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPERMW(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPERMW(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMW, self).__init__("VPERMW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x8D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x8D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPERMW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMD(Instruction):
    """Permute Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMD(ymm, ymm, ymm/m256)              [AVX2]
            * VPERMD(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMD(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMD(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMD(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMD, self).__init__("VPERMD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x36, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x36]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x36]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x36, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x36]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x36, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMQ(Instruction):
    """Permute Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMQ(ymm, ymm/m256, imm8)              [AVX2]
            * VPERMQ(ymm{k}{z}, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VPERMQ(ymm{k}{z}, ymm, imm8)             [AVX512F and AVX512VL]
            * VPERMQ(ymm{k}{z}, ymm, m256/m64bcst)     [AVX512F and AVX512VL]
            * VPERMQ(ymm{k}{z}, ymm, ymm)              [AVX512F and AVX512VL]
            * VPERMQ(zmm{k}{z}, m512/m64bcst, imm8)    [AVX512F]
            * VPERMQ(zmm{k}{z}, zmm, imm8)             [AVX512F]
            * VPERMQ(zmm{k}{z}, zmm, m512/m64bcst)     [AVX512F]
            * VPERMQ(zmm{k}{z}, zmm, zmm)              [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMQ, self).__init__("VPERMQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMQ\" requires 3 operands")
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFD, 0x00, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x85, op[0].hcode, op[1].address) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x36]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x00, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x36, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x00]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x36]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x00, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x36, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.in_regs = (False, True, True)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2B(Instruction):
    """Full Permute of Bytes From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2B(xmm{k}{z}, xmm, xmm/m128)    [AVX512VL and AVX512VBMI]
            * VPERMT2B(ymm{k}{z}, ymm, ymm/m256)    [AVX512VL and AVX512VBMI]
            * VPERMT2B(zmm{k}{z}, zmm, zmm/m512)    [AVX512VBMI]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2B, self).__init__("VPERMT2B", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2B\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2B " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2W(Instruction):
    """Full Permute of Words From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2W(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPERMT2W(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPERMT2W(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2W, self).__init__("VPERMT2W", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2W\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7D, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x7D]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2W " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2D(Instruction):
    """Full Permute of Doublewords From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2D(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPERMT2D(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMT2D(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMT2D(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMT2D(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMT2D(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2D, self).__init__("VPERMT2D", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2D\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2D " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMT2Q(Instruction):
    """Full Permute of Quadwords From Two Tables Overwriting a Table"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMT2Q(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPERMT2Q(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMT2Q(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPERMT2Q(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMT2Q(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPERMT2Q(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMT2Q, self).__init__("VPERMT2Q", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMT2Q\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x7E]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x7E, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMT2Q " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2B(Instruction):
    """Full Permute of Bytes From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2B(xmm{k}{z}, xmm, xmm/m128)    [AVX512VL and AVX512VBMI]
            * VPERMI2B(ymm{k}{z}, ymm, ymm/m256)    [AVX512VL and AVX512VBMI]
            * VPERMI2B(zmm{k}{z}, zmm, zmm/m512)    [AVX512VBMI]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2B, self).__init__("VPERMI2B", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2B\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2B " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2W(Instruction):
    """Full Permute of Words From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2W(xmm{k}{z}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPERMI2W(ymm{k}{z}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPERMI2W(zmm{k}{z}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2W, self).__init__("VPERMI2W", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2W\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x75, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x75]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2W " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2D(Instruction):
    """Full Permute of Doublewords From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2D(xmm{k}{z}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPERMI2D(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMI2D(ymm{k}{z}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPERMI2D(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMI2D(zmm{k}{z}, zmm, m512/m32bcst)    [AVX512F]
            * VPERMI2D(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2D, self).__init__("VPERMI2D", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2D\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2D " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERMI2Q(Instruction):
    """Full Permute of Quadwords From Two Tables Overwriting the Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERMI2Q(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPERMI2Q(xmm{k}{z}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPERMI2Q(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPERMI2Q(ymm{k}{z}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPERMI2Q(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512F]
            * VPERMI2Q(zmm{k}{z}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERMI2Q, self).__init__("VPERMI2Q", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPERMI2Q\" requires 3 operands")
        self.in_regs = (True, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x76]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x76, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPERMI2Q " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSLLDQ(Instruction):
    """Shift Packed Double Quadword Left Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSLLDQ(xmm, xmm, imm8)         [AVX]
            * VPSLLDQ(xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSLLDQ(ymm, ymm, imm8)         [AVX2]
            * VPSLLDQ(ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSLLDQ(zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSLLDQ, self).__init__("VPSLLDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSLLDQ\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xF8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xF8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmm(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x40, 0x73, 0xF8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmm(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(7, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x00, 0x73, 0xF8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(7, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x20, 0x73, 0xF8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(7, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSLLDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPSRLDQ(Instruction):
    """Shift Packed Double Quadword Right Logical"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPSRLDQ(xmm, xmm, imm8)         [AVX]
            * VPSRLDQ(xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPSRLDQ(ymm, ymm, imm8)         [AVX2]
            * VPSRLDQ(ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPSRLDQ(zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPSRLDQ, self).__init__("VPSRLDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPSRLDQ\" requires 3 operands")
        self.in_regs = (False, True, False)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(1, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xD8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x40, lambda op, vex3=False: vex2(5, 0, op[1], op[0].hlcode, vex3) + bytearray([0x73, 0xD8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmm(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x40, 0x73, 0xD8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmm(self.operands[0]) and is_m512(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(3, op[1].address, sib, min_disp, disp8xN=64) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x00, 0x73, 0xD8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(3, op[1].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, (op[1].ehcode << 5) ^ 0xF1, 0x7D ^ (op[0].hlcode << 3), (op[0].ecode << 3 ^ 0x8) | 0x20, 0x73, 0xD8 | op[1].lcode, op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_m256(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, 0, op[1].address, op[0].code) + bytearray([0x73]) + modrm_sib_disp(3, op[1].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPSRLDQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPALIGNR(Instruction):
    """Packed Align Right"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPALIGNR(xmm, xmm, xmm/m128, imm8)          [AVX]
            * VPALIGNR(xmm{k}{z}, xmm, xmm/m128, imm8)    [AVX512BW and AVX512VL]
            * VPALIGNR(ymm, ymm, ymm/m256, imm8)          [AVX2]
            * VPALIGNR(ymm{k}{z}, ymm, ymm/m256, imm8)    [AVX512BW and AVX512VL]
            * VPALIGNR(zmm{k}{z}, zmm, zmm/m512, imm8)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPALIGNR, self).__init__("VPALIGNR", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPALIGNR\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x79 ^ (op[1].hlcode << 3), 0x0F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x0F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x0F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x0F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x0F, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x0F]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPALIGNR " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VALIGND(Instruction):
    """Align Doubleword Vectors"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VALIGND(xmm{k}{z}, xmm, m128/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VALIGND(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VALIGND(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VALIGND(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VALIGND(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VALIGND(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VALIGND, self).__init__("VALIGND", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VALIGND\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VALIGND " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VALIGNQ(Instruction):
    """Align Quadword Vectors"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VALIGNQ(xmm{k}{z}, xmm, m128/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VALIGNQ(xmm{k}{z}, xmm, xmm, imm8)             [AVX512F and AVX512VL]
            * VALIGNQ(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VALIGNQ(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VALIGNQ(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VALIGNQ(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VALIGNQ, self).__init__("VALIGNQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VALIGNQ\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x03]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x03, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VALIGNQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMULTISHIFTQB(Instruction):
    """Select Packed Unaligned Bytes from Quadword Sources"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMULTISHIFTQB(xmm{k}{z}, xmm, m128/m64bcst)    [AVX512VL and AVX512VBMI]
            * VPMULTISHIFTQB(xmm{k}{z}, xmm, xmm)             [AVX512VL and AVX512VBMI]
            * VPMULTISHIFTQB(ymm{k}{z}, ymm, m256/m64bcst)    [AVX512VL and AVX512VBMI]
            * VPMULTISHIFTQB(ymm{k}{z}, ymm, ymm)             [AVX512VL and AVX512VBMI]
            * VPMULTISHIFTQB(zmm{k}{z}, zmm, m512/m64bcst)    [AVX512VBMI]
            * VPMULTISHIFTQB(zmm{k}{z}, zmm, zmm)             [AVX512VBMI]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMULTISHIFTQB, self).__init__("VPMULTISHIFTQB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPMULTISHIFTQB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x83]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi, peachpy.x86_64.isa.avx512vl])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x83, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x83]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi, peachpy.x86_64.isa.avx512vl])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x83, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi, peachpy.x86_64.isa.avx512vl])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x83]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x83, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vbmi])
        else:
            raise SyntaxError("Invalid operand types: VPMULTISHIFTQB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPOPCNTD(Instruction):
    """Packed Population Count for Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPOPCNTD(zmm{k}{z}, m512/m32bcst)    [AVX512VPOPCNTDQ]
            * VPOPCNTD(zmm{k}{z}, zmm)             [AVX512VPOPCNTDQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPOPCNTD, self).__init__("VPOPCNTD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPOPCNTD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vpopcntdq])
        if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x55, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        else:
            raise SyntaxError("Invalid operand types: VPOPCNTD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPOPCNTQ(Instruction):
    """Packed Population Count for Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPOPCNTQ(zmm{k}{z}, m512/m64bcst)    [AVX512VPOPCNTDQ]
            * VPOPCNTQ(zmm{k}{z}, zmm)             [AVX512VPOPCNTDQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPOPCNTQ, self).__init__("VPOPCNTQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPOPCNTQ\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vpopcntdq])
        if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x55]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x55, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
        else:
            raise SyntaxError("Invalid operand types: VPOPCNTQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPESTRI(Instruction):
    """Packed Compare Explicit Length Strings, Return Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPESTRI(xmm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPESTRI, self).__init__("VPCMPESTRI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPESTRI\" requires 3 operands")
        self.in_regs = (True, True, False)
        self.out_regs = (False, False, False)
        self.out_operands = (False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x61, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self._implicit_in_regs = {0: 7, 2: 7}
            self._implicit_out_regs = {1: 7}
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x61]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self._implicit_in_regs = {0: 7, 2: 7}
            self._implicit_out_regs = {1: 7}
        else:
            raise SyntaxError("Invalid operand types: VPCMPESTRI " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPESTRM(Instruction):
    """Packed Compare Explicit Length Strings, Return Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPESTRM(xmm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPESTRM, self).__init__("VPCMPESTRM", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPESTRM\" requires 3 operands")
        self.in_regs = (True, True, False)
        self.out_regs = (False, False, False)
        self.out_operands = (False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x60, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self._implicit_in_regs = {0: 7, 2: 7}
            self._implicit_out_regs = {0: 256}
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x60]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self._implicit_in_regs = {0: 7, 2: 7}
            self._implicit_out_regs = {0: 256}
        else:
            raise SyntaxError("Invalid operand types: VPCMPESTRM " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPISTRI(Instruction):
    """Packed Compare Implicit Length Strings, Return Index"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPISTRI(xmm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPISTRI, self).__init__("VPCMPISTRI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPISTRI\" requires 3 operands")
        self.in_regs = (True, True, False)
        self.out_regs = (False, False, False)
        self.out_operands = (False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x63, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self._implicit_out_regs = {1: 7}
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x63]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self._implicit_out_regs = {1: 7}
        else:
            raise SyntaxError("Invalid operand types: VPCMPISTRI " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPCMPISTRM(Instruction):
    """Packed Compare Implicit Length Strings, Return Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPCMPISTRM(xmm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPCMPISTRM, self).__init__("VPCMPISTRM", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPCMPISTRM\" requires 3 operands")
        self.in_regs = (True, True, False)
        self.out_regs = (False, False, False)
        self.out_operands = (False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x62, 0xC0 | op[0].lcode << 3 | op[1].lcode, op[2] & 0xFF])))
            self._implicit_out_regs = {0: 256}
        elif is_xmm(self.operands[0]) and is_m128(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[0].hcode, op[1].address) + bytearray([0x62]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self._implicit_out_regs = {0: 256}
        else:
            raise SyntaxError("Invalid operand types: VPCMPISTRM " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSS2SI(Instruction):
    """Convert Scalar Single-Precision FP Value to Dword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSS2SI(r32, xmm, {er})    [AVX512F]
            * VCVTSS2SI(r32, xmm/m32)      [AVX512F]
            * VCVTSS2SI(r32, xmm/m32)      [AVX]
            * VCVTSS2SI(r64, xmm, {er})    [AVX512F]
            * VCVTSS2SI(r64, xmm/m32)      [AVX512F]
            * VCVTSS2SI(r64, xmm/m32)      [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSS2SI, self).__init__("VCVTSS2SI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFA, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x82, op[0].hcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x48, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x48, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2SI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[2].code << 5) | 0x18, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[2].code << 5) | 0x18, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2SI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSS2SI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSS2USI(Instruction):
    """Convert Scalar Single-Precision Floating-Point Value to Unsigned Doubleword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSS2USI(r32, xmm, {er})    [AVX512F]
            * VCVTSS2USI(r32, xmm/m32)      [AVX512F]
            * VCVTSS2USI(r64, xmm, {er})    [AVX512F]
            * VCVTSS2USI(r64, xmm/m32)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSS2USI, self).__init__("VCVTSS2USI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2USI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[2].code << 5) | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[2].code << 5) | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2USI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSS2USI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTSS2SI(Instruction):
    """Convert with Truncation Scalar Single-Precision FP Value to Dword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTSS2SI(r32, xmm, {sae})    [AVX512F]
            * VCVTTSS2SI(r32, xmm/m32)       [AVX512F]
            * VCVTTSS2SI(r32, xmm/m32)       [AVX]
            * VCVTTSS2SI(r64, xmm, {sae})    [AVX512F]
            * VCVTTSS2SI(r64, xmm/m32)       [AVX512F]
            * VCVTTSS2SI(r64, xmm/m32)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTSS2SI, self).__init__("VCVTTSS2SI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFA, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x82, op[0].hcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x48, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x48, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTSS2SI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x18, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x18, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSS2SI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTSS2SI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTSS2USI(Instruction):
    """Convert with Truncation Scalar Single-Precision Floating-Point Value to Unsigned Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTSS2USI(r32, xmm, {sae})    [AVX512F]
            * VCVTTSS2USI(r32, xmm/m32)       [AVX512F]
            * VCVTTSS2USI(r64, xmm, {sae})    [AVX512F]
            * VCVTTSS2USI(r64, xmm/m32)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTSS2USI, self).__init__("VCVTTSS2USI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            elif is_r64(self.operands[0]) and is_m32(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=4)))
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSS2USI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSS2USI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTSS2USI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSI2SS(Instruction):
    """Convert Dword Integer to Scalar Single-Precision FP Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSI2SS(xmm, xmm, r32, {er})    [AVX512F]
            * VCVTSI2SS(xmm, xmm, r32/m32)      [AVX512F]
            * VCVTSI2SS(xmm, xmm, r32/m32)      [AVX]
            * VCVTSI2SS(xmm, xmm, r64, {er})    [AVX512F]
            * VCVTSI2SS(xmm, xmm, r64/m64)      [AVX512F]
            * VCVTSI2SS(xmm, xmm, r64/m64)      [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSI2SS, self).__init__("VCVTSI2SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xFA ^ (op[1].hlcode << 3), 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x82, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSI2SS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSI2SS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSI2SS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUSI2SS(Instruction):
    """Convert Unsigned Integer to Scalar Single-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUSI2SS(xmm, xmm, r32, {er})    [AVX512F]
            * VCVTUSI2SS(xmm, xmm, r32/m32)      [AVX512F]
            * VCVTUSI2SS(xmm, xmm, r64, {er})    [AVX512F]
            * VCVTUSI2SS(xmm, xmm, r64/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUSI2SS, self).__init__("VCVTUSI2SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTUSI2SS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            self.in_regs = (False, True, True, False)
            self.out_regs = (True, False, False, False)
            self.out_operands = (True, False, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTUSI2SS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTUSI2SS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSD2SI(Instruction):
    """Convert Scalar Double-Precision FP Value to Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSD2SI(r32, xmm, {er})    [AVX512F]
            * VCVTSD2SI(r32, xmm/m64)      [AVX512F]
            * VCVTSD2SI(r32, xmm/m64)      [AVX]
            * VCVTSD2SI(r64, xmm, {er})    [AVX512F]
            * VCVTSD2SI(r64, xmm/m64)      [AVX512F]
            * VCVTSD2SI(r64, xmm/m64)      [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSD2SI, self).__init__("VCVTSD2SI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[1], 0, vex3) + bytearray([0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFB, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x83, op[0].hcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2D]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x48, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x48, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2SI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[2].code << 5) | 0x18, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[2].code << 5) | 0x18, 0x2D, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2SI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSD2SI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSD2USI(Instruction):
    """Convert Scalar Double-Precision Floating-Point Value to Unsigned Doubleword Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSD2USI(r32, xmm, {er})    [AVX512F]
            * VCVTSD2USI(r32, xmm/m64)      [AVX512F]
            * VCVTSD2USI(r64, xmm, {er})    [AVX512F]
            * VCVTSD2USI(r64, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSD2USI, self).__init__("VCVTSD2USI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2USI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[2].code << 5) | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[2].code << 5) | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2USI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSD2USI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTSD2SI(Instruction):
    """Convert with Truncation Scalar Double-Precision FP Value to Signed Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTSD2SI(r32, xmm, {sae})    [AVX512F]
            * VCVTTSD2SI(r32, xmm/m64)       [AVX512F]
            * VCVTTSD2SI(r32, xmm/m64)       [AVX]
            * VCVTTSD2SI(r64, xmm, {sae})    [AVX512F]
            * VCVTTSD2SI(r64, xmm/m64)       [AVX512F]
            * VCVTTSD2SI(r64, xmm/m64)       [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTSD2SI, self).__init__("VCVTTSD2SI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_r32(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[1], 0, vex3) + bytearray([0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0xFB, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x83, op[0].hcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address) + bytearray([0x2C]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x48, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x48, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTSD2SI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x18, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x18, 0x2C, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSD2SI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTSD2SI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTSD2USI(Instruction):
    """Convert with Truncation Scalar Double-Precision Floating-Point Value to Unsigned Integer"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTSD2USI(r32, xmm, {sae})    [AVX512F]
            * VCVTTSD2USI(r32, xmm/m64)       [AVX512F]
            * VCVTTSD2USI(r64, xmm, {sae})    [AVX512F]
            * VCVTTSD2USI(r64, xmm/m64)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTSD2USI, self).__init__("VCVTTSD2USI", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            elif is_r64(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            elif is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSD2USI " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_r32(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            elif is_r64(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTTSD2USI " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTSD2USI\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSI2SD(Instruction):
    """Convert Dword Integer to Scalar Double-Precision FP Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSI2SD(xmm, xmm, r32/m32)      [AVX512F]
            * VCVTSI2SD(xmm, xmm, r32/m32)      [AVX]
            * VCVTSI2SD(xmm, xmm, r64, {er})    [AVX512F]
            * VCVTSI2SD(xmm, xmm, r64/m64)      [AVX512F]
            * VCVTSI2SD(xmm, xmm, r64/m64)      [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSI2SD, self).__init__("VCVTSI2SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE1 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0xFB ^ (op[1].hlcode << 3), 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b1, 0x83, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x2A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSI2SD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x2A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSI2SD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSI2SD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUSI2SD(Instruction):
    """Convert Unsigned Integer to Scalar Double-Precision Floating-Point Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUSI2SD(xmm, xmm, r32/m32)      [AVX512F]
            * VCVTUSI2SD(xmm, xmm, r64, {er})    [AVX512F]
            * VCVTUSI2SD(xmm, xmm, r64/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUSI2SD, self).__init__("VCVTUSI2SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r32(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x00, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
            elif is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | 0x40, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            else:
                raise SyntaxError("Invalid operand types: VCVTUSI2SD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_evex_xmm(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_r64(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | 0x10, 0x7B, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTUSI2SD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTUSI2SD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2DQ(Instruction):
    """Convert Packed Single-Precision FP Values to Packed Dword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2DQ(xmm, xmm/m128)              [AVX]
            * VCVTPS2DQ(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTPS2DQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPS2DQ(ymm, ymm/m256)              [AVX]
            * VCVTPS2DQ(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTPS2DQ(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTPS2DQ(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTPS2DQ(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTPS2DQ(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2DQ, self).__init__("VCVTPS2DQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2DQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2DQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2DQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2UDQ(Instruction):
    """Convert Packed Single-Precision Floating-Point Values to Packed Unsigned Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2UDQ(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTPS2UDQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPS2UDQ(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTPS2UDQ(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTPS2UDQ(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTPS2UDQ(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTPS2UDQ(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2UDQ, self).__init__("VCVTPS2UDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2UDQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPS2DQ(Instruction):
    """Convert with Truncation Packed Single-Precision FP Values to Packed Dword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPS2DQ(xmm, xmm/m128)              [AVX]
            * VCVTTPS2DQ(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTTPS2DQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTTPS2DQ(ymm, ymm/m256)              [AVX]
            * VCVTTPS2DQ(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTTPS2DQ(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTTPS2DQ(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTTPS2DQ(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTTPS2DQ(zmm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPS2DQ, self).__init__("VCVTTPS2DQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2DQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2DQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPS2DQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPS2UDQ(Instruction):
    """Convert with Truncation Packed Single-Precision Floating-Point Values to Packed Unsigned Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPS2UDQ(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTTPS2UDQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTTPS2UDQ(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTTPS2UDQ(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTTPS2UDQ(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTTPS2UDQ(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTTPS2UDQ(zmm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPS2UDQ, self).__init__("VCVTTPS2UDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPS2UDQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTDQ2PS(Instruction):
    """Convert Packed Dword Integers to Packed Single-Precision FP Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTDQ2PS(xmm, xmm/m128)              [AVX]
            * VCVTDQ2PS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTDQ2PS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTDQ2PS(ymm, ymm/m256)              [AVX]
            * VCVTDQ2PS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTDQ2PS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTDQ2PS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTDQ2PS(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTDQ2PS(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTDQ2PS, self).__init__("VCVTDQ2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTDQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTDQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTDQ2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUDQ2PS(Instruction):
    """Convert Packed Unsigned Doubleword Integers to Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUDQ2PS(xmm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTUDQ2PS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTUDQ2PS(ymm{k}{z}, m256/m32bcst)    [AVX512F and AVX512VL]
            * VCVTUDQ2PS(ymm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTUDQ2PS(zmm{k}{z}, m512/m32bcst)    [AVX512F]
            * VCVTUDQ2PS(zmm{k}{z}, zmm)             [AVX512F]
            * VCVTUDQ2PS(zmm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUDQ2PS, self).__init__("VCVTUDQ2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x07, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTUDQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7F, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTUDQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTUDQ2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2QQ(Instruction):
    """Convert Packed Single Precision Floating-Point Values to Packed Singed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2QQ(xmm{k}{z}, m64/m32bcst)     [AVX512DQ and AVX512VL]
            * VCVTPS2QQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPS2QQ(ymm{k}{z}, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VCVTPS2QQ(ymm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPS2QQ(zmm{k}{z}, m256/m32bcst)    [AVX512DQ]
            * VCVTPS2QQ(zmm{k}{z}, ymm)             [AVX512DQ]
            * VCVTPS2QQ(zmm{k}{z}, ymm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2QQ, self).__init__("VCVTPS2QQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2QQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2QQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2QQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2UQQ(Instruction):
    """Convert Packed Single Precision Floating-Point Values to Packed Unsigned Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2UQQ(xmm{k}{z}, m64/m32bcst)     [AVX512DQ and AVX512VL]
            * VCVTPS2UQQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPS2UQQ(ymm{k}{z}, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VCVTPS2UQQ(ymm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPS2UQQ(zmm{k}{z}, m256/m32bcst)    [AVX512DQ]
            * VCVTPS2UQQ(zmm{k}{z}, ymm)             [AVX512DQ]
            * VCVTPS2UQQ(zmm{k}{z}, ymm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2UQQ, self).__init__("VCVTPS2UQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2UQQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPS2QQ(Instruction):
    """Convert with Truncation Packed Single Precision Floating-Point Values to Packed Singed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPS2QQ(xmm{k}{z}, m64/m32bcst)     [AVX512DQ and AVX512VL]
            * VCVTTPS2QQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPS2QQ(ymm{k}{z}, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPS2QQ(ymm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPS2QQ(zmm{k}{z}, m256/m32bcst)    [AVX512DQ]
            * VCVTTPS2QQ(zmm{k}{z}, ymm)             [AVX512DQ]
            * VCVTTPS2QQ(zmm{k}{z}, ymm, {sae})      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPS2QQ, self).__init__("VCVTTPS2QQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2QQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2QQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPS2QQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPS2UQQ(Instruction):
    """Convert with Truncation Packed Single Precision Floating-Point Values to Packed Unsigned Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPS2UQQ(xmm{k}{z}, m64/m32bcst)     [AVX512DQ and AVX512VL]
            * VCVTTPS2UQQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPS2UQQ(ymm{k}{z}, m128/m32bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPS2UQQ(ymm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPS2UQQ(zmm{k}{z}, m256/m32bcst)    [AVX512DQ]
            * VCVTTPS2UQQ(zmm{k}{z}, ymm)             [AVX512DQ]
            * VCVTTPS2UQQ(zmm{k}{z}, ymm, {sae})      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPS2UQQ, self).__init__("VCVTTPS2UQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPS2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPS2UQQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTQQ2PS(Instruction):
    """Convert Packed Quadword Integers to Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTQQ2PS(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTQQ2PS(xmm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTQQ2PS(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTQQ2PS(xmm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTQQ2PS(ymm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTQQ2PS(ymm{k}{z}, zmm)             [AVX512DQ]
            * VCVTQQ2PS(ymm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTQQ2PS, self).__init__("VCVTQQ2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTQQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x5B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTQQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTQQ2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUQQ2PS(Instruction):
    """Convert Packed Unsigned Quadword Integers to Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUQQ2PS(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTUQQ2PS(xmm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTUQQ2PS(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTUQQ2PS(xmm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTUQQ2PS(ymm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTUQQ2PS(ymm{k}{z}, zmm)             [AVX512DQ]
            * VCVTUQQ2PS(ymm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUQQ2PS, self).__init__("VCVTUQQ2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTUQQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTUQQ2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTUQQ2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPD2DQ(Instruction):
    """Convert Packed Double-Precision FP Values to Packed Dword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPD2DQ(xmm, xmm/m128)              [AVX]
            * VCVTPD2DQ(xmm, ymm/m256)              [AVX]
            * VCVTPD2DQ(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2DQ(xmm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2DQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPD2DQ(xmm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTPD2DQ(ymm{k}{z}, m512/m64bcst)    [AVX512F]
            * VCVTPD2DQ(ymm{k}{z}, zmm)             [AVX512F]
            * VCVTPD2DQ(ymm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPD2DQ, self).__init__("VCVTPD2DQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(7, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(7, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2DQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2DQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPD2DQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPD2UDQ(Instruction):
    """Convert Packed Double-Precision Floating-Point Values to Packed Unsigned Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPD2UDQ(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2UDQ(xmm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2UDQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPD2UDQ(xmm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTPD2UDQ(ymm{k}{z}, m512/m64bcst)    [AVX512F]
            * VCVTPD2UDQ(ymm{k}{z}, zmm)             [AVX512F]
            * VCVTPD2UDQ(ymm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPD2UDQ, self).__init__("VCVTPD2UDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPD2UDQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPD2DQ(Instruction):
    """Convert with Truncation Packed Double-Precision FP Values to Packed Dword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPD2DQ(xmm, xmm/m128)              [AVX]
            * VCVTTPD2DQ(xmm, ymm/m256)              [AVX]
            * VCVTTPD2DQ(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VCVTTPD2DQ(xmm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VCVTTPD2DQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTTPD2DQ(xmm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTTPD2DQ(ymm{k}{z}, m512/m64bcst)    [AVX512F]
            * VCVTTPD2DQ(ymm{k}{z}, zmm)             [AVX512F]
            * VCVTTPD2DQ(ymm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPD2DQ, self).__init__("VCVTTPD2DQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2DQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2DQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPD2DQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPD2UDQ(Instruction):
    """Convert with Truncation Packed Double-Precision Floating-Point Values to Packed Unsigned Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPD2UDQ(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VCVTTPD2UDQ(xmm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VCVTTPD2UDQ(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTTPD2UDQ(xmm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTTPD2UDQ(ymm{k}{z}, m512/m64bcst)    [AVX512F]
            * VCVTTPD2UDQ(ymm{k}{z}, zmm)             [AVX512F]
            * VCVTTPD2UDQ(ymm{k}{z}, zmm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPD2UDQ, self).__init__("VCVTTPD2UDQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x84, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFC, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2UDQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPD2UDQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTDQ2PD(Instruction):
    """Convert Packed Dword Integers to Packed Double-Precision FP Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTDQ2PD(xmm, xmm/m64)               [AVX]
            * VCVTDQ2PD(xmm{k}{z}, m64/m32bcst)     [AVX512F and AVX512VL]
            * VCVTDQ2PD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTDQ2PD(ymm, xmm/m128)              [AVX]
            * VCVTDQ2PD(ymm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTDQ2PD(ymm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTDQ2PD(zmm{k}{z}, m256/m32bcst)    [AVX512F]
            * VCVTDQ2PD(zmm{k}{z}, ymm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTDQ2PD, self).__init__("VCVTDQ2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VCVTDQ2PD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
            self.encodings.append((0x40, lambda op, vex3=False: vex2(6, op[0].hcode, op[1], 0, vex3) + bytearray([0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(6, op[0].hcode, op[1].address, 0, vex3) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        elif is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VCVTDQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUDQ2PD(Instruction):
    """Convert Packed Unsigned Doubleword Integers to Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUDQ2PD(xmm{k}{z}, m64/m32bcst)     [AVX512F and AVX512VL]
            * VCVTUDQ2PD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTUDQ2PD(ymm{k}{z}, m128/m32bcst)    [AVX512F and AVX512VL]
            * VCVTUDQ2PD(ymm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTUDQ2PD(zmm{k}{z}, m256/m32bcst)    [AVX512F]
            * VCVTUDQ2PD(zmm{k}{z}, ymm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUDQ2PD, self).__init__("VCVTUDQ2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VCVTUDQ2PD\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VCVTUDQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPD2QQ(Instruction):
    """Convert Packed Double-Precision Floating-Point Values to Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPD2QQ(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTPD2QQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPD2QQ(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTPD2QQ(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTPD2QQ(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTPD2QQ(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTPD2QQ(zmm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPD2QQ, self).__init__("VCVTPD2QQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2QQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x7B, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2QQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPD2QQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPD2UQQ(Instruction):
    """Convert Packed Double-Precision Floating-Point Values to Packed Unsigned Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPD2UQQ(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTPD2UQQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTPD2UQQ(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTPD2UQQ(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTPD2UQQ(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTPD2UQQ(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTPD2UQQ(zmm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPD2UQQ, self).__init__("VCVTPD2UQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x79]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x79, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPD2UQQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPD2QQ(Instruction):
    """Convert with Truncation Packed Double-Precision Floating-Point Values to Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPD2QQ(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPD2QQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPD2QQ(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPD2QQ(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTTPD2QQ(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTTPD2QQ(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTTPD2QQ(zmm{k}{z}, zmm, {sae})      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPD2QQ, self).__init__("VCVTTPD2QQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2QQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2QQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPD2QQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTTPD2UQQ(Instruction):
    """Convert with Truncation Packed Double-Precision Floating-Point Values to Packed Unsigned Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTTPD2UQQ(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPD2UQQ(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTTPD2UQQ(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTTPD2UQQ(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTTPD2UQQ(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTTPD2UQQ(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTTPD2UQQ(zmm{k}{z}, zmm, {sae})      [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTTPD2UQQ, self).__init__("VCVTTPD2UQQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x78]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x78, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTTPD2UQQ " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTTPD2UQQ\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTQQ2PD(Instruction):
    """Convert Packed Quadword Integers to Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTQQ2PD(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTQQ2PD(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTQQ2PD(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTQQ2PD(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTQQ2PD(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTQQ2PD(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTQQ2PD(zmm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTQQ2PD, self).__init__("VCVTQQ2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x48, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0xE6]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x08, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x28, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTQQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0xE6, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTQQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTQQ2PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTUQQ2PD(Instruction):
    """Convert Packed Unsigned Quadword Integers to Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTUQQ2PD(xmm{k}{z}, m128/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTUQQ2PD(xmm{k}{z}, xmm)             [AVX512DQ and AVX512VL]
            * VCVTUQQ2PD(ymm{k}{z}, m256/m64bcst)    [AVX512DQ and AVX512VL]
            * VCVTUQQ2PD(ymm{k}{z}, ymm)             [AVX512DQ and AVX512VL]
            * VCVTUQQ2PD(zmm{k}{z}, m512/m64bcst)    [AVX512DQ]
            * VCVTUQQ2PD(zmm{k}{z}, zmm)             [AVX512DQ]
            * VCVTUQQ2PD(zmm{k}{z}, zmm, {er})       [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTUQQ2PD, self).__init__("VCVTUQQ2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_zmmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x86, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x7A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTUQQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFE, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x7A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
            else:
                raise SyntaxError("Invalid operand types: VCVTUQQ2PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTUQQ2PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSD2SS(Instruction):
    """Convert Scalar Double-Precision FP Value to Scalar Single-Precision FP Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSD2SS(xmm, xmm, xmm/m64)            [AVX]
            * VCVTSD2SS(xmm{k}{z}, xmm, xmm, {er})    [AVX512F]
            * VCVTSD2SS(xmm{k}{z}, xmm, xmm/m64)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSD2SS, self).__init__("VCVTSD2SS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(3, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(3, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m64(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x87, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2SS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_er(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFF ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[3].code << 5) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSD2SS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSD2SS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTSS2SD(Instruction):
    """Convert Scalar Single-Precision FP Value to Scalar Double-Precision FP Value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTSS2SD(xmm, xmm, xmm/m32)             [AVX]
            * VCVTSS2SD(xmm{k}{z}, xmm, xmm, {sae})    [AVX512F]
            * VCVTSS2SD(xmm{k}{z}, xmm, xmm/m32)       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTSS2SD, self).__init__("VCVTSS2SD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.in_regs = (False, True, True)
            self.out_regs = (True, False, False)
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_xmm(self.operands[2]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(2, op[0].hcode, op[2], op[1].hlcode, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(2, op[0].hcode, op[2].address, op[1].hlcode, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m32(self.operands[2]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=4)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2SD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_sae(self.operands[3]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7E ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x10, 0x5A, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
                self.in_regs = (False, True, True, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTSS2SD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTSS2SD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPD2PS(Instruction):
    """Convert Packed Double-Precision FP Values to Packed Single-Precision FP Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPD2PS(xmm, xmm/m128)              [AVX]
            * VCVTPD2PS(xmm, ymm/m256)              [AVX]
            * VCVTPD2PS(xmm{k}{z}, m128/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2PS(xmm{k}{z}, m256/m64bcst)    [AVX512F and AVX512VL]
            * VCVTPD2PS(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPD2PS(xmm{k}{z}, ymm)             [AVX512F and AVX512VL]
            * VCVTPD2PS(ymm{k}{z}, m512/m64bcst)    [AVX512F]
            * VCVTPD2PS(ymm{k}{z}, zmm)             [AVX512F]
            * VCVTPD2PS(ymm{k}{z}, zmm, {er})       [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPD2PS, self).__init__("VCVTPD2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(1, op[0].hcode, op[1], 0, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_ymm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(5, op[0].hcode, op[1], 0, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(1, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(5, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymmkz(self.operands[0]) and is_m512_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=64)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m128_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m256_m64bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_er(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0xFD, (op[0].zcode << 7) | (op[2].code << 5) | op[0].kcode | 0x18, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPD2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPD2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2PD(Instruction):
    """Convert Packed Single-Precision FP Values to Packed Double-Precision FP Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2PD(xmm, xmm/m64)               [AVX]
            * VCVTPS2PD(xmm{k}{z}, m64/m32bcst)     [AVX512F and AVX512VL]
            * VCVTPS2PD(xmm{k}{z}, xmm)             [AVX512F and AVX512VL]
            * VCVTPS2PD(ymm, xmm/m128)              [AVX]
            * VCVTPS2PD(ymm{k}{z}, m128/m32bcst)    [AVX512VL]
            * VCVTPS2PD(ymm{k}{z}, xmm)             [AVX512VL]
            * VCVTPS2PD(zmm{k}{z}, m256/m32bcst)    [AVX512F]
            * VCVTPS2PD(zmm{k}{z}, ymm)             [AVX512F]
            * VCVTPS2PD(zmm{k}{z}, ymm, {sae})      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2PD, self).__init__("VCVTPS2PD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(0, op[0].hcode, op[1], 0, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x40, lambda op, vex3=False: vex2(4, op[0].hcode, op[1], 0, vex3) + bytearray([0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(4, op[0].hcode, op[1].address, 0, vex3) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
            elif is_zmmkz(self.operands[0]) and is_m256_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m64_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m128_m32bcst(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b01, 0x04, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode, b=op[1].bcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2PD " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 241, 0x7C, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x5A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2PD " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2PD\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPS2PH(Instruction):
    """Convert Single-Precision FP value to Half-Precision FP value"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPS2PH(m128{k}{z}, ymm, imm8)          [AVX512F and AVX512VL]
            * VCVTPS2PH(m256{k}{z}, zmm, imm8)          [AVX512F]
            * VCVTPS2PH(m64{k}{z}, xmm, imm8)           [AVX512F and AVX512VL]
            * VCVTPS2PH(xmm/m128, ymm, imm8)            [F16C]
            * VCVTPS2PH(xmm/m64, xmm, imm8)             [F16C]
            * VCVTPS2PH(xmm{k}{z}, xmm, imm8)           [AVX512F and AVX512VL]
            * VCVTPS2PH(xmm{k}{z}, ymm, imm8)           [AVX512F and AVX512VL]
            * VCVTPS2PH(ymm{k}{z}, zmm, imm8)           [AVX512F]
            * VCVTPS2PH(ymm{k}{z}, zmm, {sae}, imm8)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPS2PH, self).__init__("VCVTPS2PH", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 3:
            self.out_operands = (True, False, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x79, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_xmm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x7D, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_m64(self.operands[0]) and is_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x01, op[1].hcode, op[0].address) + bytearray([0x1D]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_m128(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[1].hcode, op[0].address) + bytearray([0x1D]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_m64kz(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b00, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=8) + bytearray([op[2] & 0xFF])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
                if not is_imm8(self.operands[2]):
                    raise ValueError("Argument #2 can not be encoded as imm8")
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1D]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
                self.in_regs = (True, True, False)
                self.out_regs = (False, False, False)
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2PH " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 4:
            if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_sae(self.operands[2]) and is_imm(self.operands[3]):
                if not is_imm8(self.operands[3]):
                    raise ValueError("Argument #3 can not be encoded as imm8")
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x1D, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[3] & 0xFF])))
                self.in_regs = (False, True, False, False)
                self.out_regs = (True, False, False, False)
                self.out_operands = (True, False, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPS2PH " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPS2PH\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VCVTPH2PS(Instruction):
    """Convert Half-Precision FP Values to Single-Precision FP Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VCVTPH2PS(xmm, xmm/m64)             [F16C]
            * VCVTPH2PS(xmm{k}{z}, xmm/m64)       [AVX512F and AVX512VL]
            * VCVTPH2PS(ymm, xmm/m128)            [F16C]
            * VCVTPH2PS(ymm{k}{z}, xmm/m128)      [AVX512F and AVX512VL]
            * VCVTPH2PS(zmm{k}{z}, ymm, {sae})    [AVX512F]
            * VCVTPH2PS(zmm{k}{z}, ymm/m256)      [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VCVTPH2PS, self).__init__("VCVTPH2PS", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) == 2:
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            if is_xmm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x79, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_xmm(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x01, op[0].hcode, op[1].address) + bytearray([0x13]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_ymm(self.operands[0]) and is_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE2 ^ (op[0].hcode << 7) ^ (op[1].hcode << 5), 0x7D, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_ymm(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x13]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.f16c])
            elif is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
                self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x13]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPH2PS " + ", ".join(map(format_operand_type, self.operands)))
        elif len(self.operands) == 3:
            if is_zmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_sae(self.operands[2]):
                self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x18, 0x13, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
                self.in_regs = (False, True, False)
                self.out_regs = (True, False, False)
                self.out_operands = (True, False, False)
                self.avx_mode = True
                self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
            else:
                raise SyntaxError("Invalid operand types: VCVTPH2PS " + ", ".join(map(format_operand_type, self.operands)))
        else:
            raise SyntaxError("Invalid number of operands for instruction \"VCVTPH2PS\"")
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF128(Instruction):
    """Broadcast 128 Bit of Floating-Point Data"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF128(ymm, m128)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF128, self).__init__("VBROADCASTF128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF128\" requires 2 operands")
        if is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI128(Instruction):
    """Broadcast 128 Bits of Integer Data"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI128(ymm, m128)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI128, self).__init__("VBROADCASTI128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI128\" requires 2 operands")
        if is_ymm(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b10, 0x05, op[0].hcode, op[1].address) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF32X2(Instruction):
    """Broadcast Two Single-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF32X2(ymm{k}{z}, xmm/m64)    [AVX512DQ and AVX512VL]
            * VBROADCASTF32X2(zmm{k}{z}, xmm/m64)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF32X2, self).__init__("VBROADCASTF32X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF32X2\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x19, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x19, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF32X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI32X2(Instruction):
    """Broadcast Two Doubleword Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI32X2(xmm{k}{z}, xmm/m64)    [AVX512DQ and AVX512VL]
            * VBROADCASTI32X2(ymm{k}{z}, xmm/m64)    [AVX512DQ and AVX512VL]
            * VBROADCASTI32X2(zmm{k}{z}, xmm/m64)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI32X2, self).__init__("VBROADCASTI32X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI32X2\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x08, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x59, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m64(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x59]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=8)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI32X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF32X4(Instruction):
    """Broadcast Four Single-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF32X4(ymm{k}{z}, m128)    [AVX512F and AVX512VL]
            * VBROADCASTF32X4(zmm{k}{z}, m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF32X4, self).__init__("VBROADCASTF32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF32X4\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI32X4(Instruction):
    """Broadcast Four Doubleword Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI32X4(ymm{k}{z}, m128)    [AVX512F and AVX512VL]
            * VBROADCASTI32X4(zmm{k}{z}, m128)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI32X4, self).__init__("VBROADCASTI32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI32X4\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF32X8(Instruction):
    """Broadcast Eight Single-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF32X8(zmm{k}{z}, m256)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF32X8, self).__init__("VBROADCASTF32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF32X8\" requires 2 operands")
        if is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI32X8(Instruction):
    """Broadcast Eight Doubleword Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI32X8(zmm{k}{z}, m256)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI32X8, self).__init__("VBROADCASTI32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI32X8\" requires 2 operands")
        if is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF64X2(Instruction):
    """Broadcast Two Double-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF64X2(ymm{k}{z}, m128)    [AVX512DQ and AVX512VL]
            * VBROADCASTF64X2(zmm{k}{z}, m128)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF64X2, self).__init__("VBROADCASTF64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF64X2\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI64X2(Instruction):
    """Broadcast Two Quadword Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI64X2(ymm{k}{z}, m128)    [AVX512DQ and AVX512VL]
            * VBROADCASTI64X2(zmm{k}{z}, m128)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI64X2, self).__init__("VBROADCASTI64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI64X2\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_m128(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5A]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTF64X4(Instruction):
    """Broadcast Four Double-Precision Floating-Point Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTF64X4(zmm{k}{z}, m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTF64X4, self).__init__("VBROADCASTF64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTF64X4\" requires 2 operands")
        if is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTF64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VBROADCASTI64X4(Instruction):
    """Broadcast Four Quadword Elements"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VBROADCASTI64X4(zmm{k}{z}, m256)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VBROADCASTI64X4, self).__init__("VBROADCASTI64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VBROADCASTI64X4\" requires 2 operands")
        if is_zmmkz(self.operands[0]) and is_m256(self.operands[1]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[1].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x5B]) + modrm_sib_disp(op[0].lcode, op[1].address, sib, min_disp, disp8xN=32)))
            self.in_regs = (False, True)
            self.out_regs = (True, False)
            self.out_operands = (True, False)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VBROADCASTI64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTF128(Instruction):
    """Extract Packed Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTF128(xmm/m128, ymm, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTF128, self).__init__("VEXTRACTF128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTF128\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_xmm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x7D, 0x19, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[1].hcode, op[0].address) + bytearray([0x19]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTF128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTI128(Instruction):
    """Extract Packed Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTI128(xmm/m128, ymm, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTI128, self).__init__("VEXTRACTI128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTI128\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_xmm(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[1].hcode << 7) ^ (op[0].hcode << 5), 0x7D, 0x39, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m128(self.operands[0]) and is_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[1].hcode, op[0].address) + bytearray([0x39]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTI128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTF32X4(Instruction):
    """Extract 128 Bits of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTF32X4(m128{k}{z}, ymm, imm8)    [AVX512F and AVX512VL]
            * VEXTRACTF32X4(m128{k}{z}, zmm, imm8)    [AVX512F]
            * VEXTRACTF32X4(xmm{k}{z}, ymm, imm8)     [AVX512F and AVX512VL]
            * VEXTRACTF32X4(xmm{k}{z}, zmm, imm8)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTF32X4, self).__init__("VEXTRACTF32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTF32X4\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x19, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x19, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTF32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTI32X4(Instruction):
    """Extract 128 Bits of Packed Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTI32X4(m128{k}{z}, ymm, imm8)    [AVX512F and AVX512VL]
            * VEXTRACTI32X4(m128{k}{z}, zmm, imm8)    [AVX512F]
            * VEXTRACTI32X4(xmm{k}{z}, ymm, imm8)     [AVX512F and AVX512VL]
            * VEXTRACTI32X4(xmm{k}{z}, zmm, imm8)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTI32X4, self).__init__("VEXTRACTI32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTI32X4\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x39, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x39]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x39, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x39]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTI32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTF32X8(Instruction):
    """Extract 256 Bits of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTF32X8(m256{k}{z}, zmm, imm8)    [AVX512DQ]
            * VEXTRACTF32X8(ymm{k}{z}, zmm, imm8)     [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTF32X8, self).__init__("VEXTRACTF32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTF32X8\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1B, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTF32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTI32X8(Instruction):
    """Extract 256 Bits of Packed Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTI32X8(m256{k}{z}, zmm, imm8)    [AVX512DQ]
            * VEXTRACTI32X8(ymm{k}{z}, zmm, imm8)     [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTI32X8, self).__init__("VEXTRACTI32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTI32X8\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0x7D, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x3B, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTI32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTF64X2(Instruction):
    """Extract 128 Bits of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTF64X2(m128{k}{z}, ymm, imm8)    [AVX512DQ and AVX512VL]
            * VEXTRACTF64X2(m128{k}{z}, zmm, imm8)    [AVX512DQ]
            * VEXTRACTF64X2(xmm{k}{z}, ymm, imm8)     [AVX512DQ and AVX512VL]
            * VEXTRACTF64X2(xmm{k}{z}, zmm, imm8)     [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTF64X2, self).__init__("VEXTRACTF64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTF64X2\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x19, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x19, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x19]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTF64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTI64X2(Instruction):
    """Extract 128 Bits of Packed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTI64X2(m128{k}{z}, ymm, imm8)    [AVX512DQ and AVX512VL]
            * VEXTRACTI64X2(m128{k}{z}, zmm, imm8)    [AVX512DQ]
            * VEXTRACTI64X2(xmm{k}{z}, ymm, imm8)     [AVX512DQ and AVX512VL]
            * VEXTRACTI64X2(xmm{k}{z}, zmm, imm8)     [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTI64X2, self).__init__("VEXTRACTI64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTI64X2\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_xmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x39, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_m128kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x39]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_xmmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x28, 0x39, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_m128kz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x39]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=16) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTI64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTF64X4(Instruction):
    """Extract 256 Bits of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTF64X4(m256{k}{z}, zmm, imm8)    [AVX512F]
            * VEXTRACTF64X4(ymm{k}{z}, zmm, imm8)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTF64X4, self).__init__("VEXTRACTF64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTF64X4\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x1B, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTF64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VEXTRACTI64X4(Instruction):
    """Extract 256 Bits of Packed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VEXTRACTI64X4(m256{k}{z}, zmm, imm8)    [AVX512F]
            * VEXTRACTI64X4(ymm{k}{z}, zmm, imm8)     [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VEXTRACTI64X4, self).__init__("VEXTRACTI64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VEXTRACTI64X4\" requires 3 operands")
        self.out_operands = (True, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_ymmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[1].hcode << 7) | (op[0].ehcode << 5) | (op[1].ecode << 4)) ^ 243, 0xFD, (op[0].zcode << 7) | op[0].kcode | 0x48, 0x3B, 0xC0 | op[1].lcode << 3 | op[0].lcode, op[2] & 0xFF])))
            self.in_regs = (False, True, False)
            self.out_regs = (True, False, False)
        elif is_m256kz(self.operands[0]) and is_zmm(self.operands[1]) and is_imm(self.operands[2]):
            if not is_imm8(self.operands[2]):
                raise ValueError("Argument #2 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[1].ehcode, op[0].address, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3B]) + modrm_sib_disp(op[1].lcode, op[0].address, sib, min_disp, disp8xN=32) + bytearray([op[2] & 0xFF])))
            self.in_regs = (True, True, False)
            self.out_regs = (False, False, False)
        else:
            raise SyntaxError("Invalid operand types: VEXTRACTI64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTF128(Instruction):
    """Insert Packed Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTF128(ymm, ymm, xmm/m128, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTF128, self).__init__("VINSERTF128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTF128\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x18, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTF128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTI128(Instruction):
    """Insert Packed Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTI128(ymm, ymm, xmm/m128, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTI128, self).__init__("VINSERTI128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTI128\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTI128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTF32X4(Instruction):
    """Insert 128 Bits of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTF32X4(ymm{k}{z}, ymm, xmm/m128, imm8)    [AVX512F and AVX512VL]
            * VINSERTF32X4(zmm{k}{z}, zmm, xmm/m128, imm8)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTF32X4, self).__init__("VINSERTF32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTF32X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x18, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x18, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VINSERTF32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTI32X4(Instruction):
    """Insert 128 Bits of Packed Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTI32X4(ymm{k}{z}, ymm, xmm/m128, imm8)    [AVX512F and AVX512VL]
            * VINSERTI32X4(zmm{k}{z}, zmm, xmm/m128, imm8)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTI32X4, self).__init__("VINSERTI32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTI32X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VINSERTI32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTF32X8(Instruction):
    """Insert 256 Bits of Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTF32X8(zmm{k}{z}, zmm, ymm/m256, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTF32X8, self).__init__("VINSERTF32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTF32X8\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTF32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTI32X8(Instruction):
    """Insert 256 Bits of Packed Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTI32X8(zmm{k}{z}, zmm, ymm/m256, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTI32X8, self).__init__("VINSERTI32X8", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTI32X8\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTI32X8 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTF64X2(Instruction):
    """Insert 128 Bits of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTF64X2(ymm{k}{z}, ymm, xmm/m128, imm8)    [AVX512DQ and AVX512VL]
            * VINSERTF64X2(zmm{k}{z}, zmm, xmm/m128, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTF64X2, self).__init__("VINSERTF64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTF64X2\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x18, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x18, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x18]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VINSERTF64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTI64X2(Instruction):
    """Insert 128 Bits of Packed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTI64X2(ymm{k}{z}, ymm, xmm/m128, imm8)    [AVX512DQ and AVX512VL]
            * VINSERTI64X2(zmm{k}{z}, zmm, xmm/m128, imm8)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTI64X2, self).__init__("VINSERTI64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTI64X2\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_xmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x38, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m128(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x38]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VINSERTI64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTF64X4(Instruction):
    """Insert 256 Bits of Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTF64X4(zmm{k}{z}, zmm, ymm/m256, imm8)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTF64X4, self).__init__("VINSERTF64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTF64X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x1A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x1A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTF64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VINSERTI64X4(Instruction):
    """Insert 256 Bits of Packed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VINSERTI64X4(zmm{k}{z}, zmm, ymm/m256, imm8)    [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VINSERTI64X4, self).__init__("VINSERTI64X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VINSERTI64X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x3A, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode) + bytearray([0x3A]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VINSERTI64X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERM2F128(Instruction):
    """Permute Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERM2F128(ymm, ymm, ymm/m256, imm8)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERM2F128, self).__init__("VPERM2F128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPERM2F128\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x06, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x06]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VPERM2F128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPERM2I128(Instruction):
    """Permute 128-Bit Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPERM2I128(ymm, ymm, ymm/m256, imm8)    [AVX2]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPERM2I128, self).__init__("VPERM2I128", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VPERM2I128\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx2])
        if is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0xC4, 0xE3 ^ (op[0].hcode << 7) ^ (op[2].hcode << 5), 0x7D ^ (op[1].hlcode << 3), 0x46, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
        elif is_ymm(self.operands[0]) and is_ymm(self.operands[1]) and is_m256(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x10, lambda op, sib=False, min_disp=0: vex3(0xC4, 0b11, 0x05, op[0].hcode, op[2].address, op[1].hlcode) + bytearray([0x46]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp) + bytearray([op[3] & 0xFF])))
        else:
            raise SyntaxError("Invalid operand types: VPERM2I128 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFF32X4(Instruction):
    """Shuffle 128-Bit Packed Single-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFF32X4(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFF32X4(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFF32X4(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VSHUFF32X4(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFF32X4, self).__init__("VSHUFF32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFF32X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x23, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x23, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFF32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFI32X4(Instruction):
    """Shuffle 128-Bit Packed Doubleword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFI32X4(ymm{k}{z}, ymm, m256/m32bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFI32X4(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFI32X4(zmm{k}{z}, zmm, m512/m32bcst, imm8)    [AVX512F]
            * VSHUFI32X4(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFI32X4, self).__init__("VSHUFI32X4", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFI32X4\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0x7D ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFI32X4 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFF64X2(Instruction):
    """Shuffle 128-Bit Packed Double-Precision Floating-Point Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFF64X2(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFF64X2(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFF64X2(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VSHUFF64X2(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFF64X2, self).__init__("VSHUFF64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFF64X2\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x23, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x23]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x23, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFF64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSHUFI64X2(Instruction):
    """Shuffle 128-Bit Packed Quadword Integer Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSHUFI64X2(ymm{k}{z}, ymm, m256/m64bcst, imm8)    [AVX512F and AVX512VL]
            * VSHUFI64X2(ymm{k}{z}, ymm, ymm, imm8)             [AVX512F and AVX512VL]
            * VSHUFI64X2(zmm{k}{z}, zmm, m512/m64bcst, imm8)    [AVX512F]
            * VSHUFI64X2(zmm{k}{z}, zmm, zmm, imm8)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSHUFI64X2, self).__init__("VSHUFI64X2", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 4:
            raise SyntaxError("Instruction \"VSHUFI64X2\" requires 4 operands")
        self.in_regs = (False, True, True, False)
        self.out_regs = (True, False, False, False)
        self.out_operands = (True, False, False, False)
        self.avx_mode = True
        if is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_zmmkz(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b11, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, z=op[0].zcode, b=op[2].bcode) + bytearray([0x43]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32) + bytearray([op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_ymmkz(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]) and is_imm(self.operands[3]):
            if not is_imm8(self.operands[3]):
                raise ValueError("Argument #3 can not be encoded as imm8")
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 243, 0xFD ^ (op[1].hlcode << 3), (op[0].zcode << 7) | (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x43, 0xC0 | op[0].lcode << 3 | op[2].lcode, op[3] & 0xFF])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VSHUFI64X2 " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVB2M(Instruction):
    """Move Signs of Packed Byte Integers to Mask Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVB2M(k, xmm)    [AVX512BW and AVX512VL]
            * VPMOVB2M(k, ymm)    [AVX512BW and AVX512VL]
            * VPMOVB2M(k, zmm)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVB2M, self).__init__("VPMOVB2M", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVB2M\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_k(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x48, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_k(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x08, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_k(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x28, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVB2M " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVW2M(Instruction):
    """Move Signs of Packed Word Integers to Mask Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVW2M(k, xmm)    [AVX512BW and AVX512VL]
            * VPMOVW2M(k, ymm)    [AVX512BW and AVX512VL]
            * VPMOVW2M(k, zmm)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVW2M, self).__init__("VPMOVW2M", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVW2M\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_k(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x48, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_k(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x08, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_k(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x28, 0x29, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVW2M " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVD2M(Instruction):
    """Move Signs of Packed Doubleword Integers to Mask Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVD2M(k, xmm)    [AVX512DQ and AVX512VL]
            * VPMOVD2M(k, ymm)    [AVX512DQ and AVX512VL]
            * VPMOVD2M(k, zmm)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVD2M, self).__init__("VPMOVD2M", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVD2M\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_k(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x48, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_k(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x08, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_k(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x28, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPMOVD2M " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVQ2M(Instruction):
    """Move Signs of Packed Quadword Integers to Mask Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVQ2M(k, xmm)    [AVX512DQ and AVX512VL]
            * VPMOVQ2M(k, ymm)    [AVX512DQ and AVX512VL]
            * VPMOVQ2M(k, zmm)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVQ2M, self).__init__("VPMOVQ2M", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVQ2M\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_k(self.operands[0]) and is_zmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x48, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_k(self.operands[0]) and is_evex_xmm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x08, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_k(self.operands[0]) and is_evex_ymm(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x28, 0x39, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPMOVQ2M " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVM2B(Instruction):
    """Expand Bits of Mask Register to Packed Byte Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVM2B(xmm, k)    [AVX512BW and AVX512VL]
            * VPMOVM2B(ymm, k)    [AVX512BW and AVX512VL]
            * VPMOVM2B(zmm, k)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVM2B, self).__init__("VPMOVM2B", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVM2B\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x48, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x08, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x28, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVM2B " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVM2W(Instruction):
    """Expand Bits of Mask Register to Packed Word Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVM2W(xmm, k)    [AVX512BW and AVX512VL]
            * VPMOVM2W(ymm, k)    [AVX512BW and AVX512VL]
            * VPMOVM2W(zmm, k)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVM2W, self).__init__("VPMOVM2W", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVM2W\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x48, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x08, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x28, 0x28, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPMOVM2W " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVM2D(Instruction):
    """Expand Bits of Mask Register to Packed Doubleword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVM2D(xmm, k)    [AVX512DQ and AVX512VL]
            * VPMOVM2D(ymm, k)    [AVX512DQ and AVX512VL]
            * VPMOVM2D(zmm, k)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVM2D, self).__init__("VPMOVM2D", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVM2D\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x48, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x08, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x28, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPMOVM2D " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPMOVM2Q(Instruction):
    """Expand Bits of Mask Register to Packed Quadword Integers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPMOVM2Q(xmm, k)    [AVX512DQ and AVX512VL]
            * VPMOVM2Q(ymm, k)    [AVX512DQ and AVX512VL]
            * VPMOVM2Q(zmm, k)    [AVX512DQ]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPMOVM2Q, self).__init__("VPMOVM2Q", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPMOVM2Q\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x48, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512dq])
        elif is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x08, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x28, 0x38, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512dq])
        else:
            raise SyntaxError("Invalid operand types: VPMOVM2Q " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTMB2Q(Instruction):
    """Broadcast Low Byte of Mask Register to Packed Quadword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTMB2Q(xmm, k)    [AVX512VL and AVX512CD]
            * VPBROADCASTMB2Q(ymm, k)    [AVX512VL and AVX512CD]
            * VPBROADCASTMB2Q(zmm, k)    [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTMB2Q, self).__init__("VPBROADCASTMB2Q", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTMB2Q\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x08, 0x2A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x28, 0x2A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE, 0x48, 0x2A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTMB2Q " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPBROADCASTMW2D(Instruction):
    """Broadcast Low Word of Mask Register to Packed Doubleword Values"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPBROADCASTMW2D(xmm, k)    [AVX512VL and AVX512CD]
            * VPBROADCASTMW2D(ymm, k)    [AVX512VL and AVX512CD]
            * VPBROADCASTMW2D(zmm, k)    [AVX512CD]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPBROADCASTMW2D, self).__init__("VPBROADCASTMW2D", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 2:
            raise SyntaxError("Instruction \"VPBROADCASTMW2D\" requires 2 operands")
        self.in_regs = (False, True)
        self.out_regs = (True, False)
        self.out_operands = (True, False)
        self.avx_mode = True
        if is_evex_xmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x08, 0x3A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_evex_ymm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x28, 0x3A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512cd])
        elif is_zmm(self.operands[0]) and is_k(self.operands[1]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[1].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E, 0x48, 0x3A, 0xC0 | op[0].lcode << 3 | op[1].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512cd])
        else:
            raise SyntaxError("Invalid operand types: VPBROADCASTMW2D " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTMB(Instruction):
    """Logical AND of Packed Byte Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTMB(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPTESTMB(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPTESTMB(k{k}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTMB, self).__init__("VPTESTMB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTMB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPTESTMB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTMW(Instruction):
    """Logical AND of Packed Word Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTMW(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPTESTMW(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPTESTMW(k{k}, zmm, zmm/m512)    [AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTMW, self).__init__("VPTESTMW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTMW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPTESTMW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTMD(Instruction):
    """Logical AND of Packed Doubleword Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTMD(k{k}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPTESTMD(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPTESTMD(k{k}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPTESTMD(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPTESTMD(k{k}, zmm, m512/m32bcst)    [AVX512F]
            * VPTESTMD(k{k}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTMD, self).__init__("VPTESTMD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTMD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x05, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7D ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTESTMD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTMQ(Instruction):
    """Logical AND of Packed Quadword Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTMQ(k{k}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPTESTMQ(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPTESTMQ(k{k}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPTESTMQ(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPTESTMQ(k{k}, zmm, m512/m64bcst)    [AVX512F]
            * VPTESTMQ(k{k}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTMQ, self).__init__("VPTESTMQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTMQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x85, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFD ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTESTMQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTNMB(Instruction):
    """Logical NAND of Packed Byte Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTNMB(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPTESTNMB(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPTESTNMB(k{k}, zmm, zmm/m512)    [AVX512F and AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTNMB, self).__init__("VPTESTNMB", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTNMB\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPTESTNMB " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTNMW(Instruction):
    """Logical NAND of Packed Word Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTNMW(k{k}, xmm, xmm/m128)    [AVX512BW and AVX512VL]
            * VPTESTNMW(k{k}, ymm, ymm/m256)    [AVX512BW and AVX512VL]
            * VPTESTNMW(k{k}, zmm, zmm/m512)    [AVX512F and AVX512BW]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTNMW, self).__init__("VPTESTNMW", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTNMW\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x26, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode) + bytearray([0x26]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512bw])
        else:
            raise SyntaxError("Invalid operand types: VPTESTNMW " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTNMD(Instruction):
    """Logical NAND of Packed Doubleword Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTNMD(k{k}, xmm, m128/m32bcst)    [AVX512F and AVX512VL]
            * VPTESTNMD(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPTESTNMD(k{k}, ymm, m256/m32bcst)    [AVX512F and AVX512VL]
            * VPTESTNMD(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPTESTNMD(k{k}, zmm, m512/m32bcst)    [AVX512F]
            * VPTESTNMD(k{k}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTNMD, self).__init__("VPTESTNMD", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTNMD\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m32bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x06, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0x7E ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTESTNMD " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VPTESTNMQ(Instruction):
    """Logical NAND of Packed Quadword Integer Values and Set Mask"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VPTESTNMQ(k{k}, xmm, m128/m64bcst)    [AVX512F and AVX512VL]
            * VPTESTNMQ(k{k}, xmm, xmm)             [AVX512F and AVX512VL]
            * VPTESTNMQ(k{k}, ymm, m256/m64bcst)    [AVX512F and AVX512VL]
            * VPTESTNMQ(k{k}, ymm, ymm)             [AVX512F and AVX512VL]
            * VPTESTNMQ(k{k}, zmm, m512/m64bcst)    [AVX512F]
            * VPTESTNMQ(k{k}, zmm, zmm)             [AVX512F]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VPTESTNMQ, self).__init__("VPTESTNMQ", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 3:
            raise SyntaxError("Instruction \"VPTESTNMQ\" requires 3 operands")
        self.in_regs = (False, True, True)
        self.out_regs = (True, False, False)
        self.out_operands = (True, False, False)
        self.avx_mode = True
        if is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_m512_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b10, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=64)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_zmm(self.operands[1]) and is_zmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x40, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_m128_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b00, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=16)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_xmm(self.operands[1]) and is_evex_xmm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x00, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_m256_m64bcst(self.operands[2]):
            self.encodings.append((0x90, lambda op, sib=False, min_disp=0: evex(0b10, 0x86, 0b01, op[0].ehcode, op[2].address, op[1].code, aaa=op[0].kcode, b=op[2].bcode) + bytearray([0x27]) + modrm_sib_disp(op[0].lcode, op[2].address, sib, min_disp, disp8xN=32)))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        elif is_kk(self.operands[0]) and is_evex_ymm(self.operands[1]) and is_evex_ymm(self.operands[2]):
            self.encodings.append((0x00, lambda op: bytearray([0x62, ((op[0].hcode << 7) | (op[2].ehcode << 5) | (op[0].ecode << 4)) ^ 242, 0xFE ^ (op[1].hlcode << 3), (op[1].ecode << 3 ^ 0x8) | op[0].kcode | 0x20, 0x27, 0xC0 | op[0].lcode << 3 | op[2].lcode])))
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx512vl, peachpy.x86_64.isa.avx512f])
        else:
            raise SyntaxError("Invalid operand types: VPTESTNMQ " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VLDMXCSR(Instruction):
    """Load MXCSR Register"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VLDMXCSR(m32)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VLDMXCSR, self).__init__("VLDMXCSR", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VLDMXCSR\" requires 1 operands")
        if is_m32(self.operands[0]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, 0, op[0].address, 0, vex3) + bytearray([0xAE]) + modrm_sib_disp(2, op[0].address, sib, min_disp)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (False,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        else:
            raise SyntaxError("Invalid operand types: VLDMXCSR " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VSTMXCSR(Instruction):
    """Store MXCSR Register State"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VSTMXCSR(m32)    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VSTMXCSR, self).__init__("VSTMXCSR", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 1:
            raise SyntaxError("Instruction \"VSTMXCSR\" requires 1 operands")
        if is_m32(self.operands[0]):
            self.encodings.append((0x50, lambda op, vex3=False, sib=False, min_disp=0: vex2(0, 0, op[0].address, 0, vex3) + bytearray([0xAE]) + modrm_sib_disp(3, op[0].address, sib, min_disp)))
            self.in_regs = (True,)
            self.out_regs = (False,)
            self.out_operands = (True,)
            self.avx_mode = True
            self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        else:
            raise SyntaxError("Invalid operand types: VSTMXCSR " + ", ".join(map(format_operand_type, self.operands)))
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VZEROUPPER(Instruction):
    """Zero Upper Bits of YMM Registers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VZEROUPPER()    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VZEROUPPER, self).__init__("VZEROUPPER", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 0:
            raise SyntaxError("Instruction \"VZEROUPPER\" requires 0 operands")
        self.encodings.append((0x40, lambda op, vex3=False: vex2(0, 0, None, 0, vex3) + bytearray([0x77])))
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


class VZEROALL(Instruction):
    """Zero All YMM Registers"""

    def __init__(self, *args, **kwargs):
        """Supported forms:

            * VZEROALL()    [AVX]
        """

        origin = kwargs.get("origin")
        prototype = kwargs.get("prototype")
        if origin is None and prototype is None and peachpy.x86_64.options.get_debug_level() > 0:
            origin = inspect.stack()
        super(VZEROALL, self).__init__("VZEROALL", origin=origin, prototype=prototype)
        self.operands = tuple(map(check_operand, args))
        if len(self.operands) != 0:
            raise SyntaxError("Instruction \"VZEROALL\" requires 0 operands")
        self.encodings.append((0x40, lambda op, vex3=False: vex2(4, 0, None, 0, vex3) + bytearray([0x77])))
        self.avx_mode = True
        self.isa_extensions = frozenset([peachpy.x86_64.isa.avx])
        if peachpy.stream.active_stream is not None:
            peachpy.stream.active_stream.add_instruction(self)


